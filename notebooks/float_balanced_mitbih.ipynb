{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification on the MIT-BIH Arrhythmia Dataset \n",
    "*Train a Float Neural Net on Float Data (balanced data)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.8.1+cu102\n"
     ]
    }
   ],
   "source": [
    "print(f'torch version: {torch.__version__}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needed paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = Path.cwd().parent\n",
    "project_path\n",
    "train_path_x = project_path / 'data' / 'mit-bih' / 'csv' / 'mitbih_balanced_x_train.csv'\n",
    "train_path_y = project_path / 'data' / 'mit-bih' / 'csv' / 'mitbih_balanced_bin_y_train.csv'\n",
    "test_path_x = project_path / 'data' / 'mit-bih' / 'csv' / 'mitbih_balanced_x_test.csv'\n",
    "test_path_y = project_path / 'data' / 'mit-bih' / 'csv' / 'mitbih_balanced_bin_y_test.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedBinaryECG(Dataset):\n",
    "    def __init__(self, \n",
    "                 train_path_x: Path, \n",
    "                 train_path_y: Path,\n",
    "                 test_path_x: Path,\n",
    "                 test_path_y: Path, \n",
    "                 train=True):\n",
    "        if train:\n",
    "            self.x = np.loadtxt(train_path_x, delimiter=\",\", dtype=float)\n",
    "            self.x = torch.tensor(self.x, dtype=torch.float)\n",
    "            self.x = torch.unsqueeze(self.x, 1)\n",
    "\n",
    "            self.y = np.loadtxt(train_path_y, delimiter=\",\", dtype=float)\n",
    "            self.y = torch.tensor(self.y)\n",
    "\n",
    "        else:\n",
    "            self.x = np.loadtxt(test_path_x, delimiter=\",\", dtype=float)\n",
    "            self.x = torch.tensor(self.x, dtype=torch.float)\n",
    "            self.x = torch.unsqueeze(self.x, 1)\n",
    "            \n",
    "            self.y = np.loadtxt(test_path_y, delimiter=\",\", dtype=float)\n",
    "            self.y = torch.tensor(self.y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_dataset = BalancedBinaryECG(train_path_x, train_path_y, test_path_x, test_path_y, train=True)\n",
    "test_dataset = BalancedBinaryECG(train_path_x, train_path_y, test_path_x, test_path_y, train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6000, 1, 128])\n",
      "torch.Size([6000])\n",
      "torch.Size([6000, 1, 128])\n",
      "torch.Size([6000])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.x.shape)\n",
    "print(train_dataset.y.shape)\n",
    "print(test_dataset.x.shape)\n",
    "print(test_dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f83c3b696a0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x0 = train_dataset.x[0]\n",
    "print(x0.shape)\n",
    "plt.plot(x0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset.y = tensor([1., 1., 0.,  ..., 1., 1., 0.], dtype=torch.float64)\n",
      "there are 3000 normal beats and 3000 abnormal beats in the train dataset\n",
      "there are 3000 normal beats and 3000 abnormal beats in the train dataset\n"
     ]
    }
   ],
   "source": [
    "print(f\"{train_dataset.y = }\")\n",
    "\n",
    "unique, train_counts = np.unique(train_dataset.y, return_counts=True)\n",
    "print(f\"there are {train_counts[0]} normal beats and {train_counts[1]} abnormal beats in the train dataset\")\n",
    "unique, test_counts = np.unique(test_dataset.y, return_counts=True)\n",
    "print(f\"there are {test_counts[0]} normal beats and {test_counts[1]} abnormal beats in the train dataset\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, output_size)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        y_pred = self.sigmoid(y_pred)\n",
    "        return y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters, random seed and the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5000\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'device: {torch.cuda.get_device_name(0)}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel(\n",
      "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "--------- epoch: 1 ---------\n",
      "training loss = 0.6807\n",
      "training accuracy = 0.5682\n",
      "num_train_corrects / train_total_examples = 3409 / 6000\n",
      "num_test_corrects / test_total_examples = 3205 / 6000\n",
      "testing accuracy = 0.5342\n",
      "--------- epoch: 2 ---------\n",
      "training loss = 0.6525\n",
      "training accuracy = 0.6533\n",
      "num_train_corrects / train_total_examples = 3920 / 6000\n",
      "num_test_corrects / test_total_examples = 3618 / 6000\n",
      "testing accuracy = 0.6030\n",
      "--------- epoch: 3 ---------\n",
      "training loss = 0.6310\n",
      "training accuracy = 0.6860\n",
      "num_train_corrects / train_total_examples = 4116 / 6000\n",
      "num_test_corrects / test_total_examples = 3933 / 6000\n",
      "testing accuracy = 0.6555\n",
      "--------- epoch: 4 ---------\n",
      "training loss = 0.6140\n",
      "training accuracy = 0.7042\n",
      "num_train_corrects / train_total_examples = 4225 / 6000\n",
      "num_test_corrects / test_total_examples = 3998 / 6000\n",
      "testing accuracy = 0.6663\n",
      "--------- epoch: 5 ---------\n",
      "training loss = 0.6003\n",
      "training accuracy = 0.7142\n",
      "num_train_corrects / train_total_examples = 4285 / 6000\n",
      "num_test_corrects / test_total_examples = 4068 / 6000\n",
      "testing accuracy = 0.6780\n",
      "--------- epoch: 6 ---------\n",
      "training loss = 0.5890\n",
      "training accuracy = 0.7165\n",
      "num_train_corrects / train_total_examples = 4299 / 6000\n",
      "num_test_corrects / test_total_examples = 4100 / 6000\n",
      "testing accuracy = 0.6833\n",
      "--------- epoch: 7 ---------\n",
      "training loss = 0.5796\n",
      "training accuracy = 0.7183\n",
      "num_train_corrects / train_total_examples = 4310 / 6000\n",
      "num_test_corrects / test_total_examples = 4124 / 6000\n",
      "testing accuracy = 0.6873\n",
      "--------- epoch: 8 ---------\n",
      "training loss = 0.5716\n",
      "training accuracy = 0.7207\n",
      "num_train_corrects / train_total_examples = 4324 / 6000\n",
      "num_test_corrects / test_total_examples = 4147 / 6000\n",
      "testing accuracy = 0.6912\n",
      "--------- epoch: 9 ---------\n",
      "training loss = 0.5648\n",
      "training accuracy = 0.7213\n",
      "num_train_corrects / train_total_examples = 4328 / 6000\n",
      "num_test_corrects / test_total_examples = 4163 / 6000\n",
      "testing accuracy = 0.6938\n",
      "--------- epoch: 10 ---------\n",
      "training loss = 0.5589\n",
      "training accuracy = 0.7240\n",
      "num_train_corrects / train_total_examples = 4344 / 6000\n",
      "num_test_corrects / test_total_examples = 4186 / 6000\n",
      "testing accuracy = 0.6977\n",
      "--------- epoch: 11 ---------\n",
      "training loss = 0.5537\n",
      "training accuracy = 0.7262\n",
      "num_train_corrects / train_total_examples = 4357 / 6000\n",
      "num_test_corrects / test_total_examples = 4210 / 6000\n",
      "testing accuracy = 0.7017\n",
      "--------- epoch: 12 ---------\n",
      "training loss = 0.5491\n",
      "training accuracy = 0.7292\n",
      "num_train_corrects / train_total_examples = 4375 / 6000\n",
      "num_test_corrects / test_total_examples = 4226 / 6000\n",
      "testing accuracy = 0.7043\n",
      "--------- epoch: 13 ---------\n",
      "training loss = 0.5450\n",
      "training accuracy = 0.7318\n",
      "num_train_corrects / train_total_examples = 4391 / 6000\n",
      "num_test_corrects / test_total_examples = 4246 / 6000\n",
      "testing accuracy = 0.7077\n",
      "--------- epoch: 14 ---------\n",
      "training loss = 0.5412\n",
      "training accuracy = 0.7342\n",
      "num_train_corrects / train_total_examples = 4405 / 6000\n",
      "num_test_corrects / test_total_examples = 4260 / 6000\n",
      "testing accuracy = 0.7100\n",
      "--------- epoch: 15 ---------\n",
      "training loss = 0.5378\n",
      "training accuracy = 0.7365\n",
      "num_train_corrects / train_total_examples = 4419 / 6000\n",
      "num_test_corrects / test_total_examples = 4264 / 6000\n",
      "testing accuracy = 0.7107\n",
      "--------- epoch: 16 ---------\n",
      "training loss = 0.5347\n",
      "training accuracy = 0.7387\n",
      "num_train_corrects / train_total_examples = 4432 / 6000\n",
      "num_test_corrects / test_total_examples = 4277 / 6000\n",
      "testing accuracy = 0.7128\n",
      "--------- epoch: 17 ---------\n",
      "training loss = 0.5318\n",
      "training accuracy = 0.7415\n",
      "num_train_corrects / train_total_examples = 4449 / 6000\n",
      "num_test_corrects / test_total_examples = 4292 / 6000\n",
      "testing accuracy = 0.7153\n",
      "--------- epoch: 18 ---------\n",
      "training loss = 0.5292\n",
      "training accuracy = 0.7435\n",
      "num_train_corrects / train_total_examples = 4461 / 6000\n",
      "num_test_corrects / test_total_examples = 4301 / 6000\n",
      "testing accuracy = 0.7168\n",
      "--------- epoch: 19 ---------\n",
      "training loss = 0.5267\n",
      "training accuracy = 0.7457\n",
      "num_train_corrects / train_total_examples = 4474 / 6000\n",
      "num_test_corrects / test_total_examples = 4304 / 6000\n",
      "testing accuracy = 0.7173\n",
      "--------- epoch: 20 ---------\n",
      "training loss = 0.5244\n",
      "training accuracy = 0.7468\n",
      "num_train_corrects / train_total_examples = 4481 / 6000\n",
      "num_test_corrects / test_total_examples = 4305 / 6000\n",
      "testing accuracy = 0.7175\n",
      "--------- epoch: 21 ---------\n",
      "training loss = 0.5222\n",
      "training accuracy = 0.7472\n",
      "num_train_corrects / train_total_examples = 4483 / 6000\n",
      "num_test_corrects / test_total_examples = 4311 / 6000\n",
      "testing accuracy = 0.7185\n",
      "--------- epoch: 22 ---------\n",
      "training loss = 0.5201\n",
      "training accuracy = 0.7487\n",
      "num_train_corrects / train_total_examples = 4492 / 6000\n",
      "num_test_corrects / test_total_examples = 4316 / 6000\n",
      "testing accuracy = 0.7193\n",
      "--------- epoch: 23 ---------\n",
      "training loss = 0.5181\n",
      "training accuracy = 0.7493\n",
      "num_train_corrects / train_total_examples = 4496 / 6000\n",
      "num_test_corrects / test_total_examples = 4325 / 6000\n",
      "testing accuracy = 0.7208\n",
      "--------- epoch: 24 ---------\n",
      "training loss = 0.5163\n",
      "training accuracy = 0.7508\n",
      "num_train_corrects / train_total_examples = 4505 / 6000\n",
      "num_test_corrects / test_total_examples = 4337 / 6000\n",
      "testing accuracy = 0.7228\n",
      "--------- epoch: 25 ---------\n",
      "training loss = 0.5145\n",
      "training accuracy = 0.7523\n",
      "num_train_corrects / train_total_examples = 4514 / 6000\n",
      "num_test_corrects / test_total_examples = 4346 / 6000\n",
      "testing accuracy = 0.7243\n",
      "--------- epoch: 26 ---------\n",
      "training loss = 0.5128\n",
      "training accuracy = 0.7552\n",
      "num_train_corrects / train_total_examples = 4531 / 6000\n",
      "num_test_corrects / test_total_examples = 4353 / 6000\n",
      "testing accuracy = 0.7255\n",
      "--------- epoch: 27 ---------\n",
      "training loss = 0.5112\n",
      "training accuracy = 0.7567\n",
      "num_train_corrects / train_total_examples = 4540 / 6000\n",
      "num_test_corrects / test_total_examples = 4356 / 6000\n",
      "testing accuracy = 0.7260\n",
      "--------- epoch: 28 ---------\n",
      "training loss = 0.5097\n",
      "training accuracy = 0.7577\n",
      "num_train_corrects / train_total_examples = 4546 / 6000\n",
      "num_test_corrects / test_total_examples = 4367 / 6000\n",
      "testing accuracy = 0.7278\n",
      "--------- epoch: 29 ---------\n",
      "training loss = 0.5082\n",
      "training accuracy = 0.7595\n",
      "num_train_corrects / train_total_examples = 4557 / 6000\n",
      "num_test_corrects / test_total_examples = 4375 / 6000\n",
      "testing accuracy = 0.7292\n",
      "--------- epoch: 30 ---------\n",
      "training loss = 0.5067\n",
      "training accuracy = 0.7598\n",
      "num_train_corrects / train_total_examples = 4559 / 6000\n",
      "num_test_corrects / test_total_examples = 4383 / 6000\n",
      "testing accuracy = 0.7305\n",
      "--------- epoch: 31 ---------\n",
      "training loss = 0.5054\n",
      "training accuracy = 0.7600\n",
      "num_train_corrects / train_total_examples = 4560 / 6000\n",
      "num_test_corrects / test_total_examples = 4389 / 6000\n",
      "testing accuracy = 0.7315\n",
      "--------- epoch: 32 ---------\n",
      "training loss = 0.5040\n",
      "training accuracy = 0.7608\n",
      "num_train_corrects / train_total_examples = 4565 / 6000\n",
      "num_test_corrects / test_total_examples = 4405 / 6000\n",
      "testing accuracy = 0.7342\n",
      "--------- epoch: 33 ---------\n",
      "training loss = 0.5027\n",
      "training accuracy = 0.7632\n",
      "num_train_corrects / train_total_examples = 4579 / 6000\n",
      "num_test_corrects / test_total_examples = 4410 / 6000\n",
      "testing accuracy = 0.7350\n",
      "--------- epoch: 34 ---------\n",
      "training loss = 0.5015\n",
      "training accuracy = 0.7640\n",
      "num_train_corrects / train_total_examples = 4584 / 6000\n",
      "num_test_corrects / test_total_examples = 4419 / 6000\n",
      "testing accuracy = 0.7365\n",
      "--------- epoch: 35 ---------\n",
      "training loss = 0.5003\n",
      "training accuracy = 0.7642\n",
      "num_train_corrects / train_total_examples = 4585 / 6000\n",
      "num_test_corrects / test_total_examples = 4425 / 6000\n",
      "testing accuracy = 0.7375\n",
      "--------- epoch: 36 ---------\n",
      "training loss = 0.4991\n",
      "training accuracy = 0.7655\n",
      "num_train_corrects / train_total_examples = 4593 / 6000\n",
      "num_test_corrects / test_total_examples = 4431 / 6000\n",
      "testing accuracy = 0.7385\n",
      "--------- epoch: 37 ---------\n",
      "training loss = 0.4980\n",
      "training accuracy = 0.7658\n",
      "num_train_corrects / train_total_examples = 4595 / 6000\n",
      "num_test_corrects / test_total_examples = 4433 / 6000\n",
      "testing accuracy = 0.7388\n",
      "--------- epoch: 38 ---------\n",
      "training loss = 0.4969\n",
      "training accuracy = 0.7660\n",
      "num_train_corrects / train_total_examples = 4596 / 6000\n",
      "num_test_corrects / test_total_examples = 4435 / 6000\n",
      "testing accuracy = 0.7392\n",
      "--------- epoch: 39 ---------\n",
      "training loss = 0.4958\n",
      "training accuracy = 0.7673\n",
      "num_train_corrects / train_total_examples = 4604 / 6000\n",
      "num_test_corrects / test_total_examples = 4440 / 6000\n",
      "testing accuracy = 0.7400\n",
      "--------- epoch: 40 ---------\n",
      "training loss = 0.4948\n",
      "training accuracy = 0.7680\n",
      "num_train_corrects / train_total_examples = 4608 / 6000\n",
      "num_test_corrects / test_total_examples = 4446 / 6000\n",
      "testing accuracy = 0.7410\n",
      "--------- epoch: 41 ---------\n",
      "training loss = 0.4938\n",
      "training accuracy = 0.7680\n",
      "num_train_corrects / train_total_examples = 4608 / 6000\n",
      "num_test_corrects / test_total_examples = 4457 / 6000\n",
      "testing accuracy = 0.7428\n",
      "--------- epoch: 42 ---------\n",
      "training loss = 0.4928\n",
      "training accuracy = 0.7687\n",
      "num_train_corrects / train_total_examples = 4612 / 6000\n",
      "num_test_corrects / test_total_examples = 4462 / 6000\n",
      "testing accuracy = 0.7437\n",
      "--------- epoch: 43 ---------\n",
      "training loss = 0.4918\n",
      "training accuracy = 0.7702\n",
      "num_train_corrects / train_total_examples = 4621 / 6000\n",
      "num_test_corrects / test_total_examples = 4466 / 6000\n",
      "testing accuracy = 0.7443\n",
      "--------- epoch: 44 ---------\n",
      "training loss = 0.4909\n",
      "training accuracy = 0.7705\n",
      "num_train_corrects / train_total_examples = 4623 / 6000\n",
      "num_test_corrects / test_total_examples = 4469 / 6000\n",
      "testing accuracy = 0.7448\n",
      "--------- epoch: 45 ---------\n",
      "training loss = 0.4900\n",
      "training accuracy = 0.7710\n",
      "num_train_corrects / train_total_examples = 4626 / 6000\n",
      "num_test_corrects / test_total_examples = 4477 / 6000\n",
      "testing accuracy = 0.7462\n",
      "--------- epoch: 46 ---------\n",
      "training loss = 0.4891\n",
      "training accuracy = 0.7713\n",
      "num_train_corrects / train_total_examples = 4628 / 6000\n",
      "num_test_corrects / test_total_examples = 4482 / 6000\n",
      "testing accuracy = 0.7470\n",
      "--------- epoch: 47 ---------\n",
      "training loss = 0.4882\n",
      "training accuracy = 0.7720\n",
      "num_train_corrects / train_total_examples = 4632 / 6000\n",
      "num_test_corrects / test_total_examples = 4483 / 6000\n",
      "testing accuracy = 0.7472\n",
      "--------- epoch: 48 ---------\n",
      "training loss = 0.4874\n",
      "training accuracy = 0.7725\n",
      "num_train_corrects / train_total_examples = 4635 / 6000\n",
      "num_test_corrects / test_total_examples = 4491 / 6000\n",
      "testing accuracy = 0.7485\n",
      "--------- epoch: 49 ---------\n",
      "training loss = 0.4865\n",
      "training accuracy = 0.7737\n",
      "num_train_corrects / train_total_examples = 4642 / 6000\n",
      "num_test_corrects / test_total_examples = 4495 / 6000\n",
      "testing accuracy = 0.7492\n",
      "--------- epoch: 50 ---------\n",
      "training loss = 0.4857\n",
      "training accuracy = 0.7743\n",
      "num_train_corrects / train_total_examples = 4646 / 6000\n",
      "num_test_corrects / test_total_examples = 4498 / 6000\n",
      "testing accuracy = 0.7497\n",
      "--------- epoch: 51 ---------\n",
      "training loss = 0.4849\n",
      "training accuracy = 0.7755\n",
      "num_train_corrects / train_total_examples = 4653 / 6000\n",
      "num_test_corrects / test_total_examples = 4502 / 6000\n",
      "testing accuracy = 0.7503\n",
      "--------- epoch: 52 ---------\n",
      "training loss = 0.4841\n",
      "training accuracy = 0.7757\n",
      "num_train_corrects / train_total_examples = 4654 / 6000\n",
      "num_test_corrects / test_total_examples = 4505 / 6000\n",
      "testing accuracy = 0.7508\n",
      "--------- epoch: 53 ---------\n",
      "training loss = 0.4834\n",
      "training accuracy = 0.7758\n",
      "num_train_corrects / train_total_examples = 4655 / 6000\n",
      "num_test_corrects / test_total_examples = 4505 / 6000\n",
      "testing accuracy = 0.7508\n",
      "--------- epoch: 54 ---------\n",
      "training loss = 0.4826\n",
      "training accuracy = 0.7765\n",
      "num_train_corrects / train_total_examples = 4659 / 6000\n",
      "num_test_corrects / test_total_examples = 4507 / 6000\n",
      "testing accuracy = 0.7512\n",
      "--------- epoch: 55 ---------\n",
      "training loss = 0.4819\n",
      "training accuracy = 0.7775\n",
      "num_train_corrects / train_total_examples = 4665 / 6000\n",
      "num_test_corrects / test_total_examples = 4512 / 6000\n",
      "testing accuracy = 0.7520\n",
      "--------- epoch: 56 ---------\n",
      "training loss = 0.4812\n",
      "training accuracy = 0.7775\n",
      "num_train_corrects / train_total_examples = 4665 / 6000\n",
      "num_test_corrects / test_total_examples = 4513 / 6000\n",
      "testing accuracy = 0.7522\n",
      "--------- epoch: 57 ---------\n",
      "training loss = 0.4805\n",
      "training accuracy = 0.7782\n",
      "num_train_corrects / train_total_examples = 4669 / 6000\n",
      "num_test_corrects / test_total_examples = 4516 / 6000\n",
      "testing accuracy = 0.7527\n",
      "--------- epoch: 58 ---------\n",
      "training loss = 0.4798\n",
      "training accuracy = 0.7785\n",
      "num_train_corrects / train_total_examples = 4671 / 6000\n",
      "num_test_corrects / test_total_examples = 4524 / 6000\n",
      "testing accuracy = 0.7540\n",
      "--------- epoch: 59 ---------\n",
      "training loss = 0.4791\n",
      "training accuracy = 0.7792\n",
      "num_train_corrects / train_total_examples = 4675 / 6000\n",
      "num_test_corrects / test_total_examples = 4528 / 6000\n",
      "testing accuracy = 0.7547\n",
      "--------- epoch: 60 ---------\n",
      "training loss = 0.4784\n",
      "training accuracy = 0.7792\n",
      "num_train_corrects / train_total_examples = 4675 / 6000\n",
      "num_test_corrects / test_total_examples = 4529 / 6000\n",
      "testing accuracy = 0.7548\n",
      "--------- epoch: 61 ---------\n",
      "training loss = 0.4777\n",
      "training accuracy = 0.7795\n",
      "num_train_corrects / train_total_examples = 4677 / 6000\n",
      "num_test_corrects / test_total_examples = 4532 / 6000\n",
      "testing accuracy = 0.7553\n",
      "--------- epoch: 62 ---------\n",
      "training loss = 0.4771\n",
      "training accuracy = 0.7798\n",
      "num_train_corrects / train_total_examples = 4679 / 6000\n",
      "num_test_corrects / test_total_examples = 4535 / 6000\n",
      "testing accuracy = 0.7558\n",
      "--------- epoch: 63 ---------\n",
      "training loss = 0.4765\n",
      "training accuracy = 0.7797\n",
      "num_train_corrects / train_total_examples = 4678 / 6000\n",
      "num_test_corrects / test_total_examples = 4540 / 6000\n",
      "testing accuracy = 0.7567\n",
      "--------- epoch: 64 ---------\n",
      "training loss = 0.4758\n",
      "training accuracy = 0.7795\n",
      "num_train_corrects / train_total_examples = 4677 / 6000\n",
      "num_test_corrects / test_total_examples = 4545 / 6000\n",
      "testing accuracy = 0.7575\n",
      "--------- epoch: 65 ---------\n",
      "training loss = 0.4752\n",
      "training accuracy = 0.7795\n",
      "num_train_corrects / train_total_examples = 4677 / 6000\n",
      "num_test_corrects / test_total_examples = 4549 / 6000\n",
      "testing accuracy = 0.7582\n",
      "--------- epoch: 66 ---------\n",
      "training loss = 0.4746\n",
      "training accuracy = 0.7795\n",
      "num_train_corrects / train_total_examples = 4677 / 6000\n",
      "num_test_corrects / test_total_examples = 4554 / 6000\n",
      "testing accuracy = 0.7590\n",
      "--------- epoch: 67 ---------\n",
      "training loss = 0.4740\n",
      "training accuracy = 0.7802\n",
      "num_train_corrects / train_total_examples = 4681 / 6000\n",
      "num_test_corrects / test_total_examples = 4556 / 6000\n",
      "testing accuracy = 0.7593\n",
      "--------- epoch: 68 ---------\n",
      "training loss = 0.4734\n",
      "training accuracy = 0.7807\n",
      "num_train_corrects / train_total_examples = 4684 / 6000\n",
      "num_test_corrects / test_total_examples = 4565 / 6000\n",
      "testing accuracy = 0.7608\n",
      "--------- epoch: 69 ---------\n",
      "training loss = 0.4729\n",
      "training accuracy = 0.7813\n",
      "num_train_corrects / train_total_examples = 4688 / 6000\n",
      "num_test_corrects / test_total_examples = 4567 / 6000\n",
      "testing accuracy = 0.7612\n",
      "--------- epoch: 70 ---------\n",
      "training loss = 0.4723\n",
      "training accuracy = 0.7808\n",
      "num_train_corrects / train_total_examples = 4685 / 6000\n",
      "num_test_corrects / test_total_examples = 4567 / 6000\n",
      "testing accuracy = 0.7612\n",
      "--------- epoch: 71 ---------\n",
      "training loss = 0.4717\n",
      "training accuracy = 0.7810\n",
      "num_train_corrects / train_total_examples = 4686 / 6000\n",
      "num_test_corrects / test_total_examples = 4571 / 6000\n",
      "testing accuracy = 0.7618\n",
      "--------- epoch: 72 ---------\n",
      "training loss = 0.4712\n",
      "training accuracy = 0.7810\n",
      "num_train_corrects / train_total_examples = 4686 / 6000\n",
      "num_test_corrects / test_total_examples = 4575 / 6000\n",
      "testing accuracy = 0.7625\n",
      "--------- epoch: 73 ---------\n",
      "training loss = 0.4707\n",
      "training accuracy = 0.7812\n",
      "num_train_corrects / train_total_examples = 4687 / 6000\n",
      "num_test_corrects / test_total_examples = 4578 / 6000\n",
      "testing accuracy = 0.7630\n",
      "--------- epoch: 74 ---------\n",
      "training loss = 0.4701\n",
      "training accuracy = 0.7817\n",
      "num_train_corrects / train_total_examples = 4690 / 6000\n",
      "num_test_corrects / test_total_examples = 4580 / 6000\n",
      "testing accuracy = 0.7633\n",
      "--------- epoch: 75 ---------\n",
      "training loss = 0.4696\n",
      "training accuracy = 0.7822\n",
      "num_train_corrects / train_total_examples = 4693 / 6000\n",
      "num_test_corrects / test_total_examples = 4586 / 6000\n",
      "testing accuracy = 0.7643\n",
      "--------- epoch: 76 ---------\n",
      "training loss = 0.4691\n",
      "training accuracy = 0.7823\n",
      "num_train_corrects / train_total_examples = 4694 / 6000\n",
      "num_test_corrects / test_total_examples = 4586 / 6000\n",
      "testing accuracy = 0.7643\n",
      "--------- epoch: 77 ---------\n",
      "training loss = 0.4686\n",
      "training accuracy = 0.7832\n",
      "num_train_corrects / train_total_examples = 4699 / 6000\n",
      "num_test_corrects / test_total_examples = 4590 / 6000\n",
      "testing accuracy = 0.7650\n",
      "--------- epoch: 78 ---------\n",
      "training loss = 0.4681\n",
      "training accuracy = 0.7833\n",
      "num_train_corrects / train_total_examples = 4700 / 6000\n",
      "num_test_corrects / test_total_examples = 4595 / 6000\n",
      "testing accuracy = 0.7658\n",
      "--------- epoch: 79 ---------\n",
      "training loss = 0.4676\n",
      "training accuracy = 0.7833\n",
      "num_train_corrects / train_total_examples = 4700 / 6000\n",
      "num_test_corrects / test_total_examples = 4598 / 6000\n",
      "testing accuracy = 0.7663\n",
      "--------- epoch: 80 ---------\n",
      "training loss = 0.4671\n",
      "training accuracy = 0.7835\n",
      "num_train_corrects / train_total_examples = 4701 / 6000\n",
      "num_test_corrects / test_total_examples = 4600 / 6000\n",
      "testing accuracy = 0.7667\n",
      "--------- epoch: 81 ---------\n",
      "training loss = 0.4666\n",
      "training accuracy = 0.7840\n",
      "num_train_corrects / train_total_examples = 4704 / 6000\n",
      "num_test_corrects / test_total_examples = 4603 / 6000\n",
      "testing accuracy = 0.7672\n",
      "--------- epoch: 82 ---------\n",
      "training loss = 0.4661\n",
      "training accuracy = 0.7843\n",
      "num_train_corrects / train_total_examples = 4706 / 6000\n",
      "num_test_corrects / test_total_examples = 4606 / 6000\n",
      "testing accuracy = 0.7677\n",
      "--------- epoch: 83 ---------\n",
      "training loss = 0.4657\n",
      "training accuracy = 0.7845\n",
      "num_train_corrects / train_total_examples = 4707 / 6000\n",
      "num_test_corrects / test_total_examples = 4613 / 6000\n",
      "testing accuracy = 0.7688\n",
      "--------- epoch: 84 ---------\n",
      "training loss = 0.4652\n",
      "training accuracy = 0.7847\n",
      "num_train_corrects / train_total_examples = 4708 / 6000\n",
      "num_test_corrects / test_total_examples = 4616 / 6000\n",
      "testing accuracy = 0.7693\n",
      "--------- epoch: 85 ---------\n",
      "training loss = 0.4647\n",
      "training accuracy = 0.7847\n",
      "num_train_corrects / train_total_examples = 4708 / 6000\n",
      "num_test_corrects / test_total_examples = 4619 / 6000\n",
      "testing accuracy = 0.7698\n",
      "--------- epoch: 86 ---------\n",
      "training loss = 0.4643\n",
      "training accuracy = 0.7848\n",
      "num_train_corrects / train_total_examples = 4709 / 6000\n",
      "num_test_corrects / test_total_examples = 4622 / 6000\n",
      "testing accuracy = 0.7703\n",
      "--------- epoch: 87 ---------\n",
      "training loss = 0.4639\n",
      "training accuracy = 0.7855\n",
      "num_train_corrects / train_total_examples = 4713 / 6000\n",
      "num_test_corrects / test_total_examples = 4627 / 6000\n",
      "testing accuracy = 0.7712\n",
      "--------- epoch: 88 ---------\n",
      "training loss = 0.4634\n",
      "training accuracy = 0.7852\n",
      "num_train_corrects / train_total_examples = 4711 / 6000\n",
      "num_test_corrects / test_total_examples = 4630 / 6000\n",
      "testing accuracy = 0.7717\n",
      "--------- epoch: 89 ---------\n",
      "training loss = 0.4630\n",
      "training accuracy = 0.7853\n",
      "num_train_corrects / train_total_examples = 4712 / 6000\n",
      "num_test_corrects / test_total_examples = 4632 / 6000\n",
      "testing accuracy = 0.7720\n",
      "--------- epoch: 90 ---------\n",
      "training loss = 0.4626\n",
      "training accuracy = 0.7853\n",
      "num_train_corrects / train_total_examples = 4712 / 6000\n",
      "num_test_corrects / test_total_examples = 4634 / 6000\n",
      "testing accuracy = 0.7723\n",
      "--------- epoch: 91 ---------\n",
      "training loss = 0.4621\n",
      "training accuracy = 0.7855\n",
      "num_train_corrects / train_total_examples = 4713 / 6000\n",
      "num_test_corrects / test_total_examples = 4634 / 6000\n",
      "testing accuracy = 0.7723\n",
      "--------- epoch: 92 ---------\n",
      "training loss = 0.4617\n",
      "training accuracy = 0.7857\n",
      "num_train_corrects / train_total_examples = 4714 / 6000\n",
      "num_test_corrects / test_total_examples = 4635 / 6000\n",
      "testing accuracy = 0.7725\n",
      "--------- epoch: 93 ---------\n",
      "training loss = 0.4613\n",
      "training accuracy = 0.7865\n",
      "num_train_corrects / train_total_examples = 4719 / 6000\n",
      "num_test_corrects / test_total_examples = 4640 / 6000\n",
      "testing accuracy = 0.7733\n",
      "--------- epoch: 94 ---------\n",
      "training loss = 0.4609\n",
      "training accuracy = 0.7868\n",
      "num_train_corrects / train_total_examples = 4721 / 6000\n",
      "num_test_corrects / test_total_examples = 4640 / 6000\n",
      "testing accuracy = 0.7733\n",
      "--------- epoch: 95 ---------\n",
      "training loss = 0.4605\n",
      "training accuracy = 0.7875\n",
      "num_train_corrects / train_total_examples = 4725 / 6000\n",
      "num_test_corrects / test_total_examples = 4640 / 6000\n",
      "testing accuracy = 0.7733\n",
      "--------- epoch: 96 ---------\n",
      "training loss = 0.4601\n",
      "training accuracy = 0.7885\n",
      "num_train_corrects / train_total_examples = 4731 / 6000\n",
      "num_test_corrects / test_total_examples = 4643 / 6000\n",
      "testing accuracy = 0.7738\n",
      "--------- epoch: 97 ---------\n",
      "training loss = 0.4597\n",
      "training accuracy = 0.7890\n",
      "num_train_corrects / train_total_examples = 4734 / 6000\n",
      "num_test_corrects / test_total_examples = 4648 / 6000\n",
      "testing accuracy = 0.7747\n",
      "--------- epoch: 98 ---------\n",
      "training loss = 0.4593\n",
      "training accuracy = 0.7887\n",
      "num_train_corrects / train_total_examples = 4732 / 6000\n",
      "num_test_corrects / test_total_examples = 4651 / 6000\n",
      "testing accuracy = 0.7752\n",
      "--------- epoch: 99 ---------\n",
      "training loss = 0.4589\n",
      "training accuracy = 0.7892\n",
      "num_train_corrects / train_total_examples = 4735 / 6000\n",
      "num_test_corrects / test_total_examples = 4654 / 6000\n",
      "testing accuracy = 0.7757\n",
      "--------- epoch: 100 ---------\n",
      "training loss = 0.4586\n",
      "training accuracy = 0.7900\n",
      "num_train_corrects / train_total_examples = 4740 / 6000\n",
      "num_test_corrects / test_total_examples = 4657 / 6000\n",
      "testing accuracy = 0.7762\n",
      "--------- epoch: 101 ---------\n",
      "training loss = 0.4582\n",
      "training accuracy = 0.7908\n",
      "num_train_corrects / train_total_examples = 4745 / 6000\n",
      "num_test_corrects / test_total_examples = 4658 / 6000\n",
      "testing accuracy = 0.7763\n",
      "--------- epoch: 102 ---------\n",
      "training loss = 0.4578\n",
      "training accuracy = 0.7908\n",
      "num_train_corrects / train_total_examples = 4745 / 6000\n",
      "num_test_corrects / test_total_examples = 4662 / 6000\n",
      "testing accuracy = 0.7770\n",
      "--------- epoch: 103 ---------\n",
      "training loss = 0.4574\n",
      "training accuracy = 0.7912\n",
      "num_train_corrects / train_total_examples = 4747 / 6000\n",
      "num_test_corrects / test_total_examples = 4664 / 6000\n",
      "testing accuracy = 0.7773\n",
      "--------- epoch: 104 ---------\n",
      "training loss = 0.4571\n",
      "training accuracy = 0.7913\n",
      "num_train_corrects / train_total_examples = 4748 / 6000\n",
      "num_test_corrects / test_total_examples = 4667 / 6000\n",
      "testing accuracy = 0.7778\n",
      "--------- epoch: 105 ---------\n",
      "training loss = 0.4567\n",
      "training accuracy = 0.7915\n",
      "num_train_corrects / train_total_examples = 4749 / 6000\n",
      "num_test_corrects / test_total_examples = 4667 / 6000\n",
      "testing accuracy = 0.7778\n",
      "--------- epoch: 106 ---------\n",
      "training loss = 0.4564\n",
      "training accuracy = 0.7922\n",
      "num_train_corrects / train_total_examples = 4753 / 6000\n",
      "num_test_corrects / test_total_examples = 4666 / 6000\n",
      "testing accuracy = 0.7777\n",
      "--------- epoch: 107 ---------\n",
      "training loss = 0.4560\n",
      "training accuracy = 0.7927\n",
      "num_train_corrects / train_total_examples = 4756 / 6000\n",
      "num_test_corrects / test_total_examples = 4669 / 6000\n",
      "testing accuracy = 0.7782\n",
      "--------- epoch: 108 ---------\n",
      "training loss = 0.4557\n",
      "training accuracy = 0.7922\n",
      "num_train_corrects / train_total_examples = 4753 / 6000\n",
      "num_test_corrects / test_total_examples = 4669 / 6000\n",
      "testing accuracy = 0.7782\n",
      "--------- epoch: 109 ---------\n",
      "training loss = 0.4553\n",
      "training accuracy = 0.7925\n",
      "num_train_corrects / train_total_examples = 4755 / 6000\n",
      "num_test_corrects / test_total_examples = 4671 / 6000\n",
      "testing accuracy = 0.7785\n",
      "--------- epoch: 110 ---------\n",
      "training loss = 0.4550\n",
      "training accuracy = 0.7925\n",
      "num_train_corrects / train_total_examples = 4755 / 6000\n",
      "num_test_corrects / test_total_examples = 4672 / 6000\n",
      "testing accuracy = 0.7787\n",
      "--------- epoch: 111 ---------\n",
      "training loss = 0.4547\n",
      "training accuracy = 0.7927\n",
      "num_train_corrects / train_total_examples = 4756 / 6000\n",
      "num_test_corrects / test_total_examples = 4673 / 6000\n",
      "testing accuracy = 0.7788\n",
      "--------- epoch: 112 ---------\n",
      "training loss = 0.4543\n",
      "training accuracy = 0.7927\n",
      "num_train_corrects / train_total_examples = 4756 / 6000\n",
      "num_test_corrects / test_total_examples = 4676 / 6000\n",
      "testing accuracy = 0.7793\n",
      "--------- epoch: 113 ---------\n",
      "training loss = 0.4540\n",
      "training accuracy = 0.7925\n",
      "num_train_corrects / train_total_examples = 4755 / 6000\n",
      "num_test_corrects / test_total_examples = 4677 / 6000\n",
      "testing accuracy = 0.7795\n",
      "--------- epoch: 114 ---------\n",
      "training loss = 0.4537\n",
      "training accuracy = 0.7930\n",
      "num_train_corrects / train_total_examples = 4758 / 6000\n",
      "num_test_corrects / test_total_examples = 4679 / 6000\n",
      "testing accuracy = 0.7798\n",
      "--------- epoch: 115 ---------\n",
      "training loss = 0.4534\n",
      "training accuracy = 0.7933\n",
      "num_train_corrects / train_total_examples = 4760 / 6000\n",
      "num_test_corrects / test_total_examples = 4682 / 6000\n",
      "testing accuracy = 0.7803\n",
      "--------- epoch: 116 ---------\n",
      "training loss = 0.4530\n",
      "training accuracy = 0.7933\n",
      "num_train_corrects / train_total_examples = 4760 / 6000\n",
      "num_test_corrects / test_total_examples = 4682 / 6000\n",
      "testing accuracy = 0.7803\n",
      "--------- epoch: 117 ---------\n",
      "training loss = 0.4527\n",
      "training accuracy = 0.7932\n",
      "num_train_corrects / train_total_examples = 4759 / 6000\n",
      "num_test_corrects / test_total_examples = 4687 / 6000\n",
      "testing accuracy = 0.7812\n",
      "--------- epoch: 118 ---------\n",
      "training loss = 0.4524\n",
      "training accuracy = 0.7933\n",
      "num_train_corrects / train_total_examples = 4760 / 6000\n",
      "num_test_corrects / test_total_examples = 4689 / 6000\n",
      "testing accuracy = 0.7815\n",
      "--------- epoch: 119 ---------\n",
      "training loss = 0.4521\n",
      "training accuracy = 0.7940\n",
      "num_train_corrects / train_total_examples = 4764 / 6000\n",
      "num_test_corrects / test_total_examples = 4692 / 6000\n",
      "testing accuracy = 0.7820\n",
      "--------- epoch: 120 ---------\n",
      "training loss = 0.4518\n",
      "training accuracy = 0.7943\n",
      "num_train_corrects / train_total_examples = 4766 / 6000\n",
      "num_test_corrects / test_total_examples = 4695 / 6000\n",
      "testing accuracy = 0.7825\n",
      "--------- epoch: 121 ---------\n",
      "training loss = 0.4515\n",
      "training accuracy = 0.7943\n",
      "num_train_corrects / train_total_examples = 4766 / 6000\n",
      "num_test_corrects / test_total_examples = 4699 / 6000\n",
      "testing accuracy = 0.7832\n",
      "--------- epoch: 122 ---------\n",
      "training loss = 0.4512\n",
      "training accuracy = 0.7943\n",
      "num_train_corrects / train_total_examples = 4766 / 6000\n",
      "num_test_corrects / test_total_examples = 4698 / 6000\n",
      "testing accuracy = 0.7830\n",
      "--------- epoch: 123 ---------\n",
      "training loss = 0.4509\n",
      "training accuracy = 0.7945\n",
      "num_train_corrects / train_total_examples = 4767 / 6000\n",
      "num_test_corrects / test_total_examples = 4700 / 6000\n",
      "testing accuracy = 0.7833\n",
      "--------- epoch: 124 ---------\n",
      "training loss = 0.4506\n",
      "training accuracy = 0.7945\n",
      "num_train_corrects / train_total_examples = 4767 / 6000\n",
      "num_test_corrects / test_total_examples = 4699 / 6000\n",
      "testing accuracy = 0.7832\n",
      "--------- epoch: 125 ---------\n",
      "training loss = 0.4503\n",
      "training accuracy = 0.7947\n",
      "num_train_corrects / train_total_examples = 4768 / 6000\n",
      "num_test_corrects / test_total_examples = 4701 / 6000\n",
      "testing accuracy = 0.7835\n",
      "--------- epoch: 126 ---------\n",
      "training loss = 0.4500\n",
      "training accuracy = 0.7950\n",
      "num_train_corrects / train_total_examples = 4770 / 6000\n",
      "num_test_corrects / test_total_examples = 4702 / 6000\n",
      "testing accuracy = 0.7837\n",
      "--------- epoch: 127 ---------\n",
      "training loss = 0.4497\n",
      "training accuracy = 0.7948\n",
      "num_train_corrects / train_total_examples = 4769 / 6000\n",
      "num_test_corrects / test_total_examples = 4702 / 6000\n",
      "testing accuracy = 0.7837\n",
      "--------- epoch: 128 ---------\n",
      "training loss = 0.4495\n",
      "training accuracy = 0.7948\n",
      "num_train_corrects / train_total_examples = 4769 / 6000\n",
      "num_test_corrects / test_total_examples = 4704 / 6000\n",
      "testing accuracy = 0.7840\n",
      "--------- epoch: 129 ---------\n",
      "training loss = 0.4492\n",
      "training accuracy = 0.7947\n",
      "num_train_corrects / train_total_examples = 4768 / 6000\n",
      "num_test_corrects / test_total_examples = 4704 / 6000\n",
      "testing accuracy = 0.7840\n",
      "--------- epoch: 130 ---------\n",
      "training loss = 0.4489\n",
      "training accuracy = 0.7952\n",
      "num_train_corrects / train_total_examples = 4771 / 6000\n",
      "num_test_corrects / test_total_examples = 4708 / 6000\n",
      "testing accuracy = 0.7847\n",
      "--------- epoch: 131 ---------\n",
      "training loss = 0.4486\n",
      "training accuracy = 0.7953\n",
      "num_train_corrects / train_total_examples = 4772 / 6000\n",
      "num_test_corrects / test_total_examples = 4709 / 6000\n",
      "testing accuracy = 0.7848\n",
      "--------- epoch: 132 ---------\n",
      "training loss = 0.4484\n",
      "training accuracy = 0.7958\n",
      "num_train_corrects / train_total_examples = 4775 / 6000\n",
      "num_test_corrects / test_total_examples = 4715 / 6000\n",
      "testing accuracy = 0.7858\n",
      "--------- epoch: 133 ---------\n",
      "training loss = 0.4481\n",
      "training accuracy = 0.7958\n",
      "num_train_corrects / train_total_examples = 4775 / 6000\n",
      "num_test_corrects / test_total_examples = 4716 / 6000\n",
      "testing accuracy = 0.7860\n",
      "--------- epoch: 134 ---------\n",
      "training loss = 0.4478\n",
      "training accuracy = 0.7960\n",
      "num_train_corrects / train_total_examples = 4776 / 6000\n",
      "num_test_corrects / test_total_examples = 4717 / 6000\n",
      "testing accuracy = 0.7862\n",
      "--------- epoch: 135 ---------\n",
      "training loss = 0.4476\n",
      "training accuracy = 0.7963\n",
      "num_train_corrects / train_total_examples = 4778 / 6000\n",
      "num_test_corrects / test_total_examples = 4718 / 6000\n",
      "testing accuracy = 0.7863\n",
      "--------- epoch: 136 ---------\n",
      "training loss = 0.4473\n",
      "training accuracy = 0.7963\n",
      "num_train_corrects / train_total_examples = 4778 / 6000\n",
      "num_test_corrects / test_total_examples = 4720 / 6000\n",
      "testing accuracy = 0.7867\n",
      "--------- epoch: 137 ---------\n",
      "training loss = 0.4470\n",
      "training accuracy = 0.7967\n",
      "num_train_corrects / train_total_examples = 4780 / 6000\n",
      "num_test_corrects / test_total_examples = 4720 / 6000\n",
      "testing accuracy = 0.7867\n",
      "--------- epoch: 138 ---------\n",
      "training loss = 0.4468\n",
      "training accuracy = 0.7968\n",
      "num_train_corrects / train_total_examples = 4781 / 6000\n",
      "num_test_corrects / test_total_examples = 4722 / 6000\n",
      "testing accuracy = 0.7870\n",
      "--------- epoch: 139 ---------\n",
      "training loss = 0.4465\n",
      "training accuracy = 0.7970\n",
      "num_train_corrects / train_total_examples = 4782 / 6000\n",
      "num_test_corrects / test_total_examples = 4721 / 6000\n",
      "testing accuracy = 0.7868\n",
      "--------- epoch: 140 ---------\n",
      "training loss = 0.4463\n",
      "training accuracy = 0.7972\n",
      "num_train_corrects / train_total_examples = 4783 / 6000\n",
      "num_test_corrects / test_total_examples = 4725 / 6000\n",
      "testing accuracy = 0.7875\n",
      "--------- epoch: 141 ---------\n",
      "training loss = 0.4460\n",
      "training accuracy = 0.7975\n",
      "num_train_corrects / train_total_examples = 4785 / 6000\n",
      "num_test_corrects / test_total_examples = 4727 / 6000\n",
      "testing accuracy = 0.7878\n",
      "--------- epoch: 142 ---------\n",
      "training loss = 0.4458\n",
      "training accuracy = 0.7978\n",
      "num_train_corrects / train_total_examples = 4787 / 6000\n",
      "num_test_corrects / test_total_examples = 4730 / 6000\n",
      "testing accuracy = 0.7883\n",
      "--------- epoch: 143 ---------\n",
      "training loss = 0.4455\n",
      "training accuracy = 0.7980\n",
      "num_train_corrects / train_total_examples = 4788 / 6000\n",
      "num_test_corrects / test_total_examples = 4731 / 6000\n",
      "testing accuracy = 0.7885\n",
      "--------- epoch: 144 ---------\n",
      "training loss = 0.4453\n",
      "training accuracy = 0.7983\n",
      "num_train_corrects / train_total_examples = 4790 / 6000\n",
      "num_test_corrects / test_total_examples = 4732 / 6000\n",
      "testing accuracy = 0.7887\n",
      "--------- epoch: 145 ---------\n",
      "training loss = 0.4450\n",
      "training accuracy = 0.7983\n",
      "num_train_corrects / train_total_examples = 4790 / 6000\n",
      "num_test_corrects / test_total_examples = 4734 / 6000\n",
      "testing accuracy = 0.7890\n",
      "--------- epoch: 146 ---------\n",
      "training loss = 0.4448\n",
      "training accuracy = 0.7985\n",
      "num_train_corrects / train_total_examples = 4791 / 6000\n",
      "num_test_corrects / test_total_examples = 4737 / 6000\n",
      "testing accuracy = 0.7895\n",
      "--------- epoch: 147 ---------\n",
      "training loss = 0.4446\n",
      "training accuracy = 0.7992\n",
      "num_train_corrects / train_total_examples = 4795 / 6000\n",
      "num_test_corrects / test_total_examples = 4736 / 6000\n",
      "testing accuracy = 0.7893\n",
      "--------- epoch: 148 ---------\n",
      "training loss = 0.4443\n",
      "training accuracy = 0.7993\n",
      "num_train_corrects / train_total_examples = 4796 / 6000\n",
      "num_test_corrects / test_total_examples = 4737 / 6000\n",
      "testing accuracy = 0.7895\n",
      "--------- epoch: 149 ---------\n",
      "training loss = 0.4441\n",
      "training accuracy = 0.7997\n",
      "num_train_corrects / train_total_examples = 4798 / 6000\n",
      "num_test_corrects / test_total_examples = 4737 / 6000\n",
      "testing accuracy = 0.7895\n",
      "--------- epoch: 150 ---------\n",
      "training loss = 0.4439\n",
      "training accuracy = 0.7995\n",
      "num_train_corrects / train_total_examples = 4797 / 6000\n",
      "num_test_corrects / test_total_examples = 4737 / 6000\n",
      "testing accuracy = 0.7895\n",
      "--------- epoch: 151 ---------\n",
      "training loss = 0.4436\n",
      "training accuracy = 0.7997\n",
      "num_train_corrects / train_total_examples = 4798 / 6000\n",
      "num_test_corrects / test_total_examples = 4737 / 6000\n",
      "testing accuracy = 0.7895\n",
      "--------- epoch: 152 ---------\n",
      "training loss = 0.4434\n",
      "training accuracy = 0.7997\n",
      "num_train_corrects / train_total_examples = 4798 / 6000\n",
      "num_test_corrects / test_total_examples = 4738 / 6000\n",
      "testing accuracy = 0.7897\n",
      "--------- epoch: 153 ---------\n",
      "training loss = 0.4432\n",
      "training accuracy = 0.7998\n",
      "num_train_corrects / train_total_examples = 4799 / 6000\n",
      "num_test_corrects / test_total_examples = 4739 / 6000\n",
      "testing accuracy = 0.7898\n",
      "--------- epoch: 154 ---------\n",
      "training loss = 0.4430\n",
      "training accuracy = 0.7998\n",
      "num_train_corrects / train_total_examples = 4799 / 6000\n",
      "num_test_corrects / test_total_examples = 4740 / 6000\n",
      "testing accuracy = 0.7900\n",
      "--------- epoch: 155 ---------\n",
      "training loss = 0.4427\n",
      "training accuracy = 0.8000\n",
      "num_train_corrects / train_total_examples = 4800 / 6000\n",
      "num_test_corrects / test_total_examples = 4741 / 6000\n",
      "testing accuracy = 0.7902\n",
      "--------- epoch: 156 ---------\n",
      "training loss = 0.4425\n",
      "training accuracy = 0.8000\n",
      "num_train_corrects / train_total_examples = 4800 / 6000\n",
      "num_test_corrects / test_total_examples = 4741 / 6000\n",
      "testing accuracy = 0.7902\n",
      "--------- epoch: 157 ---------\n",
      "training loss = 0.4423\n",
      "training accuracy = 0.7998\n",
      "num_train_corrects / train_total_examples = 4799 / 6000\n",
      "num_test_corrects / test_total_examples = 4741 / 6000\n",
      "testing accuracy = 0.7902\n",
      "--------- epoch: 158 ---------\n",
      "training loss = 0.4421\n",
      "training accuracy = 0.7998\n",
      "num_train_corrects / train_total_examples = 4799 / 6000\n",
      "num_test_corrects / test_total_examples = 4741 / 6000\n",
      "testing accuracy = 0.7902\n",
      "--------- epoch: 159 ---------\n",
      "training loss = 0.4419\n",
      "training accuracy = 0.8000\n",
      "num_train_corrects / train_total_examples = 4800 / 6000\n",
      "num_test_corrects / test_total_examples = 4742 / 6000\n",
      "testing accuracy = 0.7903\n",
      "--------- epoch: 160 ---------\n",
      "training loss = 0.4417\n",
      "training accuracy = 0.8002\n",
      "num_train_corrects / train_total_examples = 4801 / 6000\n",
      "num_test_corrects / test_total_examples = 4741 / 6000\n",
      "testing accuracy = 0.7902\n",
      "--------- epoch: 161 ---------\n",
      "training loss = 0.4414\n",
      "training accuracy = 0.8003\n",
      "num_train_corrects / train_total_examples = 4802 / 6000\n",
      "num_test_corrects / test_total_examples = 4740 / 6000\n",
      "testing accuracy = 0.7900\n",
      "--------- epoch: 162 ---------\n",
      "training loss = 0.4412\n",
      "training accuracy = 0.8008\n",
      "num_train_corrects / train_total_examples = 4805 / 6000\n",
      "num_test_corrects / test_total_examples = 4741 / 6000\n",
      "testing accuracy = 0.7902\n",
      "--------- epoch: 163 ---------\n",
      "training loss = 0.4410\n",
      "training accuracy = 0.8008\n",
      "num_train_corrects / train_total_examples = 4805 / 6000\n",
      "num_test_corrects / test_total_examples = 4740 / 6000\n",
      "testing accuracy = 0.7900\n",
      "--------- epoch: 164 ---------\n",
      "training loss = 0.4408\n",
      "training accuracy = 0.8010\n",
      "num_train_corrects / train_total_examples = 4806 / 6000\n",
      "num_test_corrects / test_total_examples = 4740 / 6000\n",
      "testing accuracy = 0.7900\n",
      "--------- epoch: 165 ---------\n",
      "training loss = 0.4406\n",
      "training accuracy = 0.8010\n",
      "num_train_corrects / train_total_examples = 4806 / 6000\n",
      "num_test_corrects / test_total_examples = 4740 / 6000\n",
      "testing accuracy = 0.7900\n",
      "--------- epoch: 166 ---------\n",
      "training loss = 0.4404\n",
      "training accuracy = 0.8012\n",
      "num_train_corrects / train_total_examples = 4807 / 6000\n",
      "num_test_corrects / test_total_examples = 4741 / 6000\n",
      "testing accuracy = 0.7902\n",
      "--------- epoch: 167 ---------\n",
      "training loss = 0.4402\n",
      "training accuracy = 0.8010\n",
      "num_train_corrects / train_total_examples = 4806 / 6000\n",
      "num_test_corrects / test_total_examples = 4742 / 6000\n",
      "testing accuracy = 0.7903\n",
      "--------- epoch: 168 ---------\n",
      "training loss = 0.4400\n",
      "training accuracy = 0.8008\n",
      "num_train_corrects / train_total_examples = 4805 / 6000\n",
      "num_test_corrects / test_total_examples = 4745 / 6000\n",
      "testing accuracy = 0.7908\n",
      "--------- epoch: 169 ---------\n",
      "training loss = 0.4398\n",
      "training accuracy = 0.8010\n",
      "num_train_corrects / train_total_examples = 4806 / 6000\n",
      "num_test_corrects / test_total_examples = 4746 / 6000\n",
      "testing accuracy = 0.7910\n",
      "--------- epoch: 170 ---------\n",
      "training loss = 0.4396\n",
      "training accuracy = 0.8013\n",
      "num_train_corrects / train_total_examples = 4808 / 6000\n",
      "num_test_corrects / test_total_examples = 4746 / 6000\n",
      "testing accuracy = 0.7910\n",
      "--------- epoch: 171 ---------\n",
      "training loss = 0.4394\n",
      "training accuracy = 0.8012\n",
      "num_train_corrects / train_total_examples = 4807 / 6000\n",
      "num_test_corrects / test_total_examples = 4744 / 6000\n",
      "testing accuracy = 0.7907\n",
      "--------- epoch: 172 ---------\n",
      "training loss = 0.4392\n",
      "training accuracy = 0.8017\n",
      "num_train_corrects / train_total_examples = 4810 / 6000\n",
      "num_test_corrects / test_total_examples = 4747 / 6000\n",
      "testing accuracy = 0.7912\n",
      "--------- epoch: 173 ---------\n",
      "training loss = 0.4390\n",
      "training accuracy = 0.8017\n",
      "num_train_corrects / train_total_examples = 4810 / 6000\n",
      "num_test_corrects / test_total_examples = 4747 / 6000\n",
      "testing accuracy = 0.7912\n",
      "--------- epoch: 174 ---------\n",
      "training loss = 0.4388\n",
      "training accuracy = 0.8018\n",
      "num_train_corrects / train_total_examples = 4811 / 6000\n",
      "num_test_corrects / test_total_examples = 4749 / 6000\n",
      "testing accuracy = 0.7915\n",
      "--------- epoch: 175 ---------\n",
      "training loss = 0.4386\n",
      "training accuracy = 0.8018\n",
      "num_train_corrects / train_total_examples = 4811 / 6000\n",
      "num_test_corrects / test_total_examples = 4749 / 6000\n",
      "testing accuracy = 0.7915\n",
      "--------- epoch: 176 ---------\n",
      "training loss = 0.4385\n",
      "training accuracy = 0.8022\n",
      "num_train_corrects / train_total_examples = 4813 / 6000\n",
      "num_test_corrects / test_total_examples = 4751 / 6000\n",
      "testing accuracy = 0.7918\n",
      "--------- epoch: 177 ---------\n",
      "training loss = 0.4383\n",
      "training accuracy = 0.8025\n",
      "num_train_corrects / train_total_examples = 4815 / 6000\n",
      "num_test_corrects / test_total_examples = 4755 / 6000\n",
      "testing accuracy = 0.7925\n",
      "--------- epoch: 178 ---------\n",
      "training loss = 0.4381\n",
      "training accuracy = 0.8027\n",
      "num_train_corrects / train_total_examples = 4816 / 6000\n",
      "num_test_corrects / test_total_examples = 4756 / 6000\n",
      "testing accuracy = 0.7927\n",
      "--------- epoch: 179 ---------\n",
      "training loss = 0.4379\n",
      "training accuracy = 0.8027\n",
      "num_train_corrects / train_total_examples = 4816 / 6000\n",
      "num_test_corrects / test_total_examples = 4756 / 6000\n",
      "testing accuracy = 0.7927\n",
      "--------- epoch: 180 ---------\n",
      "training loss = 0.4377\n",
      "training accuracy = 0.8027\n",
      "num_train_corrects / train_total_examples = 4816 / 6000\n",
      "num_test_corrects / test_total_examples = 4756 / 6000\n",
      "testing accuracy = 0.7927\n",
      "--------- epoch: 181 ---------\n",
      "training loss = 0.4375\n",
      "training accuracy = 0.8030\n",
      "num_train_corrects / train_total_examples = 4818 / 6000\n",
      "num_test_corrects / test_total_examples = 4756 / 6000\n",
      "testing accuracy = 0.7927\n",
      "--------- epoch: 182 ---------\n",
      "training loss = 0.4373\n",
      "training accuracy = 0.8033\n",
      "num_train_corrects / train_total_examples = 4820 / 6000\n",
      "num_test_corrects / test_total_examples = 4757 / 6000\n",
      "testing accuracy = 0.7928\n",
      "--------- epoch: 183 ---------\n",
      "training loss = 0.4372\n",
      "training accuracy = 0.8035\n",
      "num_train_corrects / train_total_examples = 4821 / 6000\n",
      "num_test_corrects / test_total_examples = 4759 / 6000\n",
      "testing accuracy = 0.7932\n",
      "--------- epoch: 184 ---------\n",
      "training loss = 0.4370\n",
      "training accuracy = 0.8040\n",
      "num_train_corrects / train_total_examples = 4824 / 6000\n",
      "num_test_corrects / test_total_examples = 4761 / 6000\n",
      "testing accuracy = 0.7935\n",
      "--------- epoch: 185 ---------\n",
      "training loss = 0.4368\n",
      "training accuracy = 0.8040\n",
      "num_train_corrects / train_total_examples = 4824 / 6000\n",
      "num_test_corrects / test_total_examples = 4762 / 6000\n",
      "testing accuracy = 0.7937\n",
      "--------- epoch: 186 ---------\n",
      "training loss = 0.4366\n",
      "training accuracy = 0.8040\n",
      "num_train_corrects / train_total_examples = 4824 / 6000\n",
      "num_test_corrects / test_total_examples = 4762 / 6000\n",
      "testing accuracy = 0.7937\n",
      "--------- epoch: 187 ---------\n",
      "training loss = 0.4365\n",
      "training accuracy = 0.8042\n",
      "num_train_corrects / train_total_examples = 4825 / 6000\n",
      "num_test_corrects / test_total_examples = 4762 / 6000\n",
      "testing accuracy = 0.7937\n",
      "--------- epoch: 188 ---------\n",
      "training loss = 0.4363\n",
      "training accuracy = 0.8040\n",
      "num_train_corrects / train_total_examples = 4824 / 6000\n",
      "num_test_corrects / test_total_examples = 4763 / 6000\n",
      "testing accuracy = 0.7938\n",
      "--------- epoch: 189 ---------\n",
      "training loss = 0.4361\n",
      "training accuracy = 0.8040\n",
      "num_train_corrects / train_total_examples = 4824 / 6000\n",
      "num_test_corrects / test_total_examples = 4764 / 6000\n",
      "testing accuracy = 0.7940\n",
      "--------- epoch: 190 ---------\n",
      "training loss = 0.4359\n",
      "training accuracy = 0.8038\n",
      "num_train_corrects / train_total_examples = 4823 / 6000\n",
      "num_test_corrects / test_total_examples = 4765 / 6000\n",
      "testing accuracy = 0.7942\n",
      "--------- epoch: 191 ---------\n",
      "training loss = 0.4358\n",
      "training accuracy = 0.8042\n",
      "num_train_corrects / train_total_examples = 4825 / 6000\n",
      "num_test_corrects / test_total_examples = 4766 / 6000\n",
      "testing accuracy = 0.7943\n",
      "--------- epoch: 192 ---------\n",
      "training loss = 0.4356\n",
      "training accuracy = 0.8043\n",
      "num_train_corrects / train_total_examples = 4826 / 6000\n",
      "num_test_corrects / test_total_examples = 4767 / 6000\n",
      "testing accuracy = 0.7945\n",
      "--------- epoch: 193 ---------\n",
      "training loss = 0.4354\n",
      "training accuracy = 0.8048\n",
      "num_train_corrects / train_total_examples = 4829 / 6000\n",
      "num_test_corrects / test_total_examples = 4770 / 6000\n",
      "testing accuracy = 0.7950\n",
      "--------- epoch: 194 ---------\n",
      "training loss = 0.4353\n",
      "training accuracy = 0.8047\n",
      "num_train_corrects / train_total_examples = 4828 / 6000\n",
      "num_test_corrects / test_total_examples = 4770 / 6000\n",
      "testing accuracy = 0.7950\n",
      "--------- epoch: 195 ---------\n",
      "training loss = 0.4351\n",
      "training accuracy = 0.8047\n",
      "num_train_corrects / train_total_examples = 4828 / 6000\n",
      "num_test_corrects / test_total_examples = 4770 / 6000\n",
      "testing accuracy = 0.7950\n",
      "--------- epoch: 196 ---------\n",
      "training loss = 0.4349\n",
      "training accuracy = 0.8048\n",
      "num_train_corrects / train_total_examples = 4829 / 6000\n",
      "num_test_corrects / test_total_examples = 4771 / 6000\n",
      "testing accuracy = 0.7952\n",
      "--------- epoch: 197 ---------\n",
      "training loss = 0.4348\n",
      "training accuracy = 0.8048\n",
      "num_train_corrects / train_total_examples = 4829 / 6000\n",
      "num_test_corrects / test_total_examples = 4771 / 6000\n",
      "testing accuracy = 0.7952\n",
      "--------- epoch: 198 ---------\n",
      "training loss = 0.4346\n",
      "training accuracy = 0.8048\n",
      "num_train_corrects / train_total_examples = 4829 / 6000\n",
      "num_test_corrects / test_total_examples = 4771 / 6000\n",
      "testing accuracy = 0.7952\n",
      "--------- epoch: 199 ---------\n",
      "training loss = 0.4345\n",
      "training accuracy = 0.8048\n",
      "num_train_corrects / train_total_examples = 4829 / 6000\n",
      "num_test_corrects / test_total_examples = 4772 / 6000\n",
      "testing accuracy = 0.7953\n",
      "--------- epoch: 200 ---------\n",
      "training loss = 0.4343\n",
      "training accuracy = 0.8050\n",
      "num_train_corrects / train_total_examples = 4830 / 6000\n",
      "num_test_corrects / test_total_examples = 4774 / 6000\n",
      "testing accuracy = 0.7957\n",
      "--------- epoch: 201 ---------\n",
      "training loss = 0.4341\n",
      "training accuracy = 0.8052\n",
      "num_train_corrects / train_total_examples = 4831 / 6000\n",
      "num_test_corrects / test_total_examples = 4774 / 6000\n",
      "testing accuracy = 0.7957\n",
      "--------- epoch: 202 ---------\n",
      "training loss = 0.4340\n",
      "training accuracy = 0.8052\n",
      "num_train_corrects / train_total_examples = 4831 / 6000\n",
      "num_test_corrects / test_total_examples = 4775 / 6000\n",
      "testing accuracy = 0.7958\n",
      "--------- epoch: 203 ---------\n",
      "training loss = 0.4338\n",
      "training accuracy = 0.8057\n",
      "num_train_corrects / train_total_examples = 4834 / 6000\n",
      "num_test_corrects / test_total_examples = 4776 / 6000\n",
      "testing accuracy = 0.7960\n",
      "--------- epoch: 204 ---------\n",
      "training loss = 0.4337\n",
      "training accuracy = 0.8058\n",
      "num_train_corrects / train_total_examples = 4835 / 6000\n",
      "num_test_corrects / test_total_examples = 4778 / 6000\n",
      "testing accuracy = 0.7963\n",
      "--------- epoch: 205 ---------\n",
      "training loss = 0.4335\n",
      "training accuracy = 0.8062\n",
      "num_train_corrects / train_total_examples = 4837 / 6000\n",
      "num_test_corrects / test_total_examples = 4778 / 6000\n",
      "testing accuracy = 0.7963\n",
      "--------- epoch: 206 ---------\n",
      "training loss = 0.4334\n",
      "training accuracy = 0.8063\n",
      "num_train_corrects / train_total_examples = 4838 / 6000\n",
      "num_test_corrects / test_total_examples = 4779 / 6000\n",
      "testing accuracy = 0.7965\n",
      "--------- epoch: 207 ---------\n",
      "training loss = 0.4332\n",
      "training accuracy = 0.8063\n",
      "num_train_corrects / train_total_examples = 4838 / 6000\n",
      "num_test_corrects / test_total_examples = 4778 / 6000\n",
      "testing accuracy = 0.7963\n",
      "--------- epoch: 208 ---------\n",
      "training loss = 0.4331\n",
      "training accuracy = 0.8063\n",
      "num_train_corrects / train_total_examples = 4838 / 6000\n",
      "num_test_corrects / test_total_examples = 4779 / 6000\n",
      "testing accuracy = 0.7965\n",
      "--------- epoch: 209 ---------\n",
      "training loss = 0.4329\n",
      "training accuracy = 0.8062\n",
      "num_train_corrects / train_total_examples = 4837 / 6000\n",
      "num_test_corrects / test_total_examples = 4780 / 6000\n",
      "testing accuracy = 0.7967\n",
      "--------- epoch: 210 ---------\n",
      "training loss = 0.4328\n",
      "training accuracy = 0.8063\n",
      "num_train_corrects / train_total_examples = 4838 / 6000\n",
      "num_test_corrects / test_total_examples = 4784 / 6000\n",
      "testing accuracy = 0.7973\n",
      "--------- epoch: 211 ---------\n",
      "training loss = 0.4326\n",
      "training accuracy = 0.8062\n",
      "num_train_corrects / train_total_examples = 4837 / 6000\n",
      "num_test_corrects / test_total_examples = 4786 / 6000\n",
      "testing accuracy = 0.7977\n",
      "--------- epoch: 212 ---------\n",
      "training loss = 0.4325\n",
      "training accuracy = 0.8063\n",
      "num_train_corrects / train_total_examples = 4838 / 6000\n",
      "num_test_corrects / test_total_examples = 4790 / 6000\n",
      "testing accuracy = 0.7983\n",
      "--------- epoch: 213 ---------\n",
      "training loss = 0.4323\n",
      "training accuracy = 0.8065\n",
      "num_train_corrects / train_total_examples = 4839 / 6000\n",
      "num_test_corrects / test_total_examples = 4791 / 6000\n",
      "testing accuracy = 0.7985\n",
      "--------- epoch: 214 ---------\n",
      "training loss = 0.4322\n",
      "training accuracy = 0.8065\n",
      "num_train_corrects / train_total_examples = 4839 / 6000\n",
      "num_test_corrects / test_total_examples = 4793 / 6000\n",
      "testing accuracy = 0.7988\n",
      "--------- epoch: 215 ---------\n",
      "training loss = 0.4320\n",
      "training accuracy = 0.8070\n",
      "num_train_corrects / train_total_examples = 4842 / 6000\n",
      "num_test_corrects / test_total_examples = 4794 / 6000\n",
      "testing accuracy = 0.7990\n",
      "--------- epoch: 216 ---------\n",
      "training loss = 0.4319\n",
      "training accuracy = 0.8072\n",
      "num_train_corrects / train_total_examples = 4843 / 6000\n",
      "num_test_corrects / test_total_examples = 4795 / 6000\n",
      "testing accuracy = 0.7992\n",
      "--------- epoch: 217 ---------\n",
      "training loss = 0.4317\n",
      "training accuracy = 0.8073\n",
      "num_train_corrects / train_total_examples = 4844 / 6000\n",
      "num_test_corrects / test_total_examples = 4795 / 6000\n",
      "testing accuracy = 0.7992\n",
      "--------- epoch: 218 ---------\n",
      "training loss = 0.4316\n",
      "training accuracy = 0.8072\n",
      "num_train_corrects / train_total_examples = 4843 / 6000\n",
      "num_test_corrects / test_total_examples = 4795 / 6000\n",
      "testing accuracy = 0.7992\n",
      "--------- epoch: 219 ---------\n",
      "training loss = 0.4314\n",
      "training accuracy = 0.8070\n",
      "num_train_corrects / train_total_examples = 4842 / 6000\n",
      "num_test_corrects / test_total_examples = 4797 / 6000\n",
      "testing accuracy = 0.7995\n",
      "--------- epoch: 220 ---------\n",
      "training loss = 0.4313\n",
      "training accuracy = 0.8072\n",
      "num_train_corrects / train_total_examples = 4843 / 6000\n",
      "num_test_corrects / test_total_examples = 4798 / 6000\n",
      "testing accuracy = 0.7997\n",
      "--------- epoch: 221 ---------\n",
      "training loss = 0.4312\n",
      "training accuracy = 0.8072\n",
      "num_train_corrects / train_total_examples = 4843 / 6000\n",
      "num_test_corrects / test_total_examples = 4799 / 6000\n",
      "testing accuracy = 0.7998\n",
      "--------- epoch: 222 ---------\n",
      "training loss = 0.4310\n",
      "training accuracy = 0.8072\n",
      "num_train_corrects / train_total_examples = 4843 / 6000\n",
      "num_test_corrects / test_total_examples = 4800 / 6000\n",
      "testing accuracy = 0.8000\n",
      "--------- epoch: 223 ---------\n",
      "training loss = 0.4309\n",
      "training accuracy = 0.8072\n",
      "num_train_corrects / train_total_examples = 4843 / 6000\n",
      "num_test_corrects / test_total_examples = 4800 / 6000\n",
      "testing accuracy = 0.8000\n",
      "--------- epoch: 224 ---------\n",
      "training loss = 0.4307\n",
      "training accuracy = 0.8075\n",
      "num_train_corrects / train_total_examples = 4845 / 6000\n",
      "num_test_corrects / test_total_examples = 4800 / 6000\n",
      "testing accuracy = 0.8000\n",
      "--------- epoch: 225 ---------\n",
      "training loss = 0.4306\n",
      "training accuracy = 0.8077\n",
      "num_train_corrects / train_total_examples = 4846 / 6000\n",
      "num_test_corrects / test_total_examples = 4801 / 6000\n",
      "testing accuracy = 0.8002\n",
      "--------- epoch: 226 ---------\n",
      "training loss = 0.4305\n",
      "training accuracy = 0.8077\n",
      "num_train_corrects / train_total_examples = 4846 / 6000\n",
      "num_test_corrects / test_total_examples = 4801 / 6000\n",
      "testing accuracy = 0.8002\n",
      "--------- epoch: 227 ---------\n",
      "training loss = 0.4303\n",
      "training accuracy = 0.8078\n",
      "num_train_corrects / train_total_examples = 4847 / 6000\n",
      "num_test_corrects / test_total_examples = 4802 / 6000\n",
      "testing accuracy = 0.8003\n",
      "--------- epoch: 228 ---------\n",
      "training loss = 0.4302\n",
      "training accuracy = 0.8080\n",
      "num_train_corrects / train_total_examples = 4848 / 6000\n",
      "num_test_corrects / test_total_examples = 4802 / 6000\n",
      "testing accuracy = 0.8003\n",
      "--------- epoch: 229 ---------\n",
      "training loss = 0.4301\n",
      "training accuracy = 0.8080\n",
      "num_train_corrects / train_total_examples = 4848 / 6000\n",
      "num_test_corrects / test_total_examples = 4804 / 6000\n",
      "testing accuracy = 0.8007\n",
      "--------- epoch: 230 ---------\n",
      "training loss = 0.4299\n",
      "training accuracy = 0.8080\n",
      "num_train_corrects / train_total_examples = 4848 / 6000\n",
      "num_test_corrects / test_total_examples = 4804 / 6000\n",
      "testing accuracy = 0.8007\n",
      "--------- epoch: 231 ---------\n",
      "training loss = 0.4298\n",
      "training accuracy = 0.8082\n",
      "num_train_corrects / train_total_examples = 4849 / 6000\n",
      "num_test_corrects / test_total_examples = 4805 / 6000\n",
      "testing accuracy = 0.8008\n",
      "--------- epoch: 232 ---------\n",
      "training loss = 0.4297\n",
      "training accuracy = 0.8083\n",
      "num_train_corrects / train_total_examples = 4850 / 6000\n",
      "num_test_corrects / test_total_examples = 4805 / 6000\n",
      "testing accuracy = 0.8008\n",
      "--------- epoch: 233 ---------\n",
      "training loss = 0.4295\n",
      "training accuracy = 0.8085\n",
      "num_train_corrects / train_total_examples = 4851 / 6000\n",
      "num_test_corrects / test_total_examples = 4807 / 6000\n",
      "testing accuracy = 0.8012\n",
      "--------- epoch: 234 ---------\n",
      "training loss = 0.4294\n",
      "training accuracy = 0.8087\n",
      "num_train_corrects / train_total_examples = 4852 / 6000\n",
      "num_test_corrects / test_total_examples = 4808 / 6000\n",
      "testing accuracy = 0.8013\n",
      "--------- epoch: 235 ---------\n",
      "training loss = 0.4293\n",
      "training accuracy = 0.8090\n",
      "num_train_corrects / train_total_examples = 4854 / 6000\n",
      "num_test_corrects / test_total_examples = 4808 / 6000\n",
      "testing accuracy = 0.8013\n",
      "--------- epoch: 236 ---------\n",
      "training loss = 0.4292\n",
      "training accuracy = 0.8092\n",
      "num_train_corrects / train_total_examples = 4855 / 6000\n",
      "num_test_corrects / test_total_examples = 4809 / 6000\n",
      "testing accuracy = 0.8015\n",
      "--------- epoch: 237 ---------\n",
      "training loss = 0.4290\n",
      "training accuracy = 0.8093\n",
      "num_train_corrects / train_total_examples = 4856 / 6000\n",
      "num_test_corrects / test_total_examples = 4808 / 6000\n",
      "testing accuracy = 0.8013\n",
      "--------- epoch: 238 ---------\n",
      "training loss = 0.4289\n",
      "training accuracy = 0.8093\n",
      "num_train_corrects / train_total_examples = 4856 / 6000\n",
      "num_test_corrects / test_total_examples = 4809 / 6000\n",
      "testing accuracy = 0.8015\n",
      "--------- epoch: 239 ---------\n",
      "training loss = 0.4288\n",
      "training accuracy = 0.8095\n",
      "num_train_corrects / train_total_examples = 4857 / 6000\n",
      "num_test_corrects / test_total_examples = 4808 / 6000\n",
      "testing accuracy = 0.8013\n",
      "--------- epoch: 240 ---------\n",
      "training loss = 0.4286\n",
      "training accuracy = 0.8097\n",
      "num_train_corrects / train_total_examples = 4858 / 6000\n",
      "num_test_corrects / test_total_examples = 4807 / 6000\n",
      "testing accuracy = 0.8012\n",
      "--------- epoch: 241 ---------\n",
      "training loss = 0.4285\n",
      "training accuracy = 0.8097\n",
      "num_train_corrects / train_total_examples = 4858 / 6000\n",
      "num_test_corrects / test_total_examples = 4808 / 6000\n",
      "testing accuracy = 0.8013\n",
      "--------- epoch: 242 ---------\n",
      "training loss = 0.4284\n",
      "training accuracy = 0.8097\n",
      "num_train_corrects / train_total_examples = 4858 / 6000\n",
      "num_test_corrects / test_total_examples = 4808 / 6000\n",
      "testing accuracy = 0.8013\n",
      "--------- epoch: 243 ---------\n",
      "training loss = 0.4283\n",
      "training accuracy = 0.8097\n",
      "num_train_corrects / train_total_examples = 4858 / 6000\n",
      "num_test_corrects / test_total_examples = 4809 / 6000\n",
      "testing accuracy = 0.8015\n",
      "--------- epoch: 244 ---------\n",
      "training loss = 0.4281\n",
      "training accuracy = 0.8095\n",
      "num_train_corrects / train_total_examples = 4857 / 6000\n",
      "num_test_corrects / test_total_examples = 4809 / 6000\n",
      "testing accuracy = 0.8015\n",
      "--------- epoch: 245 ---------\n",
      "training loss = 0.4280\n",
      "training accuracy = 0.8100\n",
      "num_train_corrects / train_total_examples = 4860 / 6000\n",
      "num_test_corrects / test_total_examples = 4810 / 6000\n",
      "testing accuracy = 0.8017\n",
      "--------- epoch: 246 ---------\n",
      "training loss = 0.4279\n",
      "training accuracy = 0.8100\n",
      "num_train_corrects / train_total_examples = 4860 / 6000\n",
      "num_test_corrects / test_total_examples = 4810 / 6000\n",
      "testing accuracy = 0.8017\n",
      "--------- epoch: 247 ---------\n",
      "training loss = 0.4278\n",
      "training accuracy = 0.8102\n",
      "num_train_corrects / train_total_examples = 4861 / 6000\n",
      "num_test_corrects / test_total_examples = 4813 / 6000\n",
      "testing accuracy = 0.8022\n",
      "--------- epoch: 248 ---------\n",
      "training loss = 0.4277\n",
      "training accuracy = 0.8102\n",
      "num_train_corrects / train_total_examples = 4861 / 6000\n",
      "num_test_corrects / test_total_examples = 4814 / 6000\n",
      "testing accuracy = 0.8023\n",
      "--------- epoch: 249 ---------\n",
      "training loss = 0.4275\n",
      "training accuracy = 0.8102\n",
      "num_train_corrects / train_total_examples = 4861 / 6000\n",
      "num_test_corrects / test_total_examples = 4815 / 6000\n",
      "testing accuracy = 0.8025\n",
      "--------- epoch: 250 ---------\n",
      "training loss = 0.4274\n",
      "training accuracy = 0.8102\n",
      "num_train_corrects / train_total_examples = 4861 / 6000\n",
      "num_test_corrects / test_total_examples = 4816 / 6000\n",
      "testing accuracy = 0.8027\n",
      "--------- epoch: 251 ---------\n",
      "training loss = 0.4273\n",
      "training accuracy = 0.8102\n",
      "num_train_corrects / train_total_examples = 4861 / 6000\n",
      "num_test_corrects / test_total_examples = 4816 / 6000\n",
      "testing accuracy = 0.8027\n",
      "--------- epoch: 252 ---------\n",
      "training loss = 0.4272\n",
      "training accuracy = 0.8102\n",
      "num_train_corrects / train_total_examples = 4861 / 6000\n",
      "num_test_corrects / test_total_examples = 4816 / 6000\n",
      "testing accuracy = 0.8027\n",
      "--------- epoch: 253 ---------\n",
      "training loss = 0.4271\n",
      "training accuracy = 0.8103\n",
      "num_train_corrects / train_total_examples = 4862 / 6000\n",
      "num_test_corrects / test_total_examples = 4818 / 6000\n",
      "testing accuracy = 0.8030\n",
      "--------- epoch: 254 ---------\n",
      "training loss = 0.4269\n",
      "training accuracy = 0.8103\n",
      "num_train_corrects / train_total_examples = 4862 / 6000\n",
      "num_test_corrects / test_total_examples = 4818 / 6000\n",
      "testing accuracy = 0.8030\n",
      "--------- epoch: 255 ---------\n",
      "training loss = 0.4268\n",
      "training accuracy = 0.8105\n",
      "num_train_corrects / train_total_examples = 4863 / 6000\n",
      "num_test_corrects / test_total_examples = 4818 / 6000\n",
      "testing accuracy = 0.8030\n",
      "--------- epoch: 256 ---------\n",
      "training loss = 0.4267\n",
      "training accuracy = 0.8108\n",
      "num_train_corrects / train_total_examples = 4865 / 6000\n",
      "num_test_corrects / test_total_examples = 4818 / 6000\n",
      "testing accuracy = 0.8030\n",
      "--------- epoch: 257 ---------\n",
      "training loss = 0.4266\n",
      "training accuracy = 0.8110\n",
      "num_train_corrects / train_total_examples = 4866 / 6000\n",
      "num_test_corrects / test_total_examples = 4817 / 6000\n",
      "testing accuracy = 0.8028\n",
      "--------- epoch: 258 ---------\n",
      "training loss = 0.4265\n",
      "training accuracy = 0.8112\n",
      "num_train_corrects / train_total_examples = 4867 / 6000\n",
      "num_test_corrects / test_total_examples = 4817 / 6000\n",
      "testing accuracy = 0.8028\n",
      "--------- epoch: 259 ---------\n",
      "training loss = 0.4264\n",
      "training accuracy = 0.8115\n",
      "num_train_corrects / train_total_examples = 4869 / 6000\n",
      "num_test_corrects / test_total_examples = 4817 / 6000\n",
      "testing accuracy = 0.8028\n",
      "--------- epoch: 260 ---------\n",
      "training loss = 0.4263\n",
      "training accuracy = 0.8115\n",
      "num_train_corrects / train_total_examples = 4869 / 6000\n",
      "num_test_corrects / test_total_examples = 4818 / 6000\n",
      "testing accuracy = 0.8030\n",
      "--------- epoch: 261 ---------\n",
      "training loss = 0.4261\n",
      "training accuracy = 0.8118\n",
      "num_train_corrects / train_total_examples = 4871 / 6000\n",
      "num_test_corrects / test_total_examples = 4821 / 6000\n",
      "testing accuracy = 0.8035\n",
      "--------- epoch: 262 ---------\n",
      "training loss = 0.4260\n",
      "training accuracy = 0.8118\n",
      "num_train_corrects / train_total_examples = 4871 / 6000\n",
      "num_test_corrects / test_total_examples = 4822 / 6000\n",
      "testing accuracy = 0.8037\n",
      "--------- epoch: 263 ---------\n",
      "training loss = 0.4259\n",
      "training accuracy = 0.8122\n",
      "num_train_corrects / train_total_examples = 4873 / 6000\n",
      "num_test_corrects / test_total_examples = 4823 / 6000\n",
      "testing accuracy = 0.8038\n",
      "--------- epoch: 264 ---------\n",
      "training loss = 0.4258\n",
      "training accuracy = 0.8122\n",
      "num_train_corrects / train_total_examples = 4873 / 6000\n",
      "num_test_corrects / test_total_examples = 4824 / 6000\n",
      "testing accuracy = 0.8040\n",
      "--------- epoch: 265 ---------\n",
      "training loss = 0.4257\n",
      "training accuracy = 0.8122\n",
      "num_train_corrects / train_total_examples = 4873 / 6000\n",
      "num_test_corrects / test_total_examples = 4824 / 6000\n",
      "testing accuracy = 0.8040\n",
      "--------- epoch: 266 ---------\n",
      "training loss = 0.4256\n",
      "training accuracy = 0.8125\n",
      "num_train_corrects / train_total_examples = 4875 / 6000\n",
      "num_test_corrects / test_total_examples = 4826 / 6000\n",
      "testing accuracy = 0.8043\n",
      "--------- epoch: 267 ---------\n",
      "training loss = 0.4255\n",
      "training accuracy = 0.8128\n",
      "num_train_corrects / train_total_examples = 4877 / 6000\n",
      "num_test_corrects / test_total_examples = 4828 / 6000\n",
      "testing accuracy = 0.8047\n",
      "--------- epoch: 268 ---------\n",
      "training loss = 0.4254\n",
      "training accuracy = 0.8130\n",
      "num_train_corrects / train_total_examples = 4878 / 6000\n",
      "num_test_corrects / test_total_examples = 4828 / 6000\n",
      "testing accuracy = 0.8047\n",
      "--------- epoch: 269 ---------\n",
      "training loss = 0.4253\n",
      "training accuracy = 0.8132\n",
      "num_train_corrects / train_total_examples = 4879 / 6000\n",
      "num_test_corrects / test_total_examples = 4831 / 6000\n",
      "testing accuracy = 0.8052\n",
      "--------- epoch: 270 ---------\n",
      "training loss = 0.4252\n",
      "training accuracy = 0.8133\n",
      "num_train_corrects / train_total_examples = 4880 / 6000\n",
      "num_test_corrects / test_total_examples = 4832 / 6000\n",
      "testing accuracy = 0.8053\n",
      "--------- epoch: 271 ---------\n",
      "training loss = 0.4250\n",
      "training accuracy = 0.8133\n",
      "num_train_corrects / train_total_examples = 4880 / 6000\n",
      "num_test_corrects / test_total_examples = 4832 / 6000\n",
      "testing accuracy = 0.8053\n",
      "--------- epoch: 272 ---------\n",
      "training loss = 0.4249\n",
      "training accuracy = 0.8133\n",
      "num_train_corrects / train_total_examples = 4880 / 6000\n",
      "num_test_corrects / test_total_examples = 4832 / 6000\n",
      "testing accuracy = 0.8053\n",
      "--------- epoch: 273 ---------\n",
      "training loss = 0.4248\n",
      "training accuracy = 0.8133\n",
      "num_train_corrects / train_total_examples = 4880 / 6000\n",
      "num_test_corrects / test_total_examples = 4834 / 6000\n",
      "testing accuracy = 0.8057\n",
      "--------- epoch: 274 ---------\n",
      "training loss = 0.4247\n",
      "training accuracy = 0.8135\n",
      "num_train_corrects / train_total_examples = 4881 / 6000\n",
      "num_test_corrects / test_total_examples = 4834 / 6000\n",
      "testing accuracy = 0.8057\n",
      "--------- epoch: 275 ---------\n",
      "training loss = 0.4246\n",
      "training accuracy = 0.8135\n",
      "num_train_corrects / train_total_examples = 4881 / 6000\n",
      "num_test_corrects / test_total_examples = 4834 / 6000\n",
      "testing accuracy = 0.8057\n",
      "--------- epoch: 276 ---------\n",
      "training loss = 0.4245\n",
      "training accuracy = 0.8135\n",
      "num_train_corrects / train_total_examples = 4881 / 6000\n",
      "num_test_corrects / test_total_examples = 4835 / 6000\n",
      "testing accuracy = 0.8058\n",
      "--------- epoch: 277 ---------\n",
      "training loss = 0.4244\n",
      "training accuracy = 0.8137\n",
      "num_train_corrects / train_total_examples = 4882 / 6000\n",
      "num_test_corrects / test_total_examples = 4835 / 6000\n",
      "testing accuracy = 0.8058\n",
      "--------- epoch: 278 ---------\n",
      "training loss = 0.4243\n",
      "training accuracy = 0.8138\n",
      "num_train_corrects / train_total_examples = 4883 / 6000\n",
      "num_test_corrects / test_total_examples = 4836 / 6000\n",
      "testing accuracy = 0.8060\n",
      "--------- epoch: 279 ---------\n",
      "training loss = 0.4242\n",
      "training accuracy = 0.8138\n",
      "num_train_corrects / train_total_examples = 4883 / 6000\n",
      "num_test_corrects / test_total_examples = 4838 / 6000\n",
      "testing accuracy = 0.8063\n",
      "--------- epoch: 280 ---------\n",
      "training loss = 0.4241\n",
      "training accuracy = 0.8138\n",
      "num_train_corrects / train_total_examples = 4883 / 6000\n",
      "num_test_corrects / test_total_examples = 4839 / 6000\n",
      "testing accuracy = 0.8065\n",
      "--------- epoch: 281 ---------\n",
      "training loss = 0.4240\n",
      "training accuracy = 0.8140\n",
      "num_train_corrects / train_total_examples = 4884 / 6000\n",
      "num_test_corrects / test_total_examples = 4839 / 6000\n",
      "testing accuracy = 0.8065\n",
      "--------- epoch: 282 ---------\n",
      "training loss = 0.4239\n",
      "training accuracy = 0.8140\n",
      "num_train_corrects / train_total_examples = 4884 / 6000\n",
      "num_test_corrects / test_total_examples = 4839 / 6000\n",
      "testing accuracy = 0.8065\n",
      "--------- epoch: 283 ---------\n",
      "training loss = 0.4238\n",
      "training accuracy = 0.8140\n",
      "num_train_corrects / train_total_examples = 4884 / 6000\n",
      "num_test_corrects / test_total_examples = 4839 / 6000\n",
      "testing accuracy = 0.8065\n",
      "--------- epoch: 284 ---------\n",
      "training loss = 0.4237\n",
      "training accuracy = 0.8140\n",
      "num_train_corrects / train_total_examples = 4884 / 6000\n",
      "num_test_corrects / test_total_examples = 4839 / 6000\n",
      "testing accuracy = 0.8065\n",
      "--------- epoch: 285 ---------\n",
      "training loss = 0.4236\n",
      "training accuracy = 0.8140\n",
      "num_train_corrects / train_total_examples = 4884 / 6000\n",
      "num_test_corrects / test_total_examples = 4839 / 6000\n",
      "testing accuracy = 0.8065\n",
      "--------- epoch: 286 ---------\n",
      "training loss = 0.4235\n",
      "training accuracy = 0.8140\n",
      "num_train_corrects / train_total_examples = 4884 / 6000\n",
      "num_test_corrects / test_total_examples = 4840 / 6000\n",
      "testing accuracy = 0.8067\n",
      "--------- epoch: 287 ---------\n",
      "training loss = 0.4234\n",
      "training accuracy = 0.8137\n",
      "num_train_corrects / train_total_examples = 4882 / 6000\n",
      "num_test_corrects / test_total_examples = 4841 / 6000\n",
      "testing accuracy = 0.8068\n",
      "--------- epoch: 288 ---------\n",
      "training loss = 0.4233\n",
      "training accuracy = 0.8142\n",
      "num_train_corrects / train_total_examples = 4885 / 6000\n",
      "num_test_corrects / test_total_examples = 4842 / 6000\n",
      "testing accuracy = 0.8070\n",
      "--------- epoch: 289 ---------\n",
      "training loss = 0.4232\n",
      "training accuracy = 0.8143\n",
      "num_train_corrects / train_total_examples = 4886 / 6000\n",
      "num_test_corrects / test_total_examples = 4842 / 6000\n",
      "testing accuracy = 0.8070\n",
      "--------- epoch: 290 ---------\n",
      "training loss = 0.4231\n",
      "training accuracy = 0.8143\n",
      "num_train_corrects / train_total_examples = 4886 / 6000\n",
      "num_test_corrects / test_total_examples = 4842 / 6000\n",
      "testing accuracy = 0.8070\n",
      "--------- epoch: 291 ---------\n",
      "training loss = 0.4230\n",
      "training accuracy = 0.8147\n",
      "num_train_corrects / train_total_examples = 4888 / 6000\n",
      "num_test_corrects / test_total_examples = 4845 / 6000\n",
      "testing accuracy = 0.8075\n",
      "--------- epoch: 292 ---------\n",
      "training loss = 0.4229\n",
      "training accuracy = 0.8150\n",
      "num_train_corrects / train_total_examples = 4890 / 6000\n",
      "num_test_corrects / test_total_examples = 4845 / 6000\n",
      "testing accuracy = 0.8075\n",
      "--------- epoch: 293 ---------\n",
      "training loss = 0.4228\n",
      "training accuracy = 0.8152\n",
      "num_train_corrects / train_total_examples = 4891 / 6000\n",
      "num_test_corrects / test_total_examples = 4848 / 6000\n",
      "testing accuracy = 0.8080\n",
      "--------- epoch: 294 ---------\n",
      "training loss = 0.4227\n",
      "training accuracy = 0.8152\n",
      "num_train_corrects / train_total_examples = 4891 / 6000\n",
      "num_test_corrects / test_total_examples = 4848 / 6000\n",
      "testing accuracy = 0.8080\n",
      "--------- epoch: 295 ---------\n",
      "training loss = 0.4226\n",
      "training accuracy = 0.8153\n",
      "num_train_corrects / train_total_examples = 4892 / 6000\n",
      "num_test_corrects / test_total_examples = 4848 / 6000\n",
      "testing accuracy = 0.8080\n",
      "--------- epoch: 296 ---------\n",
      "training loss = 0.4225\n",
      "training accuracy = 0.8153\n",
      "num_train_corrects / train_total_examples = 4892 / 6000\n",
      "num_test_corrects / test_total_examples = 4848 / 6000\n",
      "testing accuracy = 0.8080\n",
      "--------- epoch: 297 ---------\n",
      "training loss = 0.4224\n",
      "training accuracy = 0.8155\n",
      "num_train_corrects / train_total_examples = 4893 / 6000\n",
      "num_test_corrects / test_total_examples = 4848 / 6000\n",
      "testing accuracy = 0.8080\n",
      "--------- epoch: 298 ---------\n",
      "training loss = 0.4223\n",
      "training accuracy = 0.8155\n",
      "num_train_corrects / train_total_examples = 4893 / 6000\n",
      "num_test_corrects / test_total_examples = 4848 / 6000\n",
      "testing accuracy = 0.8080\n",
      "--------- epoch: 299 ---------\n",
      "training loss = 0.4222\n",
      "training accuracy = 0.8155\n",
      "num_train_corrects / train_total_examples = 4893 / 6000\n",
      "num_test_corrects / test_total_examples = 4848 / 6000\n",
      "testing accuracy = 0.8080\n",
      "--------- epoch: 300 ---------\n",
      "training loss = 0.4221\n",
      "training accuracy = 0.8153\n",
      "num_train_corrects / train_total_examples = 4892 / 6000\n",
      "num_test_corrects / test_total_examples = 4848 / 6000\n",
      "testing accuracy = 0.8080\n",
      "--------- epoch: 301 ---------\n",
      "training loss = 0.4220\n",
      "training accuracy = 0.8152\n",
      "num_train_corrects / train_total_examples = 4891 / 6000\n",
      "num_test_corrects / test_total_examples = 4848 / 6000\n",
      "testing accuracy = 0.8080\n",
      "--------- epoch: 302 ---------\n",
      "training loss = 0.4219\n",
      "training accuracy = 0.8153\n",
      "num_train_corrects / train_total_examples = 4892 / 6000\n",
      "num_test_corrects / test_total_examples = 4848 / 6000\n",
      "testing accuracy = 0.8080\n",
      "--------- epoch: 303 ---------\n",
      "training loss = 0.4219\n",
      "training accuracy = 0.8153\n",
      "num_train_corrects / train_total_examples = 4892 / 6000\n",
      "num_test_corrects / test_total_examples = 4848 / 6000\n",
      "testing accuracy = 0.8080\n",
      "--------- epoch: 304 ---------\n",
      "training loss = 0.4218\n",
      "training accuracy = 0.8155\n",
      "num_train_corrects / train_total_examples = 4893 / 6000\n",
      "num_test_corrects / test_total_examples = 4848 / 6000\n",
      "testing accuracy = 0.8080\n",
      "--------- epoch: 305 ---------\n",
      "training loss = 0.4217\n",
      "training accuracy = 0.8157\n",
      "num_train_corrects / train_total_examples = 4894 / 6000\n",
      "num_test_corrects / test_total_examples = 4849 / 6000\n",
      "testing accuracy = 0.8082\n",
      "--------- epoch: 306 ---------\n",
      "training loss = 0.4216\n",
      "training accuracy = 0.8157\n",
      "num_train_corrects / train_total_examples = 4894 / 6000\n",
      "num_test_corrects / test_total_examples = 4849 / 6000\n",
      "testing accuracy = 0.8082\n",
      "--------- epoch: 307 ---------\n",
      "training loss = 0.4215\n",
      "training accuracy = 0.8157\n",
      "num_train_corrects / train_total_examples = 4894 / 6000\n",
      "num_test_corrects / test_total_examples = 4849 / 6000\n",
      "testing accuracy = 0.8082\n",
      "--------- epoch: 308 ---------\n",
      "training loss = 0.4214\n",
      "training accuracy = 0.8157\n",
      "num_train_corrects / train_total_examples = 4894 / 6000\n",
      "num_test_corrects / test_total_examples = 4849 / 6000\n",
      "testing accuracy = 0.8082\n",
      "--------- epoch: 309 ---------\n",
      "training loss = 0.4213\n",
      "training accuracy = 0.8160\n",
      "num_train_corrects / train_total_examples = 4896 / 6000\n",
      "num_test_corrects / test_total_examples = 4851 / 6000\n",
      "testing accuracy = 0.8085\n",
      "--------- epoch: 310 ---------\n",
      "training loss = 0.4212\n",
      "training accuracy = 0.8160\n",
      "num_train_corrects / train_total_examples = 4896 / 6000\n",
      "num_test_corrects / test_total_examples = 4851 / 6000\n",
      "testing accuracy = 0.8085\n",
      "--------- epoch: 311 ---------\n",
      "training loss = 0.4211\n",
      "training accuracy = 0.8162\n",
      "num_train_corrects / train_total_examples = 4897 / 6000\n",
      "num_test_corrects / test_total_examples = 4851 / 6000\n",
      "testing accuracy = 0.8085\n",
      "--------- epoch: 312 ---------\n",
      "training loss = 0.4210\n",
      "training accuracy = 0.8162\n",
      "num_train_corrects / train_total_examples = 4897 / 6000\n",
      "num_test_corrects / test_total_examples = 4852 / 6000\n",
      "testing accuracy = 0.8087\n",
      "--------- epoch: 313 ---------\n",
      "training loss = 0.4209\n",
      "training accuracy = 0.8162\n",
      "num_train_corrects / train_total_examples = 4897 / 6000\n",
      "num_test_corrects / test_total_examples = 4852 / 6000\n",
      "testing accuracy = 0.8087\n",
      "--------- epoch: 314 ---------\n",
      "training loss = 0.4209\n",
      "training accuracy = 0.8162\n",
      "num_train_corrects / train_total_examples = 4897 / 6000\n",
      "num_test_corrects / test_total_examples = 4852 / 6000\n",
      "testing accuracy = 0.8087\n",
      "--------- epoch: 315 ---------\n",
      "training loss = 0.4208\n",
      "training accuracy = 0.8162\n",
      "num_train_corrects / train_total_examples = 4897 / 6000\n",
      "num_test_corrects / test_total_examples = 4855 / 6000\n",
      "testing accuracy = 0.8092\n",
      "--------- epoch: 316 ---------\n",
      "training loss = 0.4207\n",
      "training accuracy = 0.8160\n",
      "num_train_corrects / train_total_examples = 4896 / 6000\n",
      "num_test_corrects / test_total_examples = 4856 / 6000\n",
      "testing accuracy = 0.8093\n",
      "--------- epoch: 317 ---------\n",
      "training loss = 0.4206\n",
      "training accuracy = 0.8160\n",
      "num_train_corrects / train_total_examples = 4896 / 6000\n",
      "num_test_corrects / test_total_examples = 4857 / 6000\n",
      "testing accuracy = 0.8095\n",
      "--------- epoch: 318 ---------\n",
      "training loss = 0.4205\n",
      "training accuracy = 0.8160\n",
      "num_train_corrects / train_total_examples = 4896 / 6000\n",
      "num_test_corrects / test_total_examples = 4859 / 6000\n",
      "testing accuracy = 0.8098\n",
      "--------- epoch: 319 ---------\n",
      "training loss = 0.4204\n",
      "training accuracy = 0.8163\n",
      "num_train_corrects / train_total_examples = 4898 / 6000\n",
      "num_test_corrects / test_total_examples = 4860 / 6000\n",
      "testing accuracy = 0.8100\n",
      "--------- epoch: 320 ---------\n",
      "training loss = 0.4203\n",
      "training accuracy = 0.8165\n",
      "num_train_corrects / train_total_examples = 4899 / 6000\n",
      "num_test_corrects / test_total_examples = 4860 / 6000\n",
      "testing accuracy = 0.8100\n",
      "--------- epoch: 321 ---------\n",
      "training loss = 0.4202\n",
      "training accuracy = 0.8165\n",
      "num_train_corrects / train_total_examples = 4899 / 6000\n",
      "num_test_corrects / test_total_examples = 4862 / 6000\n",
      "testing accuracy = 0.8103\n",
      "--------- epoch: 322 ---------\n",
      "training loss = 0.4202\n",
      "training accuracy = 0.8167\n",
      "num_train_corrects / train_total_examples = 4900 / 6000\n",
      "num_test_corrects / test_total_examples = 4862 / 6000\n",
      "testing accuracy = 0.8103\n",
      "--------- epoch: 323 ---------\n",
      "training loss = 0.4201\n",
      "training accuracy = 0.8170\n",
      "num_train_corrects / train_total_examples = 4902 / 6000\n",
      "num_test_corrects / test_total_examples = 4862 / 6000\n",
      "testing accuracy = 0.8103\n",
      "--------- epoch: 324 ---------\n",
      "training loss = 0.4200\n",
      "training accuracy = 0.8170\n",
      "num_train_corrects / train_total_examples = 4902 / 6000\n",
      "num_test_corrects / test_total_examples = 4862 / 6000\n",
      "testing accuracy = 0.8103\n",
      "--------- epoch: 325 ---------\n",
      "training loss = 0.4199\n",
      "training accuracy = 0.8172\n",
      "num_train_corrects / train_total_examples = 4903 / 6000\n",
      "num_test_corrects / test_total_examples = 4863 / 6000\n",
      "testing accuracy = 0.8105\n",
      "--------- epoch: 326 ---------\n",
      "training loss = 0.4198\n",
      "training accuracy = 0.8172\n",
      "num_train_corrects / train_total_examples = 4903 / 6000\n",
      "num_test_corrects / test_total_examples = 4863 / 6000\n",
      "testing accuracy = 0.8105\n",
      "--------- epoch: 327 ---------\n",
      "training loss = 0.4197\n",
      "training accuracy = 0.8173\n",
      "num_train_corrects / train_total_examples = 4904 / 6000\n",
      "num_test_corrects / test_total_examples = 4864 / 6000\n",
      "testing accuracy = 0.8107\n",
      "--------- epoch: 328 ---------\n",
      "training loss = 0.4196\n",
      "training accuracy = 0.8173\n",
      "num_train_corrects / train_total_examples = 4904 / 6000\n",
      "num_test_corrects / test_total_examples = 4864 / 6000\n",
      "testing accuracy = 0.8107\n",
      "--------- epoch: 329 ---------\n",
      "training loss = 0.4196\n",
      "training accuracy = 0.8177\n",
      "num_train_corrects / train_total_examples = 4906 / 6000\n",
      "num_test_corrects / test_total_examples = 4864 / 6000\n",
      "testing accuracy = 0.8107\n",
      "--------- epoch: 330 ---------\n",
      "training loss = 0.4195\n",
      "training accuracy = 0.8177\n",
      "num_train_corrects / train_total_examples = 4906 / 6000\n",
      "num_test_corrects / test_total_examples = 4864 / 6000\n",
      "testing accuracy = 0.8107\n",
      "--------- epoch: 331 ---------\n",
      "training loss = 0.4194\n",
      "training accuracy = 0.8178\n",
      "num_train_corrects / train_total_examples = 4907 / 6000\n",
      "num_test_corrects / test_total_examples = 4864 / 6000\n",
      "testing accuracy = 0.8107\n",
      "--------- epoch: 332 ---------\n",
      "training loss = 0.4193\n",
      "training accuracy = 0.8178\n",
      "num_train_corrects / train_total_examples = 4907 / 6000\n",
      "num_test_corrects / test_total_examples = 4864 / 6000\n",
      "testing accuracy = 0.8107\n",
      "--------- epoch: 333 ---------\n",
      "training loss = 0.4192\n",
      "training accuracy = 0.8182\n",
      "num_train_corrects / train_total_examples = 4909 / 6000\n",
      "num_test_corrects / test_total_examples = 4864 / 6000\n",
      "testing accuracy = 0.8107\n",
      "--------- epoch: 334 ---------\n",
      "training loss = 0.4191\n",
      "training accuracy = 0.8183\n",
      "num_train_corrects / train_total_examples = 4910 / 6000\n",
      "num_test_corrects / test_total_examples = 4866 / 6000\n",
      "testing accuracy = 0.8110\n",
      "--------- epoch: 335 ---------\n",
      "training loss = 0.4191\n",
      "training accuracy = 0.8183\n",
      "num_train_corrects / train_total_examples = 4910 / 6000\n",
      "num_test_corrects / test_total_examples = 4866 / 6000\n",
      "testing accuracy = 0.8110\n",
      "--------- epoch: 336 ---------\n",
      "training loss = 0.4190\n",
      "training accuracy = 0.8183\n",
      "num_train_corrects / train_total_examples = 4910 / 6000\n",
      "num_test_corrects / test_total_examples = 4866 / 6000\n",
      "testing accuracy = 0.8110\n",
      "--------- epoch: 337 ---------\n",
      "training loss = 0.4189\n",
      "training accuracy = 0.8185\n",
      "num_train_corrects / train_total_examples = 4911 / 6000\n",
      "num_test_corrects / test_total_examples = 4866 / 6000\n",
      "testing accuracy = 0.8110\n",
      "--------- epoch: 338 ---------\n",
      "training loss = 0.4188\n",
      "training accuracy = 0.8185\n",
      "num_train_corrects / train_total_examples = 4911 / 6000\n",
      "num_test_corrects / test_total_examples = 4867 / 6000\n",
      "testing accuracy = 0.8112\n",
      "--------- epoch: 339 ---------\n",
      "training loss = 0.4187\n",
      "training accuracy = 0.8187\n",
      "num_train_corrects / train_total_examples = 4912 / 6000\n",
      "num_test_corrects / test_total_examples = 4867 / 6000\n",
      "testing accuracy = 0.8112\n",
      "--------- epoch: 340 ---------\n",
      "training loss = 0.4187\n",
      "training accuracy = 0.8187\n",
      "num_train_corrects / train_total_examples = 4912 / 6000\n",
      "num_test_corrects / test_total_examples = 4867 / 6000\n",
      "testing accuracy = 0.8112\n",
      "--------- epoch: 341 ---------\n",
      "training loss = 0.4186\n",
      "training accuracy = 0.8188\n",
      "num_train_corrects / train_total_examples = 4913 / 6000\n",
      "num_test_corrects / test_total_examples = 4868 / 6000\n",
      "testing accuracy = 0.8113\n",
      "--------- epoch: 342 ---------\n",
      "training loss = 0.4185\n",
      "training accuracy = 0.8188\n",
      "num_train_corrects / train_total_examples = 4913 / 6000\n",
      "num_test_corrects / test_total_examples = 4868 / 6000\n",
      "testing accuracy = 0.8113\n",
      "--------- epoch: 343 ---------\n",
      "training loss = 0.4184\n",
      "training accuracy = 0.8193\n",
      "num_train_corrects / train_total_examples = 4916 / 6000\n",
      "num_test_corrects / test_total_examples = 4869 / 6000\n",
      "testing accuracy = 0.8115\n",
      "--------- epoch: 344 ---------\n",
      "training loss = 0.4183\n",
      "training accuracy = 0.8192\n",
      "num_train_corrects / train_total_examples = 4915 / 6000\n",
      "num_test_corrects / test_total_examples = 4869 / 6000\n",
      "testing accuracy = 0.8115\n",
      "--------- epoch: 345 ---------\n",
      "training loss = 0.4183\n",
      "training accuracy = 0.8193\n",
      "num_train_corrects / train_total_examples = 4916 / 6000\n",
      "num_test_corrects / test_total_examples = 4870 / 6000\n",
      "testing accuracy = 0.8117\n",
      "--------- epoch: 346 ---------\n",
      "training loss = 0.4182\n",
      "training accuracy = 0.8193\n",
      "num_train_corrects / train_total_examples = 4916 / 6000\n",
      "num_test_corrects / test_total_examples = 4870 / 6000\n",
      "testing accuracy = 0.8117\n",
      "--------- epoch: 347 ---------\n",
      "training loss = 0.4181\n",
      "training accuracy = 0.8195\n",
      "num_train_corrects / train_total_examples = 4917 / 6000\n",
      "num_test_corrects / test_total_examples = 4869 / 6000\n",
      "testing accuracy = 0.8115\n",
      "--------- epoch: 348 ---------\n",
      "training loss = 0.4180\n",
      "training accuracy = 0.8195\n",
      "num_train_corrects / train_total_examples = 4917 / 6000\n",
      "num_test_corrects / test_total_examples = 4869 / 6000\n",
      "testing accuracy = 0.8115\n",
      "--------- epoch: 349 ---------\n",
      "training loss = 0.4179\n",
      "training accuracy = 0.8197\n",
      "num_train_corrects / train_total_examples = 4918 / 6000\n",
      "num_test_corrects / test_total_examples = 4869 / 6000\n",
      "testing accuracy = 0.8115\n",
      "--------- epoch: 350 ---------\n",
      "training loss = 0.4179\n",
      "training accuracy = 0.8197\n",
      "num_train_corrects / train_total_examples = 4918 / 6000\n",
      "num_test_corrects / test_total_examples = 4870 / 6000\n",
      "testing accuracy = 0.8117\n",
      "--------- epoch: 351 ---------\n",
      "training loss = 0.4178\n",
      "training accuracy = 0.8198\n",
      "num_train_corrects / train_total_examples = 4919 / 6000\n",
      "num_test_corrects / test_total_examples = 4870 / 6000\n",
      "testing accuracy = 0.8117\n",
      "--------- epoch: 352 ---------\n",
      "training loss = 0.4177\n",
      "training accuracy = 0.8202\n",
      "num_train_corrects / train_total_examples = 4921 / 6000\n",
      "num_test_corrects / test_total_examples = 4869 / 6000\n",
      "testing accuracy = 0.8115\n",
      "--------- epoch: 353 ---------\n",
      "training loss = 0.4176\n",
      "training accuracy = 0.8202\n",
      "num_train_corrects / train_total_examples = 4921 / 6000\n",
      "num_test_corrects / test_total_examples = 4869 / 6000\n",
      "testing accuracy = 0.8115\n",
      "--------- epoch: 354 ---------\n",
      "training loss = 0.4176\n",
      "training accuracy = 0.8202\n",
      "num_train_corrects / train_total_examples = 4921 / 6000\n",
      "num_test_corrects / test_total_examples = 4869 / 6000\n",
      "testing accuracy = 0.8115\n",
      "--------- epoch: 355 ---------\n",
      "training loss = 0.4175\n",
      "training accuracy = 0.8203\n",
      "num_train_corrects / train_total_examples = 4922 / 6000\n",
      "num_test_corrects / test_total_examples = 4869 / 6000\n",
      "testing accuracy = 0.8115\n",
      "--------- epoch: 356 ---------\n",
      "training loss = 0.4174\n",
      "training accuracy = 0.8203\n",
      "num_train_corrects / train_total_examples = 4922 / 6000\n",
      "num_test_corrects / test_total_examples = 4869 / 6000\n",
      "testing accuracy = 0.8115\n",
      "--------- epoch: 357 ---------\n",
      "training loss = 0.4173\n",
      "training accuracy = 0.8205\n",
      "num_train_corrects / train_total_examples = 4923 / 6000\n",
      "num_test_corrects / test_total_examples = 4870 / 6000\n",
      "testing accuracy = 0.8117\n",
      "--------- epoch: 358 ---------\n",
      "training loss = 0.4172\n",
      "training accuracy = 0.8207\n",
      "num_train_corrects / train_total_examples = 4924 / 6000\n",
      "num_test_corrects / test_total_examples = 4870 / 6000\n",
      "testing accuracy = 0.8117\n",
      "--------- epoch: 359 ---------\n",
      "training loss = 0.4172\n",
      "training accuracy = 0.8207\n",
      "num_train_corrects / train_total_examples = 4924 / 6000\n",
      "num_test_corrects / test_total_examples = 4870 / 6000\n",
      "testing accuracy = 0.8117\n",
      "--------- epoch: 360 ---------\n",
      "training loss = 0.4171\n",
      "training accuracy = 0.8208\n",
      "num_train_corrects / train_total_examples = 4925 / 6000\n",
      "num_test_corrects / test_total_examples = 4870 / 6000\n",
      "testing accuracy = 0.8117\n",
      "--------- epoch: 361 ---------\n",
      "training loss = 0.4170\n",
      "training accuracy = 0.8208\n",
      "num_train_corrects / train_total_examples = 4925 / 6000\n",
      "num_test_corrects / test_total_examples = 4870 / 6000\n",
      "testing accuracy = 0.8117\n",
      "--------- epoch: 362 ---------\n",
      "training loss = 0.4169\n",
      "training accuracy = 0.8208\n",
      "num_train_corrects / train_total_examples = 4925 / 6000\n",
      "num_test_corrects / test_total_examples = 4869 / 6000\n",
      "testing accuracy = 0.8115\n",
      "--------- epoch: 363 ---------\n",
      "training loss = 0.4169\n",
      "training accuracy = 0.8208\n",
      "num_train_corrects / train_total_examples = 4925 / 6000\n",
      "num_test_corrects / test_total_examples = 4869 / 6000\n",
      "testing accuracy = 0.8115\n",
      "--------- epoch: 364 ---------\n",
      "training loss = 0.4168\n",
      "training accuracy = 0.8210\n",
      "num_train_corrects / train_total_examples = 4926 / 6000\n",
      "num_test_corrects / test_total_examples = 4869 / 6000\n",
      "testing accuracy = 0.8115\n",
      "--------- epoch: 365 ---------\n",
      "training loss = 0.4167\n",
      "training accuracy = 0.8212\n",
      "num_train_corrects / train_total_examples = 4927 / 6000\n",
      "num_test_corrects / test_total_examples = 4869 / 6000\n",
      "testing accuracy = 0.8115\n",
      "--------- epoch: 366 ---------\n",
      "training loss = 0.4167\n",
      "training accuracy = 0.8215\n",
      "num_train_corrects / train_total_examples = 4929 / 6000\n",
      "num_test_corrects / test_total_examples = 4871 / 6000\n",
      "testing accuracy = 0.8118\n",
      "--------- epoch: 367 ---------\n",
      "training loss = 0.4166\n",
      "training accuracy = 0.8215\n",
      "num_train_corrects / train_total_examples = 4929 / 6000\n",
      "num_test_corrects / test_total_examples = 4871 / 6000\n",
      "testing accuracy = 0.8118\n",
      "--------- epoch: 368 ---------\n",
      "training loss = 0.4165\n",
      "training accuracy = 0.8215\n",
      "num_train_corrects / train_total_examples = 4929 / 6000\n",
      "num_test_corrects / test_total_examples = 4872 / 6000\n",
      "testing accuracy = 0.8120\n",
      "--------- epoch: 369 ---------\n",
      "training loss = 0.4164\n",
      "training accuracy = 0.8215\n",
      "num_train_corrects / train_total_examples = 4929 / 6000\n",
      "num_test_corrects / test_total_examples = 4872 / 6000\n",
      "testing accuracy = 0.8120\n",
      "--------- epoch: 370 ---------\n",
      "training loss = 0.4164\n",
      "training accuracy = 0.8213\n",
      "num_train_corrects / train_total_examples = 4928 / 6000\n",
      "num_test_corrects / test_total_examples = 4872 / 6000\n",
      "testing accuracy = 0.8120\n",
      "--------- epoch: 371 ---------\n",
      "training loss = 0.4163\n",
      "training accuracy = 0.8213\n",
      "num_train_corrects / train_total_examples = 4928 / 6000\n",
      "num_test_corrects / test_total_examples = 4872 / 6000\n",
      "testing accuracy = 0.8120\n",
      "--------- epoch: 372 ---------\n",
      "training loss = 0.4162\n",
      "training accuracy = 0.8213\n",
      "num_train_corrects / train_total_examples = 4928 / 6000\n",
      "num_test_corrects / test_total_examples = 4873 / 6000\n",
      "testing accuracy = 0.8122\n",
      "--------- epoch: 373 ---------\n",
      "training loss = 0.4161\n",
      "training accuracy = 0.8213\n",
      "num_train_corrects / train_total_examples = 4928 / 6000\n",
      "num_test_corrects / test_total_examples = 4873 / 6000\n",
      "testing accuracy = 0.8122\n",
      "--------- epoch: 374 ---------\n",
      "training loss = 0.4161\n",
      "training accuracy = 0.8215\n",
      "num_train_corrects / train_total_examples = 4929 / 6000\n",
      "num_test_corrects / test_total_examples = 4873 / 6000\n",
      "testing accuracy = 0.8122\n",
      "--------- epoch: 375 ---------\n",
      "training loss = 0.4160\n",
      "training accuracy = 0.8215\n",
      "num_train_corrects / train_total_examples = 4929 / 6000\n",
      "num_test_corrects / test_total_examples = 4873 / 6000\n",
      "testing accuracy = 0.8122\n",
      "--------- epoch: 376 ---------\n",
      "training loss = 0.4159\n",
      "training accuracy = 0.8217\n",
      "num_train_corrects / train_total_examples = 4930 / 6000\n",
      "num_test_corrects / test_total_examples = 4873 / 6000\n",
      "testing accuracy = 0.8122\n",
      "--------- epoch: 377 ---------\n",
      "training loss = 0.4159\n",
      "training accuracy = 0.8217\n",
      "num_train_corrects / train_total_examples = 4930 / 6000\n",
      "num_test_corrects / test_total_examples = 4873 / 6000\n",
      "testing accuracy = 0.8122\n",
      "--------- epoch: 378 ---------\n",
      "training loss = 0.4158\n",
      "training accuracy = 0.8217\n",
      "num_train_corrects / train_total_examples = 4930 / 6000\n",
      "num_test_corrects / test_total_examples = 4874 / 6000\n",
      "testing accuracy = 0.8123\n",
      "--------- epoch: 379 ---------\n",
      "training loss = 0.4157\n",
      "training accuracy = 0.8217\n",
      "num_train_corrects / train_total_examples = 4930 / 6000\n",
      "num_test_corrects / test_total_examples = 4875 / 6000\n",
      "testing accuracy = 0.8125\n",
      "--------- epoch: 380 ---------\n",
      "training loss = 0.4156\n",
      "training accuracy = 0.8215\n",
      "num_train_corrects / train_total_examples = 4929 / 6000\n",
      "num_test_corrects / test_total_examples = 4875 / 6000\n",
      "testing accuracy = 0.8125\n",
      "--------- epoch: 381 ---------\n",
      "training loss = 0.4156\n",
      "training accuracy = 0.8215\n",
      "num_train_corrects / train_total_examples = 4929 / 6000\n",
      "num_test_corrects / test_total_examples = 4876 / 6000\n",
      "testing accuracy = 0.8127\n",
      "--------- epoch: 382 ---------\n",
      "training loss = 0.4155\n",
      "training accuracy = 0.8215\n",
      "num_train_corrects / train_total_examples = 4929 / 6000\n",
      "num_test_corrects / test_total_examples = 4876 / 6000\n",
      "testing accuracy = 0.8127\n",
      "--------- epoch: 383 ---------\n",
      "training loss = 0.4154\n",
      "training accuracy = 0.8215\n",
      "num_train_corrects / train_total_examples = 4929 / 6000\n",
      "num_test_corrects / test_total_examples = 4877 / 6000\n",
      "testing accuracy = 0.8128\n",
      "--------- epoch: 384 ---------\n",
      "training loss = 0.4154\n",
      "training accuracy = 0.8215\n",
      "num_train_corrects / train_total_examples = 4929 / 6000\n",
      "num_test_corrects / test_total_examples = 4879 / 6000\n",
      "testing accuracy = 0.8132\n",
      "--------- epoch: 385 ---------\n",
      "training loss = 0.4153\n",
      "training accuracy = 0.8215\n",
      "num_train_corrects / train_total_examples = 4929 / 6000\n",
      "num_test_corrects / test_total_examples = 4879 / 6000\n",
      "testing accuracy = 0.8132\n",
      "--------- epoch: 386 ---------\n",
      "training loss = 0.4152\n",
      "training accuracy = 0.8217\n",
      "num_train_corrects / train_total_examples = 4930 / 6000\n",
      "num_test_corrects / test_total_examples = 4878 / 6000\n",
      "testing accuracy = 0.8130\n",
      "--------- epoch: 387 ---------\n",
      "training loss = 0.4152\n",
      "training accuracy = 0.8218\n",
      "num_train_corrects / train_total_examples = 4931 / 6000\n",
      "num_test_corrects / test_total_examples = 4879 / 6000\n",
      "testing accuracy = 0.8132\n",
      "--------- epoch: 388 ---------\n",
      "training loss = 0.4151\n",
      "training accuracy = 0.8218\n",
      "num_train_corrects / train_total_examples = 4931 / 6000\n",
      "num_test_corrects / test_total_examples = 4879 / 6000\n",
      "testing accuracy = 0.8132\n",
      "--------- epoch: 389 ---------\n",
      "training loss = 0.4150\n",
      "training accuracy = 0.8218\n",
      "num_train_corrects / train_total_examples = 4931 / 6000\n",
      "num_test_corrects / test_total_examples = 4879 / 6000\n",
      "testing accuracy = 0.8132\n",
      "--------- epoch: 390 ---------\n",
      "training loss = 0.4150\n",
      "training accuracy = 0.8220\n",
      "num_train_corrects / train_total_examples = 4932 / 6000\n",
      "num_test_corrects / test_total_examples = 4879 / 6000\n",
      "testing accuracy = 0.8132\n",
      "--------- epoch: 391 ---------\n",
      "training loss = 0.4149\n",
      "training accuracy = 0.8225\n",
      "num_train_corrects / train_total_examples = 4935 / 6000\n",
      "num_test_corrects / test_total_examples = 4880 / 6000\n",
      "testing accuracy = 0.8133\n",
      "--------- epoch: 392 ---------\n",
      "training loss = 0.4148\n",
      "training accuracy = 0.8225\n",
      "num_train_corrects / train_total_examples = 4935 / 6000\n",
      "num_test_corrects / test_total_examples = 4880 / 6000\n",
      "testing accuracy = 0.8133\n",
      "--------- epoch: 393 ---------\n",
      "training loss = 0.4147\n",
      "training accuracy = 0.8225\n",
      "num_train_corrects / train_total_examples = 4935 / 6000\n",
      "num_test_corrects / test_total_examples = 4882 / 6000\n",
      "testing accuracy = 0.8137\n",
      "--------- epoch: 394 ---------\n",
      "training loss = 0.4147\n",
      "training accuracy = 0.8225\n",
      "num_train_corrects / train_total_examples = 4935 / 6000\n",
      "num_test_corrects / test_total_examples = 4882 / 6000\n",
      "testing accuracy = 0.8137\n",
      "--------- epoch: 395 ---------\n",
      "training loss = 0.4146\n",
      "training accuracy = 0.8225\n",
      "num_train_corrects / train_total_examples = 4935 / 6000\n",
      "num_test_corrects / test_total_examples = 4882 / 6000\n",
      "testing accuracy = 0.8137\n",
      "--------- epoch: 396 ---------\n",
      "training loss = 0.4145\n",
      "training accuracy = 0.8223\n",
      "num_train_corrects / train_total_examples = 4934 / 6000\n",
      "num_test_corrects / test_total_examples = 4883 / 6000\n",
      "testing accuracy = 0.8138\n",
      "--------- epoch: 397 ---------\n",
      "training loss = 0.4145\n",
      "training accuracy = 0.8225\n",
      "num_train_corrects / train_total_examples = 4935 / 6000\n",
      "num_test_corrects / test_total_examples = 4883 / 6000\n",
      "testing accuracy = 0.8138\n",
      "--------- epoch: 398 ---------\n",
      "training loss = 0.4144\n",
      "training accuracy = 0.8227\n",
      "num_train_corrects / train_total_examples = 4936 / 6000\n",
      "num_test_corrects / test_total_examples = 4883 / 6000\n",
      "testing accuracy = 0.8138\n",
      "--------- epoch: 399 ---------\n",
      "training loss = 0.4143\n",
      "training accuracy = 0.8227\n",
      "num_train_corrects / train_total_examples = 4936 / 6000\n",
      "num_test_corrects / test_total_examples = 4883 / 6000\n",
      "testing accuracy = 0.8138\n",
      "--------- epoch: 400 ---------\n",
      "training loss = 0.4143\n",
      "training accuracy = 0.8227\n",
      "num_train_corrects / train_total_examples = 4936 / 6000\n",
      "num_test_corrects / test_total_examples = 4883 / 6000\n",
      "testing accuracy = 0.8138\n",
      "--------- epoch: 401 ---------\n",
      "training loss = 0.4142\n",
      "training accuracy = 0.8227\n",
      "num_train_corrects / train_total_examples = 4936 / 6000\n",
      "num_test_corrects / test_total_examples = 4883 / 6000\n",
      "testing accuracy = 0.8138\n",
      "--------- epoch: 402 ---------\n",
      "training loss = 0.4141\n",
      "training accuracy = 0.8225\n",
      "num_train_corrects / train_total_examples = 4935 / 6000\n",
      "num_test_corrects / test_total_examples = 4884 / 6000\n",
      "testing accuracy = 0.8140\n",
      "--------- epoch: 403 ---------\n",
      "training loss = 0.4141\n",
      "training accuracy = 0.8225\n",
      "num_train_corrects / train_total_examples = 4935 / 6000\n",
      "num_test_corrects / test_total_examples = 4884 / 6000\n",
      "testing accuracy = 0.8140\n",
      "--------- epoch: 404 ---------\n",
      "training loss = 0.4140\n",
      "training accuracy = 0.8227\n",
      "num_train_corrects / train_total_examples = 4936 / 6000\n",
      "num_test_corrects / test_total_examples = 4884 / 6000\n",
      "testing accuracy = 0.8140\n",
      "--------- epoch: 405 ---------\n",
      "training loss = 0.4140\n",
      "training accuracy = 0.8227\n",
      "num_train_corrects / train_total_examples = 4936 / 6000\n",
      "num_test_corrects / test_total_examples = 4884 / 6000\n",
      "testing accuracy = 0.8140\n",
      "--------- epoch: 406 ---------\n",
      "training loss = 0.4139\n",
      "training accuracy = 0.8225\n",
      "num_train_corrects / train_total_examples = 4935 / 6000\n",
      "num_test_corrects / test_total_examples = 4884 / 6000\n",
      "testing accuracy = 0.8140\n",
      "--------- epoch: 407 ---------\n",
      "training loss = 0.4138\n",
      "training accuracy = 0.8223\n",
      "num_train_corrects / train_total_examples = 4934 / 6000\n",
      "num_test_corrects / test_total_examples = 4885 / 6000\n",
      "testing accuracy = 0.8142\n",
      "--------- epoch: 408 ---------\n",
      "training loss = 0.4138\n",
      "training accuracy = 0.8223\n",
      "num_train_corrects / train_total_examples = 4934 / 6000\n",
      "num_test_corrects / test_total_examples = 4885 / 6000\n",
      "testing accuracy = 0.8142\n",
      "--------- epoch: 409 ---------\n",
      "training loss = 0.4137\n",
      "training accuracy = 0.8225\n",
      "num_train_corrects / train_total_examples = 4935 / 6000\n",
      "num_test_corrects / test_total_examples = 4885 / 6000\n",
      "testing accuracy = 0.8142\n",
      "--------- epoch: 410 ---------\n",
      "training loss = 0.4136\n",
      "training accuracy = 0.8228\n",
      "num_train_corrects / train_total_examples = 4937 / 6000\n",
      "num_test_corrects / test_total_examples = 4886 / 6000\n",
      "testing accuracy = 0.8143\n",
      "--------- epoch: 411 ---------\n",
      "training loss = 0.4136\n",
      "training accuracy = 0.8228\n",
      "num_train_corrects / train_total_examples = 4937 / 6000\n",
      "num_test_corrects / test_total_examples = 4886 / 6000\n",
      "testing accuracy = 0.8143\n",
      "--------- epoch: 412 ---------\n",
      "training loss = 0.4135\n",
      "training accuracy = 0.8232\n",
      "num_train_corrects / train_total_examples = 4939 / 6000\n",
      "num_test_corrects / test_total_examples = 4886 / 6000\n",
      "testing accuracy = 0.8143\n",
      "--------- epoch: 413 ---------\n",
      "training loss = 0.4134\n",
      "training accuracy = 0.8233\n",
      "num_train_corrects / train_total_examples = 4940 / 6000\n",
      "num_test_corrects / test_total_examples = 4886 / 6000\n",
      "testing accuracy = 0.8143\n",
      "--------- epoch: 414 ---------\n",
      "training loss = 0.4134\n",
      "training accuracy = 0.8233\n",
      "num_train_corrects / train_total_examples = 4940 / 6000\n",
      "num_test_corrects / test_total_examples = 4885 / 6000\n",
      "testing accuracy = 0.8142\n",
      "--------- epoch: 415 ---------\n",
      "training loss = 0.4133\n",
      "training accuracy = 0.8233\n",
      "num_train_corrects / train_total_examples = 4940 / 6000\n",
      "num_test_corrects / test_total_examples = 4886 / 6000\n",
      "testing accuracy = 0.8143\n",
      "--------- epoch: 416 ---------\n",
      "training loss = 0.4132\n",
      "training accuracy = 0.8233\n",
      "num_train_corrects / train_total_examples = 4940 / 6000\n",
      "num_test_corrects / test_total_examples = 4886 / 6000\n",
      "testing accuracy = 0.8143\n",
      "--------- epoch: 417 ---------\n",
      "training loss = 0.4132\n",
      "training accuracy = 0.8235\n",
      "num_train_corrects / train_total_examples = 4941 / 6000\n",
      "num_test_corrects / test_total_examples = 4886 / 6000\n",
      "testing accuracy = 0.8143\n",
      "--------- epoch: 418 ---------\n",
      "training loss = 0.4131\n",
      "training accuracy = 0.8237\n",
      "num_train_corrects / train_total_examples = 4942 / 6000\n",
      "num_test_corrects / test_total_examples = 4887 / 6000\n",
      "testing accuracy = 0.8145\n",
      "--------- epoch: 419 ---------\n",
      "training loss = 0.4131\n",
      "training accuracy = 0.8237\n",
      "num_train_corrects / train_total_examples = 4942 / 6000\n",
      "num_test_corrects / test_total_examples = 4888 / 6000\n",
      "testing accuracy = 0.8147\n",
      "--------- epoch: 420 ---------\n",
      "training loss = 0.4130\n",
      "training accuracy = 0.8237\n",
      "num_train_corrects / train_total_examples = 4942 / 6000\n",
      "num_test_corrects / test_total_examples = 4889 / 6000\n",
      "testing accuracy = 0.8148\n",
      "--------- epoch: 421 ---------\n",
      "training loss = 0.4129\n",
      "training accuracy = 0.8237\n",
      "num_train_corrects / train_total_examples = 4942 / 6000\n",
      "num_test_corrects / test_total_examples = 4889 / 6000\n",
      "testing accuracy = 0.8148\n",
      "--------- epoch: 422 ---------\n",
      "training loss = 0.4129\n",
      "training accuracy = 0.8238\n",
      "num_train_corrects / train_total_examples = 4943 / 6000\n",
      "num_test_corrects / test_total_examples = 4890 / 6000\n",
      "testing accuracy = 0.8150\n",
      "--------- epoch: 423 ---------\n",
      "training loss = 0.4128\n",
      "training accuracy = 0.8240\n",
      "num_train_corrects / train_total_examples = 4944 / 6000\n",
      "num_test_corrects / test_total_examples = 4889 / 6000\n",
      "testing accuracy = 0.8148\n",
      "--------- epoch: 424 ---------\n",
      "training loss = 0.4127\n",
      "training accuracy = 0.8240\n",
      "num_train_corrects / train_total_examples = 4944 / 6000\n",
      "num_test_corrects / test_total_examples = 4891 / 6000\n",
      "testing accuracy = 0.8152\n",
      "--------- epoch: 425 ---------\n",
      "training loss = 0.4127\n",
      "training accuracy = 0.8240\n",
      "num_train_corrects / train_total_examples = 4944 / 6000\n",
      "num_test_corrects / test_total_examples = 4891 / 6000\n",
      "testing accuracy = 0.8152\n",
      "--------- epoch: 426 ---------\n",
      "training loss = 0.4126\n",
      "training accuracy = 0.8240\n",
      "num_train_corrects / train_total_examples = 4944 / 6000\n",
      "num_test_corrects / test_total_examples = 4891 / 6000\n",
      "testing accuracy = 0.8152\n",
      "--------- epoch: 427 ---------\n",
      "training loss = 0.4126\n",
      "training accuracy = 0.8240\n",
      "num_train_corrects / train_total_examples = 4944 / 6000\n",
      "num_test_corrects / test_total_examples = 4891 / 6000\n",
      "testing accuracy = 0.8152\n",
      "--------- epoch: 428 ---------\n",
      "training loss = 0.4125\n",
      "training accuracy = 0.8240\n",
      "num_train_corrects / train_total_examples = 4944 / 6000\n",
      "num_test_corrects / test_total_examples = 4891 / 6000\n",
      "testing accuracy = 0.8152\n",
      "--------- epoch: 429 ---------\n",
      "training loss = 0.4124\n",
      "training accuracy = 0.8242\n",
      "num_train_corrects / train_total_examples = 4945 / 6000\n",
      "num_test_corrects / test_total_examples = 4892 / 6000\n",
      "testing accuracy = 0.8153\n",
      "--------- epoch: 430 ---------\n",
      "training loss = 0.4124\n",
      "training accuracy = 0.8242\n",
      "num_train_corrects / train_total_examples = 4945 / 6000\n",
      "num_test_corrects / test_total_examples = 4892 / 6000\n",
      "testing accuracy = 0.8153\n",
      "--------- epoch: 431 ---------\n",
      "training loss = 0.4123\n",
      "training accuracy = 0.8243\n",
      "num_train_corrects / train_total_examples = 4946 / 6000\n",
      "num_test_corrects / test_total_examples = 4892 / 6000\n",
      "testing accuracy = 0.8153\n",
      "--------- epoch: 432 ---------\n",
      "training loss = 0.4123\n",
      "training accuracy = 0.8243\n",
      "num_train_corrects / train_total_examples = 4946 / 6000\n",
      "num_test_corrects / test_total_examples = 4893 / 6000\n",
      "testing accuracy = 0.8155\n",
      "--------- epoch: 433 ---------\n",
      "training loss = 0.4122\n",
      "training accuracy = 0.8243\n",
      "num_train_corrects / train_total_examples = 4946 / 6000\n",
      "num_test_corrects / test_total_examples = 4893 / 6000\n",
      "testing accuracy = 0.8155\n",
      "--------- epoch: 434 ---------\n",
      "training loss = 0.4121\n",
      "training accuracy = 0.8243\n",
      "num_train_corrects / train_total_examples = 4946 / 6000\n",
      "num_test_corrects / test_total_examples = 4892 / 6000\n",
      "testing accuracy = 0.8153\n",
      "--------- epoch: 435 ---------\n",
      "training loss = 0.4121\n",
      "training accuracy = 0.8245\n",
      "num_train_corrects / train_total_examples = 4947 / 6000\n",
      "num_test_corrects / test_total_examples = 4893 / 6000\n",
      "testing accuracy = 0.8155\n",
      "--------- epoch: 436 ---------\n",
      "training loss = 0.4120\n",
      "training accuracy = 0.8245\n",
      "num_train_corrects / train_total_examples = 4947 / 6000\n",
      "num_test_corrects / test_total_examples = 4895 / 6000\n",
      "testing accuracy = 0.8158\n",
      "--------- epoch: 437 ---------\n",
      "training loss = 0.4120\n",
      "training accuracy = 0.8245\n",
      "num_train_corrects / train_total_examples = 4947 / 6000\n",
      "num_test_corrects / test_total_examples = 4895 / 6000\n",
      "testing accuracy = 0.8158\n",
      "--------- epoch: 438 ---------\n",
      "training loss = 0.4119\n",
      "training accuracy = 0.8245\n",
      "num_train_corrects / train_total_examples = 4947 / 6000\n",
      "num_test_corrects / test_total_examples = 4896 / 6000\n",
      "testing accuracy = 0.8160\n",
      "--------- epoch: 439 ---------\n",
      "training loss = 0.4118\n",
      "training accuracy = 0.8245\n",
      "num_train_corrects / train_total_examples = 4947 / 6000\n",
      "num_test_corrects / test_total_examples = 4896 / 6000\n",
      "testing accuracy = 0.8160\n",
      "--------- epoch: 440 ---------\n",
      "training loss = 0.4118\n",
      "training accuracy = 0.8245\n",
      "num_train_corrects / train_total_examples = 4947 / 6000\n",
      "num_test_corrects / test_total_examples = 4897 / 6000\n",
      "testing accuracy = 0.8162\n",
      "--------- epoch: 441 ---------\n",
      "training loss = 0.4117\n",
      "training accuracy = 0.8245\n",
      "num_train_corrects / train_total_examples = 4947 / 6000\n",
      "num_test_corrects / test_total_examples = 4898 / 6000\n",
      "testing accuracy = 0.8163\n",
      "--------- epoch: 442 ---------\n",
      "training loss = 0.4117\n",
      "training accuracy = 0.8250\n",
      "num_train_corrects / train_total_examples = 4950 / 6000\n",
      "num_test_corrects / test_total_examples = 4898 / 6000\n",
      "testing accuracy = 0.8163\n",
      "--------- epoch: 443 ---------\n",
      "training loss = 0.4116\n",
      "training accuracy = 0.8252\n",
      "num_train_corrects / train_total_examples = 4951 / 6000\n",
      "num_test_corrects / test_total_examples = 4898 / 6000\n",
      "testing accuracy = 0.8163\n",
      "--------- epoch: 444 ---------\n",
      "training loss = 0.4115\n",
      "training accuracy = 0.8252\n",
      "num_train_corrects / train_total_examples = 4951 / 6000\n",
      "num_test_corrects / test_total_examples = 4898 / 6000\n",
      "testing accuracy = 0.8163\n",
      "--------- epoch: 445 ---------\n",
      "training loss = 0.4115\n",
      "training accuracy = 0.8252\n",
      "num_train_corrects / train_total_examples = 4951 / 6000\n",
      "num_test_corrects / test_total_examples = 4898 / 6000\n",
      "testing accuracy = 0.8163\n",
      "--------- epoch: 446 ---------\n",
      "training loss = 0.4114\n",
      "training accuracy = 0.8252\n",
      "num_train_corrects / train_total_examples = 4951 / 6000\n",
      "num_test_corrects / test_total_examples = 4898 / 6000\n",
      "testing accuracy = 0.8163\n",
      "--------- epoch: 447 ---------\n",
      "training loss = 0.4114\n",
      "training accuracy = 0.8253\n",
      "num_train_corrects / train_total_examples = 4952 / 6000\n",
      "num_test_corrects / test_total_examples = 4898 / 6000\n",
      "testing accuracy = 0.8163\n",
      "--------- epoch: 448 ---------\n",
      "training loss = 0.4113\n",
      "training accuracy = 0.8253\n",
      "num_train_corrects / train_total_examples = 4952 / 6000\n",
      "num_test_corrects / test_total_examples = 4899 / 6000\n",
      "testing accuracy = 0.8165\n",
      "--------- epoch: 449 ---------\n",
      "training loss = 0.4112\n",
      "training accuracy = 0.8253\n",
      "num_train_corrects / train_total_examples = 4952 / 6000\n",
      "num_test_corrects / test_total_examples = 4901 / 6000\n",
      "testing accuracy = 0.8168\n",
      "--------- epoch: 450 ---------\n",
      "training loss = 0.4112\n",
      "training accuracy = 0.8255\n",
      "num_train_corrects / train_total_examples = 4953 / 6000\n",
      "num_test_corrects / test_total_examples = 4902 / 6000\n",
      "testing accuracy = 0.8170\n",
      "--------- epoch: 451 ---------\n",
      "training loss = 0.4111\n",
      "training accuracy = 0.8255\n",
      "num_train_corrects / train_total_examples = 4953 / 6000\n",
      "num_test_corrects / test_total_examples = 4902 / 6000\n",
      "testing accuracy = 0.8170\n",
      "--------- epoch: 452 ---------\n",
      "training loss = 0.4111\n",
      "training accuracy = 0.8257\n",
      "num_train_corrects / train_total_examples = 4954 / 6000\n",
      "num_test_corrects / test_total_examples = 4904 / 6000\n",
      "testing accuracy = 0.8173\n",
      "--------- epoch: 453 ---------\n",
      "training loss = 0.4110\n",
      "training accuracy = 0.8258\n",
      "num_train_corrects / train_total_examples = 4955 / 6000\n",
      "num_test_corrects / test_total_examples = 4904 / 6000\n",
      "testing accuracy = 0.8173\n",
      "--------- epoch: 454 ---------\n",
      "training loss = 0.4110\n",
      "training accuracy = 0.8260\n",
      "num_train_corrects / train_total_examples = 4956 / 6000\n",
      "num_test_corrects / test_total_examples = 4905 / 6000\n",
      "testing accuracy = 0.8175\n",
      "--------- epoch: 455 ---------\n",
      "training loss = 0.4109\n",
      "training accuracy = 0.8258\n",
      "num_train_corrects / train_total_examples = 4955 / 6000\n",
      "num_test_corrects / test_total_examples = 4905 / 6000\n",
      "testing accuracy = 0.8175\n",
      "--------- epoch: 456 ---------\n",
      "training loss = 0.4108\n",
      "training accuracy = 0.8260\n",
      "num_train_corrects / train_total_examples = 4956 / 6000\n",
      "num_test_corrects / test_total_examples = 4906 / 6000\n",
      "testing accuracy = 0.8177\n",
      "--------- epoch: 457 ---------\n",
      "training loss = 0.4108\n",
      "training accuracy = 0.8260\n",
      "num_train_corrects / train_total_examples = 4956 / 6000\n",
      "num_test_corrects / test_total_examples = 4906 / 6000\n",
      "testing accuracy = 0.8177\n",
      "--------- epoch: 458 ---------\n",
      "training loss = 0.4107\n",
      "training accuracy = 0.8260\n",
      "num_train_corrects / train_total_examples = 4956 / 6000\n",
      "num_test_corrects / test_total_examples = 4906 / 6000\n",
      "testing accuracy = 0.8177\n",
      "--------- epoch: 459 ---------\n",
      "training loss = 0.4107\n",
      "training accuracy = 0.8260\n",
      "num_train_corrects / train_total_examples = 4956 / 6000\n",
      "num_test_corrects / test_total_examples = 4906 / 6000\n",
      "testing accuracy = 0.8177\n",
      "--------- epoch: 460 ---------\n",
      "training loss = 0.4106\n",
      "training accuracy = 0.8260\n",
      "num_train_corrects / train_total_examples = 4956 / 6000\n",
      "num_test_corrects / test_total_examples = 4906 / 6000\n",
      "testing accuracy = 0.8177\n",
      "--------- epoch: 461 ---------\n",
      "training loss = 0.4106\n",
      "training accuracy = 0.8260\n",
      "num_train_corrects / train_total_examples = 4956 / 6000\n",
      "num_test_corrects / test_total_examples = 4906 / 6000\n",
      "testing accuracy = 0.8177\n",
      "--------- epoch: 462 ---------\n",
      "training loss = 0.4105\n",
      "training accuracy = 0.8260\n",
      "num_train_corrects / train_total_examples = 4956 / 6000\n",
      "num_test_corrects / test_total_examples = 4906 / 6000\n",
      "testing accuracy = 0.8177\n",
      "--------- epoch: 463 ---------\n",
      "training loss = 0.4105\n",
      "training accuracy = 0.8262\n",
      "num_train_corrects / train_total_examples = 4957 / 6000\n",
      "num_test_corrects / test_total_examples = 4905 / 6000\n",
      "testing accuracy = 0.8175\n",
      "--------- epoch: 464 ---------\n",
      "training loss = 0.4104\n",
      "training accuracy = 0.8262\n",
      "num_train_corrects / train_total_examples = 4957 / 6000\n",
      "num_test_corrects / test_total_examples = 4908 / 6000\n",
      "testing accuracy = 0.8180\n",
      "--------- epoch: 465 ---------\n",
      "training loss = 0.4103\n",
      "training accuracy = 0.8260\n",
      "num_train_corrects / train_total_examples = 4956 / 6000\n",
      "num_test_corrects / test_total_examples = 4909 / 6000\n",
      "testing accuracy = 0.8182\n",
      "--------- epoch: 466 ---------\n",
      "training loss = 0.4103\n",
      "training accuracy = 0.8260\n",
      "num_train_corrects / train_total_examples = 4956 / 6000\n",
      "num_test_corrects / test_total_examples = 4909 / 6000\n",
      "testing accuracy = 0.8182\n",
      "--------- epoch: 467 ---------\n",
      "training loss = 0.4102\n",
      "training accuracy = 0.8262\n",
      "num_train_corrects / train_total_examples = 4957 / 6000\n",
      "num_test_corrects / test_total_examples = 4909 / 6000\n",
      "testing accuracy = 0.8182\n",
      "--------- epoch: 468 ---------\n",
      "training loss = 0.4102\n",
      "training accuracy = 0.8263\n",
      "num_train_corrects / train_total_examples = 4958 / 6000\n",
      "num_test_corrects / test_total_examples = 4909 / 6000\n",
      "testing accuracy = 0.8182\n",
      "--------- epoch: 469 ---------\n",
      "training loss = 0.4101\n",
      "training accuracy = 0.8263\n",
      "num_train_corrects / train_total_examples = 4958 / 6000\n",
      "num_test_corrects / test_total_examples = 4910 / 6000\n",
      "testing accuracy = 0.8183\n",
      "--------- epoch: 470 ---------\n",
      "training loss = 0.4101\n",
      "training accuracy = 0.8263\n",
      "num_train_corrects / train_total_examples = 4958 / 6000\n",
      "num_test_corrects / test_total_examples = 4910 / 6000\n",
      "testing accuracy = 0.8183\n",
      "--------- epoch: 471 ---------\n",
      "training loss = 0.4100\n",
      "training accuracy = 0.8263\n",
      "num_train_corrects / train_total_examples = 4958 / 6000\n",
      "num_test_corrects / test_total_examples = 4910 / 6000\n",
      "testing accuracy = 0.8183\n",
      "--------- epoch: 472 ---------\n",
      "training loss = 0.4100\n",
      "training accuracy = 0.8263\n",
      "num_train_corrects / train_total_examples = 4958 / 6000\n",
      "num_test_corrects / test_total_examples = 4910 / 6000\n",
      "testing accuracy = 0.8183\n",
      "--------- epoch: 473 ---------\n",
      "training loss = 0.4099\n",
      "training accuracy = 0.8263\n",
      "num_train_corrects / train_total_examples = 4958 / 6000\n",
      "num_test_corrects / test_total_examples = 4910 / 6000\n",
      "testing accuracy = 0.8183\n",
      "--------- epoch: 474 ---------\n",
      "training loss = 0.4098\n",
      "training accuracy = 0.8262\n",
      "num_train_corrects / train_total_examples = 4957 / 6000\n",
      "num_test_corrects / test_total_examples = 4910 / 6000\n",
      "testing accuracy = 0.8183\n",
      "--------- epoch: 475 ---------\n",
      "training loss = 0.4098\n",
      "training accuracy = 0.8263\n",
      "num_train_corrects / train_total_examples = 4958 / 6000\n",
      "num_test_corrects / test_total_examples = 4910 / 6000\n",
      "testing accuracy = 0.8183\n",
      "--------- epoch: 476 ---------\n",
      "training loss = 0.4097\n",
      "training accuracy = 0.8265\n",
      "num_train_corrects / train_total_examples = 4959 / 6000\n",
      "num_test_corrects / test_total_examples = 4910 / 6000\n",
      "testing accuracy = 0.8183\n",
      "--------- epoch: 477 ---------\n",
      "training loss = 0.4097\n",
      "training accuracy = 0.8267\n",
      "num_train_corrects / train_total_examples = 4960 / 6000\n",
      "num_test_corrects / test_total_examples = 4910 / 6000\n",
      "testing accuracy = 0.8183\n",
      "--------- epoch: 478 ---------\n",
      "training loss = 0.4096\n",
      "training accuracy = 0.8268\n",
      "num_train_corrects / train_total_examples = 4961 / 6000\n",
      "num_test_corrects / test_total_examples = 4911 / 6000\n",
      "testing accuracy = 0.8185\n",
      "--------- epoch: 479 ---------\n",
      "training loss = 0.4096\n",
      "training accuracy = 0.8268\n",
      "num_train_corrects / train_total_examples = 4961 / 6000\n",
      "num_test_corrects / test_total_examples = 4911 / 6000\n",
      "testing accuracy = 0.8185\n",
      "--------- epoch: 480 ---------\n",
      "training loss = 0.4095\n",
      "training accuracy = 0.8268\n",
      "num_train_corrects / train_total_examples = 4961 / 6000\n",
      "num_test_corrects / test_total_examples = 4911 / 6000\n",
      "testing accuracy = 0.8185\n",
      "--------- epoch: 481 ---------\n",
      "training loss = 0.4095\n",
      "training accuracy = 0.8270\n",
      "num_train_corrects / train_total_examples = 4962 / 6000\n",
      "num_test_corrects / test_total_examples = 4911 / 6000\n",
      "testing accuracy = 0.8185\n",
      "--------- epoch: 482 ---------\n",
      "training loss = 0.4094\n",
      "training accuracy = 0.8272\n",
      "num_train_corrects / train_total_examples = 4963 / 6000\n",
      "num_test_corrects / test_total_examples = 4913 / 6000\n",
      "testing accuracy = 0.8188\n",
      "--------- epoch: 483 ---------\n",
      "training loss = 0.4094\n",
      "training accuracy = 0.8272\n",
      "num_train_corrects / train_total_examples = 4963 / 6000\n",
      "num_test_corrects / test_total_examples = 4913 / 6000\n",
      "testing accuracy = 0.8188\n",
      "--------- epoch: 484 ---------\n",
      "training loss = 0.4093\n",
      "training accuracy = 0.8272\n",
      "num_train_corrects / train_total_examples = 4963 / 6000\n",
      "num_test_corrects / test_total_examples = 4913 / 6000\n",
      "testing accuracy = 0.8188\n",
      "--------- epoch: 485 ---------\n",
      "training loss = 0.4093\n",
      "training accuracy = 0.8273\n",
      "num_train_corrects / train_total_examples = 4964 / 6000\n",
      "num_test_corrects / test_total_examples = 4913 / 6000\n",
      "testing accuracy = 0.8188\n",
      "--------- epoch: 486 ---------\n",
      "training loss = 0.4092\n",
      "training accuracy = 0.8273\n",
      "num_train_corrects / train_total_examples = 4964 / 6000\n",
      "num_test_corrects / test_total_examples = 4913 / 6000\n",
      "testing accuracy = 0.8188\n",
      "--------- epoch: 487 ---------\n",
      "training loss = 0.4091\n",
      "training accuracy = 0.8273\n",
      "num_train_corrects / train_total_examples = 4964 / 6000\n",
      "num_test_corrects / test_total_examples = 4913 / 6000\n",
      "testing accuracy = 0.8188\n",
      "--------- epoch: 488 ---------\n",
      "training loss = 0.4091\n",
      "training accuracy = 0.8273\n",
      "num_train_corrects / train_total_examples = 4964 / 6000\n",
      "num_test_corrects / test_total_examples = 4914 / 6000\n",
      "testing accuracy = 0.8190\n",
      "--------- epoch: 489 ---------\n",
      "training loss = 0.4090\n",
      "training accuracy = 0.8273\n",
      "num_train_corrects / train_total_examples = 4964 / 6000\n",
      "num_test_corrects / test_total_examples = 4914 / 6000\n",
      "testing accuracy = 0.8190\n",
      "--------- epoch: 490 ---------\n",
      "training loss = 0.4090\n",
      "training accuracy = 0.8270\n",
      "num_train_corrects / train_total_examples = 4962 / 6000\n",
      "num_test_corrects / test_total_examples = 4914 / 6000\n",
      "testing accuracy = 0.8190\n",
      "--------- epoch: 491 ---------\n",
      "training loss = 0.4089\n",
      "training accuracy = 0.8272\n",
      "num_train_corrects / train_total_examples = 4963 / 6000\n",
      "num_test_corrects / test_total_examples = 4914 / 6000\n",
      "testing accuracy = 0.8190\n",
      "--------- epoch: 492 ---------\n",
      "training loss = 0.4089\n",
      "training accuracy = 0.8272\n",
      "num_train_corrects / train_total_examples = 4963 / 6000\n",
      "num_test_corrects / test_total_examples = 4914 / 6000\n",
      "testing accuracy = 0.8190\n",
      "--------- epoch: 493 ---------\n",
      "training loss = 0.4088\n",
      "training accuracy = 0.8273\n",
      "num_train_corrects / train_total_examples = 4964 / 6000\n",
      "num_test_corrects / test_total_examples = 4915 / 6000\n",
      "testing accuracy = 0.8192\n",
      "--------- epoch: 494 ---------\n",
      "training loss = 0.4088\n",
      "training accuracy = 0.8273\n",
      "num_train_corrects / train_total_examples = 4964 / 6000\n",
      "num_test_corrects / test_total_examples = 4916 / 6000\n",
      "testing accuracy = 0.8193\n",
      "--------- epoch: 495 ---------\n",
      "training loss = 0.4087\n",
      "training accuracy = 0.8273\n",
      "num_train_corrects / train_total_examples = 4964 / 6000\n",
      "num_test_corrects / test_total_examples = 4916 / 6000\n",
      "testing accuracy = 0.8193\n",
      "--------- epoch: 496 ---------\n",
      "training loss = 0.4087\n",
      "training accuracy = 0.8273\n",
      "num_train_corrects / train_total_examples = 4964 / 6000\n",
      "num_test_corrects / test_total_examples = 4916 / 6000\n",
      "testing accuracy = 0.8193\n",
      "--------- epoch: 497 ---------\n",
      "training loss = 0.4086\n",
      "training accuracy = 0.8273\n",
      "num_train_corrects / train_total_examples = 4964 / 6000\n",
      "num_test_corrects / test_total_examples = 4916 / 6000\n",
      "testing accuracy = 0.8193\n",
      "--------- epoch: 498 ---------\n",
      "training loss = 0.4086\n",
      "training accuracy = 0.8273\n",
      "num_train_corrects / train_total_examples = 4964 / 6000\n",
      "num_test_corrects / test_total_examples = 4917 / 6000\n",
      "testing accuracy = 0.8195\n",
      "--------- epoch: 499 ---------\n",
      "training loss = 0.4085\n",
      "training accuracy = 0.8272\n",
      "num_train_corrects / train_total_examples = 4963 / 6000\n",
      "num_test_corrects / test_total_examples = 4917 / 6000\n",
      "testing accuracy = 0.8195\n",
      "--------- epoch: 500 ---------\n",
      "training loss = 0.4085\n",
      "training accuracy = 0.8270\n",
      "num_train_corrects / train_total_examples = 4962 / 6000\n",
      "num_test_corrects / test_total_examples = 4918 / 6000\n",
      "testing accuracy = 0.8197\n",
      "--------- epoch: 501 ---------\n",
      "training loss = 0.4084\n",
      "training accuracy = 0.8270\n",
      "num_train_corrects / train_total_examples = 4962 / 6000\n",
      "num_test_corrects / test_total_examples = 4920 / 6000\n",
      "testing accuracy = 0.8200\n",
      "--------- epoch: 502 ---------\n",
      "training loss = 0.4084\n",
      "training accuracy = 0.8270\n",
      "num_train_corrects / train_total_examples = 4962 / 6000\n",
      "num_test_corrects / test_total_examples = 4921 / 6000\n",
      "testing accuracy = 0.8202\n",
      "--------- epoch: 503 ---------\n",
      "training loss = 0.4083\n",
      "training accuracy = 0.8270\n",
      "num_train_corrects / train_total_examples = 4962 / 6000\n",
      "num_test_corrects / test_total_examples = 4921 / 6000\n",
      "testing accuracy = 0.8202\n",
      "--------- epoch: 504 ---------\n",
      "training loss = 0.4083\n",
      "training accuracy = 0.8270\n",
      "num_train_corrects / train_total_examples = 4962 / 6000\n",
      "num_test_corrects / test_total_examples = 4921 / 6000\n",
      "testing accuracy = 0.8202\n",
      "--------- epoch: 505 ---------\n",
      "training loss = 0.4082\n",
      "training accuracy = 0.8270\n",
      "num_train_corrects / train_total_examples = 4962 / 6000\n",
      "num_test_corrects / test_total_examples = 4922 / 6000\n",
      "testing accuracy = 0.8203\n",
      "--------- epoch: 506 ---------\n",
      "training loss = 0.4082\n",
      "training accuracy = 0.8270\n",
      "num_train_corrects / train_total_examples = 4962 / 6000\n",
      "num_test_corrects / test_total_examples = 4922 / 6000\n",
      "testing accuracy = 0.8203\n",
      "--------- epoch: 507 ---------\n",
      "training loss = 0.4081\n",
      "training accuracy = 0.8270\n",
      "num_train_corrects / train_total_examples = 4962 / 6000\n",
      "num_test_corrects / test_total_examples = 4923 / 6000\n",
      "testing accuracy = 0.8205\n",
      "--------- epoch: 508 ---------\n",
      "training loss = 0.4081\n",
      "training accuracy = 0.8270\n",
      "num_train_corrects / train_total_examples = 4962 / 6000\n",
      "num_test_corrects / test_total_examples = 4924 / 6000\n",
      "testing accuracy = 0.8207\n",
      "--------- epoch: 509 ---------\n",
      "training loss = 0.4080\n",
      "training accuracy = 0.8272\n",
      "num_train_corrects / train_total_examples = 4963 / 6000\n",
      "num_test_corrects / test_total_examples = 4924 / 6000\n",
      "testing accuracy = 0.8207\n",
      "--------- epoch: 510 ---------\n",
      "training loss = 0.4080\n",
      "training accuracy = 0.8270\n",
      "num_train_corrects / train_total_examples = 4962 / 6000\n",
      "num_test_corrects / test_total_examples = 4924 / 6000\n",
      "testing accuracy = 0.8207\n",
      "--------- epoch: 511 ---------\n",
      "training loss = 0.4079\n",
      "training accuracy = 0.8273\n",
      "num_train_corrects / train_total_examples = 4964 / 6000\n",
      "num_test_corrects / test_total_examples = 4924 / 6000\n",
      "testing accuracy = 0.8207\n",
      "--------- epoch: 512 ---------\n",
      "training loss = 0.4079\n",
      "training accuracy = 0.8275\n",
      "num_train_corrects / train_total_examples = 4965 / 6000\n",
      "num_test_corrects / test_total_examples = 4924 / 6000\n",
      "testing accuracy = 0.8207\n",
      "--------- epoch: 513 ---------\n",
      "training loss = 0.4078\n",
      "training accuracy = 0.8275\n",
      "num_train_corrects / train_total_examples = 4965 / 6000\n",
      "num_test_corrects / test_total_examples = 4924 / 6000\n",
      "testing accuracy = 0.8207\n",
      "--------- epoch: 514 ---------\n",
      "training loss = 0.4078\n",
      "training accuracy = 0.8278\n",
      "num_train_corrects / train_total_examples = 4967 / 6000\n",
      "num_test_corrects / test_total_examples = 4924 / 6000\n",
      "testing accuracy = 0.8207\n",
      "--------- epoch: 515 ---------\n",
      "training loss = 0.4077\n",
      "training accuracy = 0.8278\n",
      "num_train_corrects / train_total_examples = 4967 / 6000\n",
      "num_test_corrects / test_total_examples = 4924 / 6000\n",
      "testing accuracy = 0.8207\n",
      "--------- epoch: 516 ---------\n",
      "training loss = 0.4077\n",
      "training accuracy = 0.8278\n",
      "num_train_corrects / train_total_examples = 4967 / 6000\n",
      "num_test_corrects / test_total_examples = 4925 / 6000\n",
      "testing accuracy = 0.8208\n",
      "--------- epoch: 517 ---------\n",
      "training loss = 0.4076\n",
      "training accuracy = 0.8280\n",
      "num_train_corrects / train_total_examples = 4968 / 6000\n",
      "num_test_corrects / test_total_examples = 4925 / 6000\n",
      "testing accuracy = 0.8208\n",
      "--------- epoch: 518 ---------\n",
      "training loss = 0.4076\n",
      "training accuracy = 0.8282\n",
      "num_train_corrects / train_total_examples = 4969 / 6000\n",
      "num_test_corrects / test_total_examples = 4925 / 6000\n",
      "testing accuracy = 0.8208\n",
      "--------- epoch: 519 ---------\n",
      "training loss = 0.4075\n",
      "training accuracy = 0.8282\n",
      "num_train_corrects / train_total_examples = 4969 / 6000\n",
      "num_test_corrects / test_total_examples = 4925 / 6000\n",
      "testing accuracy = 0.8208\n",
      "--------- epoch: 520 ---------\n",
      "training loss = 0.4075\n",
      "training accuracy = 0.8282\n",
      "num_train_corrects / train_total_examples = 4969 / 6000\n",
      "num_test_corrects / test_total_examples = 4926 / 6000\n",
      "testing accuracy = 0.8210\n",
      "--------- epoch: 521 ---------\n",
      "training loss = 0.4074\n",
      "training accuracy = 0.8282\n",
      "num_train_corrects / train_total_examples = 4969 / 6000\n",
      "num_test_corrects / test_total_examples = 4926 / 6000\n",
      "testing accuracy = 0.8210\n",
      "--------- epoch: 522 ---------\n",
      "training loss = 0.4074\n",
      "training accuracy = 0.8282\n",
      "num_train_corrects / train_total_examples = 4969 / 6000\n",
      "num_test_corrects / test_total_examples = 4928 / 6000\n",
      "testing accuracy = 0.8213\n",
      "--------- epoch: 523 ---------\n",
      "training loss = 0.4073\n",
      "training accuracy = 0.8282\n",
      "num_train_corrects / train_total_examples = 4969 / 6000\n",
      "num_test_corrects / test_total_examples = 4929 / 6000\n",
      "testing accuracy = 0.8215\n",
      "--------- epoch: 524 ---------\n",
      "training loss = 0.4073\n",
      "training accuracy = 0.8282\n",
      "num_train_corrects / train_total_examples = 4969 / 6000\n",
      "num_test_corrects / test_total_examples = 4929 / 6000\n",
      "testing accuracy = 0.8215\n",
      "--------- epoch: 525 ---------\n",
      "training loss = 0.4072\n",
      "training accuracy = 0.8283\n",
      "num_train_corrects / train_total_examples = 4970 / 6000\n",
      "num_test_corrects / test_total_examples = 4930 / 6000\n",
      "testing accuracy = 0.8217\n",
      "--------- epoch: 526 ---------\n",
      "training loss = 0.4072\n",
      "training accuracy = 0.8285\n",
      "num_train_corrects / train_total_examples = 4971 / 6000\n",
      "num_test_corrects / test_total_examples = 4931 / 6000\n",
      "testing accuracy = 0.8218\n",
      "--------- epoch: 527 ---------\n",
      "training loss = 0.4071\n",
      "training accuracy = 0.8285\n",
      "num_train_corrects / train_total_examples = 4971 / 6000\n",
      "num_test_corrects / test_total_examples = 4933 / 6000\n",
      "testing accuracy = 0.8222\n",
      "--------- epoch: 528 ---------\n",
      "training loss = 0.4071\n",
      "training accuracy = 0.8285\n",
      "num_train_corrects / train_total_examples = 4971 / 6000\n",
      "num_test_corrects / test_total_examples = 4935 / 6000\n",
      "testing accuracy = 0.8225\n",
      "--------- epoch: 529 ---------\n",
      "training loss = 0.4070\n",
      "training accuracy = 0.8285\n",
      "num_train_corrects / train_total_examples = 4971 / 6000\n",
      "num_test_corrects / test_total_examples = 4935 / 6000\n",
      "testing accuracy = 0.8225\n",
      "--------- epoch: 530 ---------\n",
      "training loss = 0.4070\n",
      "training accuracy = 0.8287\n",
      "num_train_corrects / train_total_examples = 4972 / 6000\n",
      "num_test_corrects / test_total_examples = 4934 / 6000\n",
      "testing accuracy = 0.8223\n",
      "--------- epoch: 531 ---------\n",
      "training loss = 0.4069\n",
      "training accuracy = 0.8287\n",
      "num_train_corrects / train_total_examples = 4972 / 6000\n",
      "num_test_corrects / test_total_examples = 4934 / 6000\n",
      "testing accuracy = 0.8223\n",
      "--------- epoch: 532 ---------\n",
      "training loss = 0.4069\n",
      "training accuracy = 0.8287\n",
      "num_train_corrects / train_total_examples = 4972 / 6000\n",
      "num_test_corrects / test_total_examples = 4935 / 6000\n",
      "testing accuracy = 0.8225\n",
      "--------- epoch: 533 ---------\n",
      "training loss = 0.4068\n",
      "training accuracy = 0.8287\n",
      "num_train_corrects / train_total_examples = 4972 / 6000\n",
      "num_test_corrects / test_total_examples = 4935 / 6000\n",
      "testing accuracy = 0.8225\n",
      "--------- epoch: 534 ---------\n",
      "training loss = 0.4068\n",
      "training accuracy = 0.8288\n",
      "num_train_corrects / train_total_examples = 4973 / 6000\n",
      "num_test_corrects / test_total_examples = 4935 / 6000\n",
      "testing accuracy = 0.8225\n",
      "--------- epoch: 535 ---------\n",
      "training loss = 0.4067\n",
      "training accuracy = 0.8290\n",
      "num_train_corrects / train_total_examples = 4974 / 6000\n",
      "num_test_corrects / test_total_examples = 4935 / 6000\n",
      "testing accuracy = 0.8225\n",
      "--------- epoch: 536 ---------\n",
      "training loss = 0.4067\n",
      "training accuracy = 0.8290\n",
      "num_train_corrects / train_total_examples = 4974 / 6000\n",
      "num_test_corrects / test_total_examples = 4935 / 6000\n",
      "testing accuracy = 0.8225\n",
      "--------- epoch: 537 ---------\n",
      "training loss = 0.4066\n",
      "training accuracy = 0.8293\n",
      "num_train_corrects / train_total_examples = 4976 / 6000\n",
      "num_test_corrects / test_total_examples = 4934 / 6000\n",
      "testing accuracy = 0.8223\n",
      "--------- epoch: 538 ---------\n",
      "training loss = 0.4066\n",
      "training accuracy = 0.8293\n",
      "num_train_corrects / train_total_examples = 4976 / 6000\n",
      "num_test_corrects / test_total_examples = 4936 / 6000\n",
      "testing accuracy = 0.8227\n",
      "--------- epoch: 539 ---------\n",
      "training loss = 0.4065\n",
      "training accuracy = 0.8295\n",
      "num_train_corrects / train_total_examples = 4977 / 6000\n",
      "num_test_corrects / test_total_examples = 4936 / 6000\n",
      "testing accuracy = 0.8227\n",
      "--------- epoch: 540 ---------\n",
      "training loss = 0.4065\n",
      "training accuracy = 0.8297\n",
      "num_train_corrects / train_total_examples = 4978 / 6000\n",
      "num_test_corrects / test_total_examples = 4937 / 6000\n",
      "testing accuracy = 0.8228\n",
      "--------- epoch: 541 ---------\n",
      "training loss = 0.4065\n",
      "training accuracy = 0.8297\n",
      "num_train_corrects / train_total_examples = 4978 / 6000\n",
      "num_test_corrects / test_total_examples = 4938 / 6000\n",
      "testing accuracy = 0.8230\n",
      "--------- epoch: 542 ---------\n",
      "training loss = 0.4064\n",
      "training accuracy = 0.8297\n",
      "num_train_corrects / train_total_examples = 4978 / 6000\n",
      "num_test_corrects / test_total_examples = 4942 / 6000\n",
      "testing accuracy = 0.8237\n",
      "--------- epoch: 543 ---------\n",
      "training loss = 0.4064\n",
      "training accuracy = 0.8297\n",
      "num_train_corrects / train_total_examples = 4978 / 6000\n",
      "num_test_corrects / test_total_examples = 4943 / 6000\n",
      "testing accuracy = 0.8238\n",
      "--------- epoch: 544 ---------\n",
      "training loss = 0.4063\n",
      "training accuracy = 0.8298\n",
      "num_train_corrects / train_total_examples = 4979 / 6000\n",
      "num_test_corrects / test_total_examples = 4943 / 6000\n",
      "testing accuracy = 0.8238\n",
      "--------- epoch: 545 ---------\n",
      "training loss = 0.4063\n",
      "training accuracy = 0.8300\n",
      "num_train_corrects / train_total_examples = 4980 / 6000\n",
      "num_test_corrects / test_total_examples = 4943 / 6000\n",
      "testing accuracy = 0.8238\n",
      "--------- epoch: 546 ---------\n",
      "training loss = 0.4062\n",
      "training accuracy = 0.8303\n",
      "num_train_corrects / train_total_examples = 4982 / 6000\n",
      "num_test_corrects / test_total_examples = 4943 / 6000\n",
      "testing accuracy = 0.8238\n",
      "--------- epoch: 547 ---------\n",
      "training loss = 0.4062\n",
      "training accuracy = 0.8303\n",
      "num_train_corrects / train_total_examples = 4982 / 6000\n",
      "num_test_corrects / test_total_examples = 4944 / 6000\n",
      "testing accuracy = 0.8240\n",
      "--------- epoch: 548 ---------\n",
      "training loss = 0.4061\n",
      "training accuracy = 0.8305\n",
      "num_train_corrects / train_total_examples = 4983 / 6000\n",
      "num_test_corrects / test_total_examples = 4944 / 6000\n",
      "testing accuracy = 0.8240\n",
      "--------- epoch: 549 ---------\n",
      "training loss = 0.4061\n",
      "training accuracy = 0.8305\n",
      "num_train_corrects / train_total_examples = 4983 / 6000\n",
      "num_test_corrects / test_total_examples = 4944 / 6000\n",
      "testing accuracy = 0.8240\n",
      "--------- epoch: 550 ---------\n",
      "training loss = 0.4060\n",
      "training accuracy = 0.8305\n",
      "num_train_corrects / train_total_examples = 4983 / 6000\n",
      "num_test_corrects / test_total_examples = 4944 / 6000\n",
      "testing accuracy = 0.8240\n",
      "--------- epoch: 551 ---------\n",
      "training loss = 0.4060\n",
      "training accuracy = 0.8305\n",
      "num_train_corrects / train_total_examples = 4983 / 6000\n",
      "num_test_corrects / test_total_examples = 4943 / 6000\n",
      "testing accuracy = 0.8238\n",
      "--------- epoch: 552 ---------\n",
      "training loss = 0.4059\n",
      "training accuracy = 0.8305\n",
      "num_train_corrects / train_total_examples = 4983 / 6000\n",
      "num_test_corrects / test_total_examples = 4943 / 6000\n",
      "testing accuracy = 0.8238\n",
      "--------- epoch: 553 ---------\n",
      "training loss = 0.4059\n",
      "training accuracy = 0.8305\n",
      "num_train_corrects / train_total_examples = 4983 / 6000\n",
      "num_test_corrects / test_total_examples = 4943 / 6000\n",
      "testing accuracy = 0.8238\n",
      "--------- epoch: 554 ---------\n",
      "training loss = 0.4058\n",
      "training accuracy = 0.8307\n",
      "num_train_corrects / train_total_examples = 4984 / 6000\n",
      "num_test_corrects / test_total_examples = 4943 / 6000\n",
      "testing accuracy = 0.8238\n",
      "--------- epoch: 555 ---------\n",
      "training loss = 0.4058\n",
      "training accuracy = 0.8307\n",
      "num_train_corrects / train_total_examples = 4984 / 6000\n",
      "num_test_corrects / test_total_examples = 4943 / 6000\n",
      "testing accuracy = 0.8238\n",
      "--------- epoch: 556 ---------\n",
      "training loss = 0.4058\n",
      "training accuracy = 0.8307\n",
      "num_train_corrects / train_total_examples = 4984 / 6000\n",
      "num_test_corrects / test_total_examples = 4945 / 6000\n",
      "testing accuracy = 0.8242\n",
      "--------- epoch: 557 ---------\n",
      "training loss = 0.4057\n",
      "training accuracy = 0.8307\n",
      "num_train_corrects / train_total_examples = 4984 / 6000\n",
      "num_test_corrects / test_total_examples = 4945 / 6000\n",
      "testing accuracy = 0.8242\n",
      "--------- epoch: 558 ---------\n",
      "training loss = 0.4057\n",
      "training accuracy = 0.8307\n",
      "num_train_corrects / train_total_examples = 4984 / 6000\n",
      "num_test_corrects / test_total_examples = 4945 / 6000\n",
      "testing accuracy = 0.8242\n",
      "--------- epoch: 559 ---------\n",
      "training loss = 0.4056\n",
      "training accuracy = 0.8307\n",
      "num_train_corrects / train_total_examples = 4984 / 6000\n",
      "num_test_corrects / test_total_examples = 4946 / 6000\n",
      "testing accuracy = 0.8243\n",
      "--------- epoch: 560 ---------\n",
      "training loss = 0.4056\n",
      "training accuracy = 0.8307\n",
      "num_train_corrects / train_total_examples = 4984 / 6000\n",
      "num_test_corrects / test_total_examples = 4946 / 6000\n",
      "testing accuracy = 0.8243\n",
      "--------- epoch: 561 ---------\n",
      "training loss = 0.4055\n",
      "training accuracy = 0.8310\n",
      "num_train_corrects / train_total_examples = 4986 / 6000\n",
      "num_test_corrects / test_total_examples = 4946 / 6000\n",
      "testing accuracy = 0.8243\n",
      "--------- epoch: 562 ---------\n",
      "training loss = 0.4055\n",
      "training accuracy = 0.8310\n",
      "num_train_corrects / train_total_examples = 4986 / 6000\n",
      "num_test_corrects / test_total_examples = 4947 / 6000\n",
      "testing accuracy = 0.8245\n",
      "--------- epoch: 563 ---------\n",
      "training loss = 0.4054\n",
      "training accuracy = 0.8310\n",
      "num_train_corrects / train_total_examples = 4986 / 6000\n",
      "num_test_corrects / test_total_examples = 4947 / 6000\n",
      "testing accuracy = 0.8245\n",
      "--------- epoch: 564 ---------\n",
      "training loss = 0.4054\n",
      "training accuracy = 0.8310\n",
      "num_train_corrects / train_total_examples = 4986 / 6000\n",
      "num_test_corrects / test_total_examples = 4947 / 6000\n",
      "testing accuracy = 0.8245\n",
      "--------- epoch: 565 ---------\n",
      "training loss = 0.4053\n",
      "training accuracy = 0.8310\n",
      "num_train_corrects / train_total_examples = 4986 / 6000\n",
      "num_test_corrects / test_total_examples = 4947 / 6000\n",
      "testing accuracy = 0.8245\n",
      "--------- epoch: 566 ---------\n",
      "training loss = 0.4053\n",
      "training accuracy = 0.8310\n",
      "num_train_corrects / train_total_examples = 4986 / 6000\n",
      "num_test_corrects / test_total_examples = 4948 / 6000\n",
      "testing accuracy = 0.8247\n",
      "--------- epoch: 567 ---------\n",
      "training loss = 0.4053\n",
      "training accuracy = 0.8310\n",
      "num_train_corrects / train_total_examples = 4986 / 6000\n",
      "num_test_corrects / test_total_examples = 4948 / 6000\n",
      "testing accuracy = 0.8247\n",
      "--------- epoch: 568 ---------\n",
      "training loss = 0.4052\n",
      "training accuracy = 0.8312\n",
      "num_train_corrects / train_total_examples = 4987 / 6000\n",
      "num_test_corrects / test_total_examples = 4948 / 6000\n",
      "testing accuracy = 0.8247\n",
      "--------- epoch: 569 ---------\n",
      "training loss = 0.4052\n",
      "training accuracy = 0.8312\n",
      "num_train_corrects / train_total_examples = 4987 / 6000\n",
      "num_test_corrects / test_total_examples = 4948 / 6000\n",
      "testing accuracy = 0.8247\n",
      "--------- epoch: 570 ---------\n",
      "training loss = 0.4051\n",
      "training accuracy = 0.8312\n",
      "num_train_corrects / train_total_examples = 4987 / 6000\n",
      "num_test_corrects / test_total_examples = 4948 / 6000\n",
      "testing accuracy = 0.8247\n",
      "--------- epoch: 571 ---------\n",
      "training loss = 0.4051\n",
      "training accuracy = 0.8313\n",
      "num_train_corrects / train_total_examples = 4988 / 6000\n",
      "num_test_corrects / test_total_examples = 4948 / 6000\n",
      "testing accuracy = 0.8247\n",
      "--------- epoch: 572 ---------\n",
      "training loss = 0.4050\n",
      "training accuracy = 0.8313\n",
      "num_train_corrects / train_total_examples = 4988 / 6000\n",
      "num_test_corrects / test_total_examples = 4948 / 6000\n",
      "testing accuracy = 0.8247\n",
      "--------- epoch: 573 ---------\n",
      "training loss = 0.4050\n",
      "training accuracy = 0.8313\n",
      "num_train_corrects / train_total_examples = 4988 / 6000\n",
      "num_test_corrects / test_total_examples = 4949 / 6000\n",
      "testing accuracy = 0.8248\n",
      "--------- epoch: 574 ---------\n",
      "training loss = 0.4049\n",
      "training accuracy = 0.8315\n",
      "num_train_corrects / train_total_examples = 4989 / 6000\n",
      "num_test_corrects / test_total_examples = 4949 / 6000\n",
      "testing accuracy = 0.8248\n",
      "--------- epoch: 575 ---------\n",
      "training loss = 0.4049\n",
      "training accuracy = 0.8317\n",
      "num_train_corrects / train_total_examples = 4990 / 6000\n",
      "num_test_corrects / test_total_examples = 4949 / 6000\n",
      "testing accuracy = 0.8248\n",
      "--------- epoch: 576 ---------\n",
      "training loss = 0.4049\n",
      "training accuracy = 0.8315\n",
      "num_train_corrects / train_total_examples = 4989 / 6000\n",
      "num_test_corrects / test_total_examples = 4949 / 6000\n",
      "testing accuracy = 0.8248\n",
      "--------- epoch: 577 ---------\n",
      "training loss = 0.4048\n",
      "training accuracy = 0.8315\n",
      "num_train_corrects / train_total_examples = 4989 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 578 ---------\n",
      "training loss = 0.4048\n",
      "training accuracy = 0.8315\n",
      "num_train_corrects / train_total_examples = 4989 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 579 ---------\n",
      "training loss = 0.4047\n",
      "training accuracy = 0.8315\n",
      "num_train_corrects / train_total_examples = 4989 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 580 ---------\n",
      "training loss = 0.4047\n",
      "training accuracy = 0.8317\n",
      "num_train_corrects / train_total_examples = 4990 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 581 ---------\n",
      "training loss = 0.4046\n",
      "training accuracy = 0.8317\n",
      "num_train_corrects / train_total_examples = 4990 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 582 ---------\n",
      "training loss = 0.4046\n",
      "training accuracy = 0.8318\n",
      "num_train_corrects / train_total_examples = 4991 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 583 ---------\n",
      "training loss = 0.4046\n",
      "training accuracy = 0.8318\n",
      "num_train_corrects / train_total_examples = 4991 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 584 ---------\n",
      "training loss = 0.4045\n",
      "training accuracy = 0.8318\n",
      "num_train_corrects / train_total_examples = 4991 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 585 ---------\n",
      "training loss = 0.4045\n",
      "training accuracy = 0.8318\n",
      "num_train_corrects / train_total_examples = 4991 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 586 ---------\n",
      "training loss = 0.4044\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 587 ---------\n",
      "training loss = 0.4044\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 588 ---------\n",
      "training loss = 0.4043\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 589 ---------\n",
      "training loss = 0.4043\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4950 / 6000\n",
      "testing accuracy = 0.8250\n",
      "--------- epoch: 590 ---------\n",
      "training loss = 0.4043\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4949 / 6000\n",
      "testing accuracy = 0.8248\n",
      "--------- epoch: 591 ---------\n",
      "training loss = 0.4042\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4949 / 6000\n",
      "testing accuracy = 0.8248\n",
      "--------- epoch: 592 ---------\n",
      "training loss = 0.4042\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4950 / 6000\n",
      "testing accuracy = 0.8250\n",
      "--------- epoch: 593 ---------\n",
      "training loss = 0.4041\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4950 / 6000\n",
      "testing accuracy = 0.8250\n",
      "--------- epoch: 594 ---------\n",
      "training loss = 0.4041\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 595 ---------\n",
      "training loss = 0.4040\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 596 ---------\n",
      "training loss = 0.4040\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4951 / 6000\n",
      "testing accuracy = 0.8252\n",
      "--------- epoch: 597 ---------\n",
      "training loss = 0.4040\n",
      "training accuracy = 0.8322\n",
      "num_train_corrects / train_total_examples = 4993 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 598 ---------\n",
      "training loss = 0.4039\n",
      "training accuracy = 0.8322\n",
      "num_train_corrects / train_total_examples = 4993 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 599 ---------\n",
      "training loss = 0.4039\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 600 ---------\n",
      "training loss = 0.4038\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 601 ---------\n",
      "training loss = 0.4038\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 602 ---------\n",
      "training loss = 0.4037\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4953 / 6000\n",
      "testing accuracy = 0.8255\n",
      "--------- epoch: 603 ---------\n",
      "training loss = 0.4037\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4953 / 6000\n",
      "testing accuracy = 0.8255\n",
      "--------- epoch: 604 ---------\n",
      "training loss = 0.4037\n",
      "training accuracy = 0.8320\n",
      "num_train_corrects / train_total_examples = 4992 / 6000\n",
      "num_test_corrects / test_total_examples = 4953 / 6000\n",
      "testing accuracy = 0.8255\n",
      "--------- epoch: 605 ---------\n",
      "training loss = 0.4036\n",
      "training accuracy = 0.8322\n",
      "num_train_corrects / train_total_examples = 4993 / 6000\n",
      "num_test_corrects / test_total_examples = 4953 / 6000\n",
      "testing accuracy = 0.8255\n",
      "--------- epoch: 606 ---------\n",
      "training loss = 0.4036\n",
      "training accuracy = 0.8323\n",
      "num_train_corrects / train_total_examples = 4994 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 607 ---------\n",
      "training loss = 0.4035\n",
      "training accuracy = 0.8323\n",
      "num_train_corrects / train_total_examples = 4994 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 608 ---------\n",
      "training loss = 0.4035\n",
      "training accuracy = 0.8323\n",
      "num_train_corrects / train_total_examples = 4994 / 6000\n",
      "num_test_corrects / test_total_examples = 4953 / 6000\n",
      "testing accuracy = 0.8255\n",
      "--------- epoch: 609 ---------\n",
      "training loss = 0.4034\n",
      "training accuracy = 0.8322\n",
      "num_train_corrects / train_total_examples = 4993 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 610 ---------\n",
      "training loss = 0.4034\n",
      "training accuracy = 0.8322\n",
      "num_train_corrects / train_total_examples = 4993 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 611 ---------\n",
      "training loss = 0.4034\n",
      "training accuracy = 0.8322\n",
      "num_train_corrects / train_total_examples = 4993 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 612 ---------\n",
      "training loss = 0.4033\n",
      "training accuracy = 0.8322\n",
      "num_train_corrects / train_total_examples = 4993 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 613 ---------\n",
      "training loss = 0.4033\n",
      "training accuracy = 0.8322\n",
      "num_train_corrects / train_total_examples = 4993 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 614 ---------\n",
      "training loss = 0.4032\n",
      "training accuracy = 0.8323\n",
      "num_train_corrects / train_total_examples = 4994 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 615 ---------\n",
      "training loss = 0.4032\n",
      "training accuracy = 0.8323\n",
      "num_train_corrects / train_total_examples = 4994 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 616 ---------\n",
      "training loss = 0.4032\n",
      "training accuracy = 0.8323\n",
      "num_train_corrects / train_total_examples = 4994 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 617 ---------\n",
      "training loss = 0.4031\n",
      "training accuracy = 0.8323\n",
      "num_train_corrects / train_total_examples = 4994 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 618 ---------\n",
      "training loss = 0.4031\n",
      "training accuracy = 0.8323\n",
      "num_train_corrects / train_total_examples = 4994 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 619 ---------\n",
      "training loss = 0.4030\n",
      "training accuracy = 0.8325\n",
      "num_train_corrects / train_total_examples = 4995 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 620 ---------\n",
      "training loss = 0.4030\n",
      "training accuracy = 0.8325\n",
      "num_train_corrects / train_total_examples = 4995 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 621 ---------\n",
      "training loss = 0.4030\n",
      "training accuracy = 0.8325\n",
      "num_train_corrects / train_total_examples = 4995 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 622 ---------\n",
      "training loss = 0.4029\n",
      "training accuracy = 0.8325\n",
      "num_train_corrects / train_total_examples = 4995 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 623 ---------\n",
      "training loss = 0.4029\n",
      "training accuracy = 0.8325\n",
      "num_train_corrects / train_total_examples = 4995 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 624 ---------\n",
      "training loss = 0.4028\n",
      "training accuracy = 0.8325\n",
      "num_train_corrects / train_total_examples = 4995 / 6000\n",
      "num_test_corrects / test_total_examples = 4952 / 6000\n",
      "testing accuracy = 0.8253\n",
      "--------- epoch: 625 ---------\n",
      "training loss = 0.4028\n",
      "training accuracy = 0.8325\n",
      "num_train_corrects / train_total_examples = 4995 / 6000\n",
      "num_test_corrects / test_total_examples = 4953 / 6000\n",
      "testing accuracy = 0.8255\n",
      "--------- epoch: 626 ---------\n",
      "training loss = 0.4028\n",
      "training accuracy = 0.8327\n",
      "num_train_corrects / train_total_examples = 4996 / 6000\n",
      "num_test_corrects / test_total_examples = 4953 / 6000\n",
      "testing accuracy = 0.8255\n",
      "--------- epoch: 627 ---------\n",
      "training loss = 0.4027\n",
      "training accuracy = 0.8327\n",
      "num_train_corrects / train_total_examples = 4996 / 6000\n",
      "num_test_corrects / test_total_examples = 4953 / 6000\n",
      "testing accuracy = 0.8255\n",
      "--------- epoch: 628 ---------\n",
      "training loss = 0.4027\n",
      "training accuracy = 0.8327\n",
      "num_train_corrects / train_total_examples = 4996 / 6000\n",
      "num_test_corrects / test_total_examples = 4954 / 6000\n",
      "testing accuracy = 0.8257\n",
      "--------- epoch: 629 ---------\n",
      "training loss = 0.4026\n",
      "training accuracy = 0.8327\n",
      "num_train_corrects / train_total_examples = 4996 / 6000\n",
      "num_test_corrects / test_total_examples = 4955 / 6000\n",
      "testing accuracy = 0.8258\n",
      "--------- epoch: 630 ---------\n",
      "training loss = 0.4026\n",
      "training accuracy = 0.8328\n",
      "num_train_corrects / train_total_examples = 4997 / 6000\n",
      "num_test_corrects / test_total_examples = 4955 / 6000\n",
      "testing accuracy = 0.8258\n",
      "--------- epoch: 631 ---------\n",
      "training loss = 0.4026\n",
      "training accuracy = 0.8328\n",
      "num_train_corrects / train_total_examples = 4997 / 6000\n",
      "num_test_corrects / test_total_examples = 4955 / 6000\n",
      "testing accuracy = 0.8258\n",
      "--------- epoch: 632 ---------\n",
      "training loss = 0.4025\n",
      "training accuracy = 0.8328\n",
      "num_train_corrects / train_total_examples = 4997 / 6000\n",
      "num_test_corrects / test_total_examples = 4955 / 6000\n",
      "testing accuracy = 0.8258\n",
      "--------- epoch: 633 ---------\n",
      "training loss = 0.4025\n",
      "training accuracy = 0.8330\n",
      "num_train_corrects / train_total_examples = 4998 / 6000\n",
      "num_test_corrects / test_total_examples = 4955 / 6000\n",
      "testing accuracy = 0.8258\n",
      "--------- epoch: 634 ---------\n",
      "training loss = 0.4024\n",
      "training accuracy = 0.8330\n",
      "num_train_corrects / train_total_examples = 4998 / 6000\n",
      "num_test_corrects / test_total_examples = 4955 / 6000\n",
      "testing accuracy = 0.8258\n",
      "--------- epoch: 635 ---------\n",
      "training loss = 0.4024\n",
      "training accuracy = 0.8330\n",
      "num_train_corrects / train_total_examples = 4998 / 6000\n",
      "num_test_corrects / test_total_examples = 4955 / 6000\n",
      "testing accuracy = 0.8258\n",
      "--------- epoch: 636 ---------\n",
      "training loss = 0.4024\n",
      "training accuracy = 0.8330\n",
      "num_train_corrects / train_total_examples = 4998 / 6000\n",
      "num_test_corrects / test_total_examples = 4955 / 6000\n",
      "testing accuracy = 0.8258\n",
      "--------- epoch: 637 ---------\n",
      "training loss = 0.4023\n",
      "training accuracy = 0.8330\n",
      "num_train_corrects / train_total_examples = 4998 / 6000\n",
      "num_test_corrects / test_total_examples = 4955 / 6000\n",
      "testing accuracy = 0.8258\n",
      "--------- epoch: 638 ---------\n",
      "training loss = 0.4023\n",
      "training accuracy = 0.8330\n",
      "num_train_corrects / train_total_examples = 4998 / 6000\n",
      "num_test_corrects / test_total_examples = 4956 / 6000\n",
      "testing accuracy = 0.8260\n",
      "--------- epoch: 639 ---------\n",
      "training loss = 0.4022\n",
      "training accuracy = 0.8328\n",
      "num_train_corrects / train_total_examples = 4997 / 6000\n",
      "num_test_corrects / test_total_examples = 4956 / 6000\n",
      "testing accuracy = 0.8260\n",
      "--------- epoch: 640 ---------\n",
      "training loss = 0.4022\n",
      "training accuracy = 0.8328\n",
      "num_train_corrects / train_total_examples = 4997 / 6000\n",
      "num_test_corrects / test_total_examples = 4956 / 6000\n",
      "testing accuracy = 0.8260\n",
      "--------- epoch: 641 ---------\n",
      "training loss = 0.4022\n",
      "training accuracy = 0.8328\n",
      "num_train_corrects / train_total_examples = 4997 / 6000\n",
      "num_test_corrects / test_total_examples = 4956 / 6000\n",
      "testing accuracy = 0.8260\n",
      "--------- epoch: 642 ---------\n",
      "training loss = 0.4021\n",
      "training accuracy = 0.8330\n",
      "num_train_corrects / train_total_examples = 4998 / 6000\n",
      "num_test_corrects / test_total_examples = 4956 / 6000\n",
      "testing accuracy = 0.8260\n",
      "--------- epoch: 643 ---------\n",
      "training loss = 0.4021\n",
      "training accuracy = 0.8330\n",
      "num_train_corrects / train_total_examples = 4998 / 6000\n",
      "num_test_corrects / test_total_examples = 4955 / 6000\n",
      "testing accuracy = 0.8258\n",
      "--------- epoch: 644 ---------\n",
      "training loss = 0.4020\n",
      "training accuracy = 0.8330\n",
      "num_train_corrects / train_total_examples = 4998 / 6000\n",
      "num_test_corrects / test_total_examples = 4956 / 6000\n",
      "testing accuracy = 0.8260\n",
      "--------- epoch: 645 ---------\n",
      "training loss = 0.4020\n",
      "training accuracy = 0.8332\n",
      "num_train_corrects / train_total_examples = 4999 / 6000\n",
      "num_test_corrects / test_total_examples = 4956 / 6000\n",
      "testing accuracy = 0.8260\n",
      "--------- epoch: 646 ---------\n",
      "training loss = 0.4020\n",
      "training accuracy = 0.8333\n",
      "num_train_corrects / train_total_examples = 5000 / 6000\n",
      "num_test_corrects / test_total_examples = 4955 / 6000\n",
      "testing accuracy = 0.8258\n",
      "--------- epoch: 647 ---------\n",
      "training loss = 0.4019\n",
      "training accuracy = 0.8333\n",
      "num_train_corrects / train_total_examples = 5000 / 6000\n",
      "num_test_corrects / test_total_examples = 4955 / 6000\n",
      "testing accuracy = 0.8258\n",
      "--------- epoch: 648 ---------\n",
      "training loss = 0.4019\n",
      "training accuracy = 0.8333\n",
      "num_train_corrects / train_total_examples = 5000 / 6000\n",
      "num_test_corrects / test_total_examples = 4956 / 6000\n",
      "testing accuracy = 0.8260\n",
      "--------- epoch: 649 ---------\n",
      "training loss = 0.4018\n",
      "training accuracy = 0.8335\n",
      "num_train_corrects / train_total_examples = 5001 / 6000\n",
      "num_test_corrects / test_total_examples = 4956 / 6000\n",
      "testing accuracy = 0.8260\n",
      "--------- epoch: 650 ---------\n",
      "training loss = 0.4018\n",
      "training accuracy = 0.8333\n",
      "num_train_corrects / train_total_examples = 5000 / 6000\n",
      "num_test_corrects / test_total_examples = 4955 / 6000\n",
      "testing accuracy = 0.8258\n",
      "--------- epoch: 651 ---------\n",
      "training loss = 0.4018\n",
      "training accuracy = 0.8332\n",
      "num_train_corrects / train_total_examples = 4999 / 6000\n",
      "num_test_corrects / test_total_examples = 4955 / 6000\n",
      "testing accuracy = 0.8258\n",
      "--------- epoch: 652 ---------\n",
      "training loss = 0.4017\n",
      "training accuracy = 0.8333\n",
      "num_train_corrects / train_total_examples = 5000 / 6000\n",
      "num_test_corrects / test_total_examples = 4954 / 6000\n",
      "testing accuracy = 0.8257\n",
      "--------- epoch: 653 ---------\n",
      "training loss = 0.4017\n",
      "training accuracy = 0.8333\n",
      "num_train_corrects / train_total_examples = 5000 / 6000\n",
      "num_test_corrects / test_total_examples = 4954 / 6000\n",
      "testing accuracy = 0.8257\n",
      "--------- epoch: 654 ---------\n",
      "training loss = 0.4016\n",
      "training accuracy = 0.8333\n",
      "num_train_corrects / train_total_examples = 5000 / 6000\n",
      "num_test_corrects / test_total_examples = 4954 / 6000\n",
      "testing accuracy = 0.8257\n",
      "--------- epoch: 655 ---------\n",
      "training loss = 0.4016\n",
      "training accuracy = 0.8333\n",
      "num_train_corrects / train_total_examples = 5000 / 6000\n",
      "num_test_corrects / test_total_examples = 4957 / 6000\n",
      "testing accuracy = 0.8262\n",
      "--------- epoch: 656 ---------\n",
      "training loss = 0.4016\n",
      "training accuracy = 0.8333\n",
      "num_train_corrects / train_total_examples = 5000 / 6000\n",
      "num_test_corrects / test_total_examples = 4957 / 6000\n",
      "testing accuracy = 0.8262\n",
      "--------- epoch: 657 ---------\n",
      "training loss = 0.4015\n",
      "training accuracy = 0.8333\n",
      "num_train_corrects / train_total_examples = 5000 / 6000\n",
      "num_test_corrects / test_total_examples = 4957 / 6000\n",
      "testing accuracy = 0.8262\n",
      "--------- epoch: 658 ---------\n",
      "training loss = 0.4015\n",
      "training accuracy = 0.8335\n",
      "num_train_corrects / train_total_examples = 5001 / 6000\n",
      "num_test_corrects / test_total_examples = 4957 / 6000\n",
      "testing accuracy = 0.8262\n",
      "--------- epoch: 659 ---------\n",
      "training loss = 0.4015\n",
      "training accuracy = 0.8335\n",
      "num_train_corrects / train_total_examples = 5001 / 6000\n",
      "num_test_corrects / test_total_examples = 4957 / 6000\n",
      "testing accuracy = 0.8262\n",
      "--------- epoch: 660 ---------\n",
      "training loss = 0.4014\n",
      "training accuracy = 0.8335\n",
      "num_train_corrects / train_total_examples = 5001 / 6000\n",
      "num_test_corrects / test_total_examples = 4957 / 6000\n",
      "testing accuracy = 0.8262\n",
      "--------- epoch: 661 ---------\n",
      "training loss = 0.4014\n",
      "training accuracy = 0.8335\n",
      "num_train_corrects / train_total_examples = 5001 / 6000\n",
      "num_test_corrects / test_total_examples = 4957 / 6000\n",
      "testing accuracy = 0.8262\n",
      "--------- epoch: 662 ---------\n",
      "training loss = 0.4013\n",
      "training accuracy = 0.8335\n",
      "num_train_corrects / train_total_examples = 5001 / 6000\n",
      "num_test_corrects / test_total_examples = 4957 / 6000\n",
      "testing accuracy = 0.8262\n",
      "--------- epoch: 663 ---------\n",
      "training loss = 0.4013\n",
      "training accuracy = 0.8335\n",
      "num_train_corrects / train_total_examples = 5001 / 6000\n",
      "num_test_corrects / test_total_examples = 4957 / 6000\n",
      "testing accuracy = 0.8262\n",
      "--------- epoch: 664 ---------\n",
      "training loss = 0.4013\n",
      "training accuracy = 0.8335\n",
      "num_train_corrects / train_total_examples = 5001 / 6000\n",
      "num_test_corrects / test_total_examples = 4957 / 6000\n",
      "testing accuracy = 0.8262\n",
      "--------- epoch: 665 ---------\n",
      "training loss = 0.4012\n",
      "training accuracy = 0.8335\n",
      "num_train_corrects / train_total_examples = 5001 / 6000\n",
      "num_test_corrects / test_total_examples = 4957 / 6000\n",
      "testing accuracy = 0.8262\n",
      "--------- epoch: 666 ---------\n",
      "training loss = 0.4012\n",
      "training accuracy = 0.8333\n",
      "num_train_corrects / train_total_examples = 5000 / 6000\n",
      "num_test_corrects / test_total_examples = 4958 / 6000\n",
      "testing accuracy = 0.8263\n",
      "--------- epoch: 667 ---------\n",
      "training loss = 0.4012\n",
      "training accuracy = 0.8333\n",
      "num_train_corrects / train_total_examples = 5000 / 6000\n",
      "num_test_corrects / test_total_examples = 4958 / 6000\n",
      "testing accuracy = 0.8263\n",
      "--------- epoch: 668 ---------\n",
      "training loss = 0.4011\n",
      "training accuracy = 0.8333\n",
      "num_train_corrects / train_total_examples = 5000 / 6000\n",
      "num_test_corrects / test_total_examples = 4958 / 6000\n",
      "testing accuracy = 0.8263\n",
      "--------- epoch: 669 ---------\n",
      "training loss = 0.4011\n",
      "training accuracy = 0.8335\n",
      "num_train_corrects / train_total_examples = 5001 / 6000\n",
      "num_test_corrects / test_total_examples = 4958 / 6000\n",
      "testing accuracy = 0.8263\n",
      "--------- epoch: 670 ---------\n",
      "training loss = 0.4010\n",
      "training accuracy = 0.8335\n",
      "num_train_corrects / train_total_examples = 5001 / 6000\n",
      "num_test_corrects / test_total_examples = 4958 / 6000\n",
      "testing accuracy = 0.8263\n",
      "--------- epoch: 671 ---------\n",
      "training loss = 0.4010\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4958 / 6000\n",
      "testing accuracy = 0.8263\n",
      "--------- epoch: 672 ---------\n",
      "training loss = 0.4010\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4958 / 6000\n",
      "testing accuracy = 0.8263\n",
      "--------- epoch: 673 ---------\n",
      "training loss = 0.4009\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4958 / 6000\n",
      "testing accuracy = 0.8263\n",
      "--------- epoch: 674 ---------\n",
      "training loss = 0.4009\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4959 / 6000\n",
      "testing accuracy = 0.8265\n",
      "--------- epoch: 675 ---------\n",
      "training loss = 0.4009\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4959 / 6000\n",
      "testing accuracy = 0.8265\n",
      "--------- epoch: 676 ---------\n",
      "training loss = 0.4008\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4960 / 6000\n",
      "testing accuracy = 0.8267\n",
      "--------- epoch: 677 ---------\n",
      "training loss = 0.4008\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4960 / 6000\n",
      "testing accuracy = 0.8267\n",
      "--------- epoch: 678 ---------\n",
      "training loss = 0.4007\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4962 / 6000\n",
      "testing accuracy = 0.8270\n",
      "--------- epoch: 679 ---------\n",
      "training loss = 0.4007\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4962 / 6000\n",
      "testing accuracy = 0.8270\n",
      "--------- epoch: 680 ---------\n",
      "training loss = 0.4007\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4962 / 6000\n",
      "testing accuracy = 0.8270\n",
      "--------- epoch: 681 ---------\n",
      "training loss = 0.4006\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4963 / 6000\n",
      "testing accuracy = 0.8272\n",
      "--------- epoch: 682 ---------\n",
      "training loss = 0.4006\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4963 / 6000\n",
      "testing accuracy = 0.8272\n",
      "--------- epoch: 683 ---------\n",
      "training loss = 0.4006\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4963 / 6000\n",
      "testing accuracy = 0.8272\n",
      "--------- epoch: 684 ---------\n",
      "training loss = 0.4005\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4963 / 6000\n",
      "testing accuracy = 0.8272\n",
      "--------- epoch: 685 ---------\n",
      "training loss = 0.4005\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4963 / 6000\n",
      "testing accuracy = 0.8272\n",
      "--------- epoch: 686 ---------\n",
      "training loss = 0.4004\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4963 / 6000\n",
      "testing accuracy = 0.8272\n",
      "--------- epoch: 687 ---------\n",
      "training loss = 0.4004\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4963 / 6000\n",
      "testing accuracy = 0.8272\n",
      "--------- epoch: 688 ---------\n",
      "training loss = 0.4004\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4963 / 6000\n",
      "testing accuracy = 0.8272\n",
      "--------- epoch: 689 ---------\n",
      "training loss = 0.4003\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4964 / 6000\n",
      "testing accuracy = 0.8273\n",
      "--------- epoch: 690 ---------\n",
      "training loss = 0.4003\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4964 / 6000\n",
      "testing accuracy = 0.8273\n",
      "--------- epoch: 691 ---------\n",
      "training loss = 0.4003\n",
      "training accuracy = 0.8337\n",
      "num_train_corrects / train_total_examples = 5002 / 6000\n",
      "num_test_corrects / test_total_examples = 4964 / 6000\n",
      "testing accuracy = 0.8273\n",
      "--------- epoch: 692 ---------\n",
      "training loss = 0.4002\n",
      "training accuracy = 0.8338\n",
      "num_train_corrects / train_total_examples = 5003 / 6000\n",
      "num_test_corrects / test_total_examples = 4964 / 6000\n",
      "testing accuracy = 0.8273\n",
      "--------- epoch: 693 ---------\n",
      "training loss = 0.4002\n",
      "training accuracy = 0.8338\n",
      "num_train_corrects / train_total_examples = 5003 / 6000\n",
      "num_test_corrects / test_total_examples = 4964 / 6000\n",
      "testing accuracy = 0.8273\n",
      "--------- epoch: 694 ---------\n",
      "training loss = 0.4002\n",
      "training accuracy = 0.8340\n",
      "num_train_corrects / train_total_examples = 5004 / 6000\n",
      "num_test_corrects / test_total_examples = 4964 / 6000\n",
      "testing accuracy = 0.8273\n",
      "--------- epoch: 695 ---------\n",
      "training loss = 0.4001\n",
      "training accuracy = 0.8340\n",
      "num_train_corrects / train_total_examples = 5004 / 6000\n",
      "num_test_corrects / test_total_examples = 4964 / 6000\n",
      "testing accuracy = 0.8273\n",
      "--------- epoch: 696 ---------\n",
      "training loss = 0.4001\n",
      "training accuracy = 0.8340\n",
      "num_train_corrects / train_total_examples = 5004 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 697 ---------\n",
      "training loss = 0.4000\n",
      "training accuracy = 0.8340\n",
      "num_train_corrects / train_total_examples = 5004 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 698 ---------\n",
      "training loss = 0.4000\n",
      "training accuracy = 0.8342\n",
      "num_train_corrects / train_total_examples = 5005 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 699 ---------\n",
      "training loss = 0.4000\n",
      "training accuracy = 0.8342\n",
      "num_train_corrects / train_total_examples = 5005 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 700 ---------\n",
      "training loss = 0.3999\n",
      "training accuracy = 0.8342\n",
      "num_train_corrects / train_total_examples = 5005 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 701 ---------\n",
      "training loss = 0.3999\n",
      "training accuracy = 0.8342\n",
      "num_train_corrects / train_total_examples = 5005 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 702 ---------\n",
      "training loss = 0.3999\n",
      "training accuracy = 0.8342\n",
      "num_train_corrects / train_total_examples = 5005 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 703 ---------\n",
      "training loss = 0.3998\n",
      "training accuracy = 0.8342\n",
      "num_train_corrects / train_total_examples = 5005 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 704 ---------\n",
      "training loss = 0.3998\n",
      "training accuracy = 0.8345\n",
      "num_train_corrects / train_total_examples = 5007 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 705 ---------\n",
      "training loss = 0.3998\n",
      "training accuracy = 0.8345\n",
      "num_train_corrects / train_total_examples = 5007 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 706 ---------\n",
      "training loss = 0.3997\n",
      "training accuracy = 0.8345\n",
      "num_train_corrects / train_total_examples = 5007 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 707 ---------\n",
      "training loss = 0.3997\n",
      "training accuracy = 0.8345\n",
      "num_train_corrects / train_total_examples = 5007 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 708 ---------\n",
      "training loss = 0.3997\n",
      "training accuracy = 0.8343\n",
      "num_train_corrects / train_total_examples = 5006 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 709 ---------\n",
      "training loss = 0.3996\n",
      "training accuracy = 0.8345\n",
      "num_train_corrects / train_total_examples = 5007 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 710 ---------\n",
      "training loss = 0.3996\n",
      "training accuracy = 0.8345\n",
      "num_train_corrects / train_total_examples = 5007 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 711 ---------\n",
      "training loss = 0.3995\n",
      "training accuracy = 0.8345\n",
      "num_train_corrects / train_total_examples = 5007 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 712 ---------\n",
      "training loss = 0.3995\n",
      "training accuracy = 0.8345\n",
      "num_train_corrects / train_total_examples = 5007 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 713 ---------\n",
      "training loss = 0.3995\n",
      "training accuracy = 0.8345\n",
      "num_train_corrects / train_total_examples = 5007 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 714 ---------\n",
      "training loss = 0.3994\n",
      "training accuracy = 0.8345\n",
      "num_train_corrects / train_total_examples = 5007 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 715 ---------\n",
      "training loss = 0.3994\n",
      "training accuracy = 0.8345\n",
      "num_train_corrects / train_total_examples = 5007 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 716 ---------\n",
      "training loss = 0.3994\n",
      "training accuracy = 0.8345\n",
      "num_train_corrects / train_total_examples = 5007 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 717 ---------\n",
      "training loss = 0.3993\n",
      "training accuracy = 0.8347\n",
      "num_train_corrects / train_total_examples = 5008 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 718 ---------\n",
      "training loss = 0.3993\n",
      "training accuracy = 0.8347\n",
      "num_train_corrects / train_total_examples = 5008 / 6000\n",
      "num_test_corrects / test_total_examples = 4964 / 6000\n",
      "testing accuracy = 0.8273\n",
      "--------- epoch: 719 ---------\n",
      "training loss = 0.3993\n",
      "training accuracy = 0.8347\n",
      "num_train_corrects / train_total_examples = 5008 / 6000\n",
      "num_test_corrects / test_total_examples = 4964 / 6000\n",
      "testing accuracy = 0.8273\n",
      "--------- epoch: 720 ---------\n",
      "training loss = 0.3992\n",
      "training accuracy = 0.8347\n",
      "num_train_corrects / train_total_examples = 5008 / 6000\n",
      "num_test_corrects / test_total_examples = 4964 / 6000\n",
      "testing accuracy = 0.8273\n",
      "--------- epoch: 721 ---------\n",
      "training loss = 0.3992\n",
      "training accuracy = 0.8347\n",
      "num_train_corrects / train_total_examples = 5008 / 6000\n",
      "num_test_corrects / test_total_examples = 4964 / 6000\n",
      "testing accuracy = 0.8273\n",
      "--------- epoch: 722 ---------\n",
      "training loss = 0.3992\n",
      "training accuracy = 0.8347\n",
      "num_train_corrects / train_total_examples = 5008 / 6000\n",
      "num_test_corrects / test_total_examples = 4964 / 6000\n",
      "testing accuracy = 0.8273\n",
      "--------- epoch: 723 ---------\n",
      "training loss = 0.3991\n",
      "training accuracy = 0.8347\n",
      "num_train_corrects / train_total_examples = 5008 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 724 ---------\n",
      "training loss = 0.3991\n",
      "training accuracy = 0.8347\n",
      "num_train_corrects / train_total_examples = 5008 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 725 ---------\n",
      "training loss = 0.3991\n",
      "training accuracy = 0.8347\n",
      "num_train_corrects / train_total_examples = 5008 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 726 ---------\n",
      "training loss = 0.3990\n",
      "training accuracy = 0.8347\n",
      "num_train_corrects / train_total_examples = 5008 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 727 ---------\n",
      "training loss = 0.3990\n",
      "training accuracy = 0.8347\n",
      "num_train_corrects / train_total_examples = 5008 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 728 ---------\n",
      "training loss = 0.3990\n",
      "training accuracy = 0.8347\n",
      "num_train_corrects / train_total_examples = 5008 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 729 ---------\n",
      "training loss = 0.3989\n",
      "training accuracy = 0.8348\n",
      "num_train_corrects / train_total_examples = 5009 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 730 ---------\n",
      "training loss = 0.3989\n",
      "training accuracy = 0.8348\n",
      "num_train_corrects / train_total_examples = 5009 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 731 ---------\n",
      "training loss = 0.3988\n",
      "training accuracy = 0.8350\n",
      "num_train_corrects / train_total_examples = 5010 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 732 ---------\n",
      "training loss = 0.3988\n",
      "training accuracy = 0.8352\n",
      "num_train_corrects / train_total_examples = 5011 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 733 ---------\n",
      "training loss = 0.3988\n",
      "training accuracy = 0.8352\n",
      "num_train_corrects / train_total_examples = 5011 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 734 ---------\n",
      "training loss = 0.3987\n",
      "training accuracy = 0.8352\n",
      "num_train_corrects / train_total_examples = 5011 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 735 ---------\n",
      "training loss = 0.3987\n",
      "training accuracy = 0.8353\n",
      "num_train_corrects / train_total_examples = 5012 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 736 ---------\n",
      "training loss = 0.3987\n",
      "training accuracy = 0.8353\n",
      "num_train_corrects / train_total_examples = 5012 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 737 ---------\n",
      "training loss = 0.3986\n",
      "training accuracy = 0.8353\n",
      "num_train_corrects / train_total_examples = 5012 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 738 ---------\n",
      "training loss = 0.3986\n",
      "training accuracy = 0.8355\n",
      "num_train_corrects / train_total_examples = 5013 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 739 ---------\n",
      "training loss = 0.3986\n",
      "training accuracy = 0.8355\n",
      "num_train_corrects / train_total_examples = 5013 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 740 ---------\n",
      "training loss = 0.3985\n",
      "training accuracy = 0.8355\n",
      "num_train_corrects / train_total_examples = 5013 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 741 ---------\n",
      "training loss = 0.3985\n",
      "training accuracy = 0.8355\n",
      "num_train_corrects / train_total_examples = 5013 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 742 ---------\n",
      "training loss = 0.3985\n",
      "training accuracy = 0.8355\n",
      "num_train_corrects / train_total_examples = 5013 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 743 ---------\n",
      "training loss = 0.3984\n",
      "training accuracy = 0.8355\n",
      "num_train_corrects / train_total_examples = 5013 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 744 ---------\n",
      "training loss = 0.3984\n",
      "training accuracy = 0.8355\n",
      "num_train_corrects / train_total_examples = 5013 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 745 ---------\n",
      "training loss = 0.3984\n",
      "training accuracy = 0.8357\n",
      "num_train_corrects / train_total_examples = 5014 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 746 ---------\n",
      "training loss = 0.3983\n",
      "training accuracy = 0.8357\n",
      "num_train_corrects / train_total_examples = 5014 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 747 ---------\n",
      "training loss = 0.3983\n",
      "training accuracy = 0.8357\n",
      "num_train_corrects / train_total_examples = 5014 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 748 ---------\n",
      "training loss = 0.3983\n",
      "training accuracy = 0.8357\n",
      "num_train_corrects / train_total_examples = 5014 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 749 ---------\n",
      "training loss = 0.3982\n",
      "training accuracy = 0.8357\n",
      "num_train_corrects / train_total_examples = 5014 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 750 ---------\n",
      "training loss = 0.3982\n",
      "training accuracy = 0.8357\n",
      "num_train_corrects / train_total_examples = 5014 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 751 ---------\n",
      "training loss = 0.3982\n",
      "training accuracy = 0.8357\n",
      "num_train_corrects / train_total_examples = 5014 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 752 ---------\n",
      "training loss = 0.3981\n",
      "training accuracy = 0.8357\n",
      "num_train_corrects / train_total_examples = 5014 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 753 ---------\n",
      "training loss = 0.3981\n",
      "training accuracy = 0.8357\n",
      "num_train_corrects / train_total_examples = 5014 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 754 ---------\n",
      "training loss = 0.3981\n",
      "training accuracy = 0.8357\n",
      "num_train_corrects / train_total_examples = 5014 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 755 ---------\n",
      "training loss = 0.3980\n",
      "training accuracy = 0.8357\n",
      "num_train_corrects / train_total_examples = 5014 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 756 ---------\n",
      "training loss = 0.3980\n",
      "training accuracy = 0.8358\n",
      "num_train_corrects / train_total_examples = 5015 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 757 ---------\n",
      "training loss = 0.3980\n",
      "training accuracy = 0.8358\n",
      "num_train_corrects / train_total_examples = 5015 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 758 ---------\n",
      "training loss = 0.3979\n",
      "training accuracy = 0.8360\n",
      "num_train_corrects / train_total_examples = 5016 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 759 ---------\n",
      "training loss = 0.3979\n",
      "training accuracy = 0.8360\n",
      "num_train_corrects / train_total_examples = 5016 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 760 ---------\n",
      "training loss = 0.3979\n",
      "training accuracy = 0.8360\n",
      "num_train_corrects / train_total_examples = 5016 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 761 ---------\n",
      "training loss = 0.3978\n",
      "training accuracy = 0.8360\n",
      "num_train_corrects / train_total_examples = 5016 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 762 ---------\n",
      "training loss = 0.3978\n",
      "training accuracy = 0.8360\n",
      "num_train_corrects / train_total_examples = 5016 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 763 ---------\n",
      "training loss = 0.3978\n",
      "training accuracy = 0.8360\n",
      "num_train_corrects / train_total_examples = 5016 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 764 ---------\n",
      "training loss = 0.3977\n",
      "training accuracy = 0.8360\n",
      "num_train_corrects / train_total_examples = 5016 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 765 ---------\n",
      "training loss = 0.3977\n",
      "training accuracy = 0.8360\n",
      "num_train_corrects / train_total_examples = 5016 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 766 ---------\n",
      "training loss = 0.3977\n",
      "training accuracy = 0.8360\n",
      "num_train_corrects / train_total_examples = 5016 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 767 ---------\n",
      "training loss = 0.3976\n",
      "training accuracy = 0.8360\n",
      "num_train_corrects / train_total_examples = 5016 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 768 ---------\n",
      "training loss = 0.3976\n",
      "training accuracy = 0.8360\n",
      "num_train_corrects / train_total_examples = 5016 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 769 ---------\n",
      "training loss = 0.3976\n",
      "training accuracy = 0.8360\n",
      "num_train_corrects / train_total_examples = 5016 / 6000\n",
      "num_test_corrects / test_total_examples = 4968 / 6000\n",
      "testing accuracy = 0.8280\n",
      "--------- epoch: 770 ---------\n",
      "training loss = 0.3975\n",
      "training accuracy = 0.8362\n",
      "num_train_corrects / train_total_examples = 5017 / 6000\n",
      "num_test_corrects / test_total_examples = 4967 / 6000\n",
      "testing accuracy = 0.8278\n",
      "--------- epoch: 771 ---------\n",
      "training loss = 0.3975\n",
      "training accuracy = 0.8362\n",
      "num_train_corrects / train_total_examples = 5017 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 772 ---------\n",
      "training loss = 0.3975\n",
      "training accuracy = 0.8362\n",
      "num_train_corrects / train_total_examples = 5017 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 773 ---------\n",
      "training loss = 0.3974\n",
      "training accuracy = 0.8362\n",
      "num_train_corrects / train_total_examples = 5017 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 774 ---------\n",
      "training loss = 0.3974\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4964 / 6000\n",
      "testing accuracy = 0.8273\n",
      "--------- epoch: 775 ---------\n",
      "training loss = 0.3974\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 776 ---------\n",
      "training loss = 0.3973\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 777 ---------\n",
      "training loss = 0.3973\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4965 / 6000\n",
      "testing accuracy = 0.8275\n",
      "--------- epoch: 778 ---------\n",
      "training loss = 0.3973\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 779 ---------\n",
      "training loss = 0.3973\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 780 ---------\n",
      "training loss = 0.3972\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4966 / 6000\n",
      "testing accuracy = 0.8277\n",
      "--------- epoch: 781 ---------\n",
      "training loss = 0.3972\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4967 / 6000\n",
      "testing accuracy = 0.8278\n",
      "--------- epoch: 782 ---------\n",
      "training loss = 0.3972\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4967 / 6000\n",
      "testing accuracy = 0.8278\n",
      "--------- epoch: 783 ---------\n",
      "training loss = 0.3971\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4967 / 6000\n",
      "testing accuracy = 0.8278\n",
      "--------- epoch: 784 ---------\n",
      "training loss = 0.3971\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4967 / 6000\n",
      "testing accuracy = 0.8278\n",
      "--------- epoch: 785 ---------\n",
      "training loss = 0.3971\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4967 / 6000\n",
      "testing accuracy = 0.8278\n",
      "--------- epoch: 786 ---------\n",
      "training loss = 0.3970\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4967 / 6000\n",
      "testing accuracy = 0.8278\n",
      "--------- epoch: 787 ---------\n",
      "training loss = 0.3970\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4967 / 6000\n",
      "testing accuracy = 0.8278\n",
      "--------- epoch: 788 ---------\n",
      "training loss = 0.3970\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4967 / 6000\n",
      "testing accuracy = 0.8278\n",
      "--------- epoch: 789 ---------\n",
      "training loss = 0.3969\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4967 / 6000\n",
      "testing accuracy = 0.8278\n",
      "--------- epoch: 790 ---------\n",
      "training loss = 0.3969\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4967 / 6000\n",
      "testing accuracy = 0.8278\n",
      "--------- epoch: 791 ---------\n",
      "training loss = 0.3969\n",
      "training accuracy = 0.8365\n",
      "num_train_corrects / train_total_examples = 5019 / 6000\n",
      "num_test_corrects / test_total_examples = 4967 / 6000\n",
      "testing accuracy = 0.8278\n",
      "--------- epoch: 792 ---------\n",
      "training loss = 0.3968\n",
      "training accuracy = 0.8365\n",
      "num_train_corrects / train_total_examples = 5019 / 6000\n",
      "num_test_corrects / test_total_examples = 4969 / 6000\n",
      "testing accuracy = 0.8282\n",
      "--------- epoch: 793 ---------\n",
      "training loss = 0.3968\n",
      "training accuracy = 0.8365\n",
      "num_train_corrects / train_total_examples = 5019 / 6000\n",
      "num_test_corrects / test_total_examples = 4969 / 6000\n",
      "testing accuracy = 0.8282\n",
      "--------- epoch: 794 ---------\n",
      "training loss = 0.3968\n",
      "training accuracy = 0.8365\n",
      "num_train_corrects / train_total_examples = 5019 / 6000\n",
      "num_test_corrects / test_total_examples = 4969 / 6000\n",
      "testing accuracy = 0.8282\n",
      "--------- epoch: 795 ---------\n",
      "training loss = 0.3967\n",
      "training accuracy = 0.8365\n",
      "num_train_corrects / train_total_examples = 5019 / 6000\n",
      "num_test_corrects / test_total_examples = 4969 / 6000\n",
      "testing accuracy = 0.8282\n",
      "--------- epoch: 796 ---------\n",
      "training loss = 0.3967\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4969 / 6000\n",
      "testing accuracy = 0.8282\n",
      "--------- epoch: 797 ---------\n",
      "training loss = 0.3967\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4969 / 6000\n",
      "testing accuracy = 0.8282\n",
      "--------- epoch: 798 ---------\n",
      "training loss = 0.3966\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4969 / 6000\n",
      "testing accuracy = 0.8282\n",
      "--------- epoch: 799 ---------\n",
      "training loss = 0.3966\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4969 / 6000\n",
      "testing accuracy = 0.8282\n",
      "--------- epoch: 800 ---------\n",
      "training loss = 0.3966\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4969 / 6000\n",
      "testing accuracy = 0.8282\n",
      "--------- epoch: 801 ---------\n",
      "training loss = 0.3966\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4969 / 6000\n",
      "testing accuracy = 0.8282\n",
      "--------- epoch: 802 ---------\n",
      "training loss = 0.3965\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4969 / 6000\n",
      "testing accuracy = 0.8282\n",
      "--------- epoch: 803 ---------\n",
      "training loss = 0.3965\n",
      "training accuracy = 0.8363\n",
      "num_train_corrects / train_total_examples = 5018 / 6000\n",
      "num_test_corrects / test_total_examples = 4970 / 6000\n",
      "testing accuracy = 0.8283\n",
      "--------- epoch: 804 ---------\n",
      "training loss = 0.3965\n",
      "training accuracy = 0.8365\n",
      "num_train_corrects / train_total_examples = 5019 / 6000\n",
      "num_test_corrects / test_total_examples = 4970 / 6000\n",
      "testing accuracy = 0.8283\n",
      "--------- epoch: 805 ---------\n",
      "training loss = 0.3964\n",
      "training accuracy = 0.8365\n",
      "num_train_corrects / train_total_examples = 5019 / 6000\n",
      "num_test_corrects / test_total_examples = 4970 / 6000\n",
      "testing accuracy = 0.8283\n",
      "--------- epoch: 806 ---------\n",
      "training loss = 0.3964\n",
      "training accuracy = 0.8367\n",
      "num_train_corrects / train_total_examples = 5020 / 6000\n",
      "num_test_corrects / test_total_examples = 4970 / 6000\n",
      "testing accuracy = 0.8283\n",
      "--------- epoch: 807 ---------\n",
      "training loss = 0.3964\n",
      "training accuracy = 0.8367\n",
      "num_train_corrects / train_total_examples = 5020 / 6000\n",
      "num_test_corrects / test_total_examples = 4970 / 6000\n",
      "testing accuracy = 0.8283\n",
      "--------- epoch: 808 ---------\n",
      "training loss = 0.3963\n",
      "training accuracy = 0.8365\n",
      "num_train_corrects / train_total_examples = 5019 / 6000\n",
      "num_test_corrects / test_total_examples = 4970 / 6000\n",
      "testing accuracy = 0.8283\n",
      "--------- epoch: 809 ---------\n",
      "training loss = 0.3963\n",
      "training accuracy = 0.8365\n",
      "num_train_corrects / train_total_examples = 5019 / 6000\n",
      "num_test_corrects / test_total_examples = 4970 / 6000\n",
      "testing accuracy = 0.8283\n",
      "--------- epoch: 810 ---------\n",
      "training loss = 0.3963\n",
      "training accuracy = 0.8365\n",
      "num_train_corrects / train_total_examples = 5019 / 6000\n",
      "num_test_corrects / test_total_examples = 4970 / 6000\n",
      "testing accuracy = 0.8283\n",
      "--------- epoch: 811 ---------\n",
      "training loss = 0.3962\n",
      "training accuracy = 0.8365\n",
      "num_train_corrects / train_total_examples = 5019 / 6000\n",
      "num_test_corrects / test_total_examples = 4970 / 6000\n",
      "testing accuracy = 0.8283\n",
      "--------- epoch: 812 ---------\n",
      "training loss = 0.3962\n",
      "training accuracy = 0.8367\n",
      "num_train_corrects / train_total_examples = 5020 / 6000\n",
      "num_test_corrects / test_total_examples = 4971 / 6000\n",
      "testing accuracy = 0.8285\n",
      "--------- epoch: 813 ---------\n",
      "training loss = 0.3962\n",
      "training accuracy = 0.8367\n",
      "num_train_corrects / train_total_examples = 5020 / 6000\n",
      "num_test_corrects / test_total_examples = 4971 / 6000\n",
      "testing accuracy = 0.8285\n",
      "--------- epoch: 814 ---------\n",
      "training loss = 0.3962\n",
      "training accuracy = 0.8367\n",
      "num_train_corrects / train_total_examples = 5020 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 815 ---------\n",
      "training loss = 0.3961\n",
      "training accuracy = 0.8367\n",
      "num_train_corrects / train_total_examples = 5020 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 816 ---------\n",
      "training loss = 0.3961\n",
      "training accuracy = 0.8367\n",
      "num_train_corrects / train_total_examples = 5020 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 817 ---------\n",
      "training loss = 0.3961\n",
      "training accuracy = 0.8367\n",
      "num_train_corrects / train_total_examples = 5020 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 818 ---------\n",
      "training loss = 0.3960\n",
      "training accuracy = 0.8367\n",
      "num_train_corrects / train_total_examples = 5020 / 6000\n",
      "num_test_corrects / test_total_examples = 4974 / 6000\n",
      "testing accuracy = 0.8290\n",
      "--------- epoch: 819 ---------\n",
      "training loss = 0.3960\n",
      "training accuracy = 0.8367\n",
      "num_train_corrects / train_total_examples = 5020 / 6000\n",
      "num_test_corrects / test_total_examples = 4974 / 6000\n",
      "testing accuracy = 0.8290\n",
      "--------- epoch: 820 ---------\n",
      "training loss = 0.3960\n",
      "training accuracy = 0.8367\n",
      "num_train_corrects / train_total_examples = 5020 / 6000\n",
      "num_test_corrects / test_total_examples = 4974 / 6000\n",
      "testing accuracy = 0.8290\n",
      "--------- epoch: 821 ---------\n",
      "training loss = 0.3959\n",
      "training accuracy = 0.8367\n",
      "num_train_corrects / train_total_examples = 5020 / 6000\n",
      "num_test_corrects / test_total_examples = 4974 / 6000\n",
      "testing accuracy = 0.8290\n",
      "--------- epoch: 822 ---------\n",
      "training loss = 0.3959\n",
      "training accuracy = 0.8368\n",
      "num_train_corrects / train_total_examples = 5021 / 6000\n",
      "num_test_corrects / test_total_examples = 4974 / 6000\n",
      "testing accuracy = 0.8290\n",
      "--------- epoch: 823 ---------\n",
      "training loss = 0.3959\n",
      "training accuracy = 0.8368\n",
      "num_train_corrects / train_total_examples = 5021 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 824 ---------\n",
      "training loss = 0.3958\n",
      "training accuracy = 0.8368\n",
      "num_train_corrects / train_total_examples = 5021 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 825 ---------\n",
      "training loss = 0.3958\n",
      "training accuracy = 0.8368\n",
      "num_train_corrects / train_total_examples = 5021 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 826 ---------\n",
      "training loss = 0.3958\n",
      "training accuracy = 0.8368\n",
      "num_train_corrects / train_total_examples = 5021 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 827 ---------\n",
      "training loss = 0.3958\n",
      "training accuracy = 0.8368\n",
      "num_train_corrects / train_total_examples = 5021 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 828 ---------\n",
      "training loss = 0.3957\n",
      "training accuracy = 0.8368\n",
      "num_train_corrects / train_total_examples = 5021 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 829 ---------\n",
      "training loss = 0.3957\n",
      "training accuracy = 0.8368\n",
      "num_train_corrects / train_total_examples = 5021 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 830 ---------\n",
      "training loss = 0.3957\n",
      "training accuracy = 0.8370\n",
      "num_train_corrects / train_total_examples = 5022 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 831 ---------\n",
      "training loss = 0.3956\n",
      "training accuracy = 0.8370\n",
      "num_train_corrects / train_total_examples = 5022 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 832 ---------\n",
      "training loss = 0.3956\n",
      "training accuracy = 0.8370\n",
      "num_train_corrects / train_total_examples = 5022 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 833 ---------\n",
      "training loss = 0.3956\n",
      "training accuracy = 0.8372\n",
      "num_train_corrects / train_total_examples = 5023 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 834 ---------\n",
      "training loss = 0.3955\n",
      "training accuracy = 0.8372\n",
      "num_train_corrects / train_total_examples = 5023 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 835 ---------\n",
      "training loss = 0.3955\n",
      "training accuracy = 0.8373\n",
      "num_train_corrects / train_total_examples = 5024 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 836 ---------\n",
      "training loss = 0.3955\n",
      "training accuracy = 0.8373\n",
      "num_train_corrects / train_total_examples = 5024 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 837 ---------\n",
      "training loss = 0.3955\n",
      "training accuracy = 0.8375\n",
      "num_train_corrects / train_total_examples = 5025 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 838 ---------\n",
      "training loss = 0.3954\n",
      "training accuracy = 0.8375\n",
      "num_train_corrects / train_total_examples = 5025 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 839 ---------\n",
      "training loss = 0.3954\n",
      "training accuracy = 0.8375\n",
      "num_train_corrects / train_total_examples = 5025 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 840 ---------\n",
      "training loss = 0.3954\n",
      "training accuracy = 0.8375\n",
      "num_train_corrects / train_total_examples = 5025 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 841 ---------\n",
      "training loss = 0.3953\n",
      "training accuracy = 0.8375\n",
      "num_train_corrects / train_total_examples = 5025 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 842 ---------\n",
      "training loss = 0.3953\n",
      "training accuracy = 0.8377\n",
      "num_train_corrects / train_total_examples = 5026 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 843 ---------\n",
      "training loss = 0.3953\n",
      "training accuracy = 0.8377\n",
      "num_train_corrects / train_total_examples = 5026 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 844 ---------\n",
      "training loss = 0.3952\n",
      "training accuracy = 0.8377\n",
      "num_train_corrects / train_total_examples = 5026 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 845 ---------\n",
      "training loss = 0.3952\n",
      "training accuracy = 0.8377\n",
      "num_train_corrects / train_total_examples = 5026 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 846 ---------\n",
      "training loss = 0.3952\n",
      "training accuracy = 0.8377\n",
      "num_train_corrects / train_total_examples = 5026 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 847 ---------\n",
      "training loss = 0.3952\n",
      "training accuracy = 0.8377\n",
      "num_train_corrects / train_total_examples = 5026 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 848 ---------\n",
      "training loss = 0.3951\n",
      "training accuracy = 0.8377\n",
      "num_train_corrects / train_total_examples = 5026 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 849 ---------\n",
      "training loss = 0.3951\n",
      "training accuracy = 0.8378\n",
      "num_train_corrects / train_total_examples = 5027 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 850 ---------\n",
      "training loss = 0.3951\n",
      "training accuracy = 0.8378\n",
      "num_train_corrects / train_total_examples = 5027 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 851 ---------\n",
      "training loss = 0.3950\n",
      "training accuracy = 0.8378\n",
      "num_train_corrects / train_total_examples = 5027 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 852 ---------\n",
      "training loss = 0.3950\n",
      "training accuracy = 0.8378\n",
      "num_train_corrects / train_total_examples = 5027 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 853 ---------\n",
      "training loss = 0.3950\n",
      "training accuracy = 0.8378\n",
      "num_train_corrects / train_total_examples = 5027 / 6000\n",
      "num_test_corrects / test_total_examples = 4972 / 6000\n",
      "testing accuracy = 0.8287\n",
      "--------- epoch: 854 ---------\n",
      "training loss = 0.3950\n",
      "training accuracy = 0.8380\n",
      "num_train_corrects / train_total_examples = 5028 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 855 ---------\n",
      "training loss = 0.3949\n",
      "training accuracy = 0.8380\n",
      "num_train_corrects / train_total_examples = 5028 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 856 ---------\n",
      "training loss = 0.3949\n",
      "training accuracy = 0.8380\n",
      "num_train_corrects / train_total_examples = 5028 / 6000\n",
      "num_test_corrects / test_total_examples = 4973 / 6000\n",
      "testing accuracy = 0.8288\n",
      "--------- epoch: 857 ---------\n",
      "training loss = 0.3949\n",
      "training accuracy = 0.8380\n",
      "num_train_corrects / train_total_examples = 5028 / 6000\n",
      "num_test_corrects / test_total_examples = 4974 / 6000\n",
      "testing accuracy = 0.8290\n",
      "--------- epoch: 858 ---------\n",
      "training loss = 0.3948\n",
      "training accuracy = 0.8380\n",
      "num_train_corrects / train_total_examples = 5028 / 6000\n",
      "num_test_corrects / test_total_examples = 4974 / 6000\n",
      "testing accuracy = 0.8290\n",
      "--------- epoch: 859 ---------\n",
      "training loss = 0.3948\n",
      "training accuracy = 0.8382\n",
      "num_train_corrects / train_total_examples = 5029 / 6000\n",
      "num_test_corrects / test_total_examples = 4974 / 6000\n",
      "testing accuracy = 0.8290\n",
      "--------- epoch: 860 ---------\n",
      "training loss = 0.3948\n",
      "training accuracy = 0.8382\n",
      "num_train_corrects / train_total_examples = 5029 / 6000\n",
      "num_test_corrects / test_total_examples = 4975 / 6000\n",
      "testing accuracy = 0.8292\n",
      "--------- epoch: 861 ---------\n",
      "training loss = 0.3948\n",
      "training accuracy = 0.8383\n",
      "num_train_corrects / train_total_examples = 5030 / 6000\n",
      "num_test_corrects / test_total_examples = 4975 / 6000\n",
      "testing accuracy = 0.8292\n",
      "--------- epoch: 862 ---------\n",
      "training loss = 0.3947\n",
      "training accuracy = 0.8383\n",
      "num_train_corrects / train_total_examples = 5030 / 6000\n",
      "num_test_corrects / test_total_examples = 4975 / 6000\n",
      "testing accuracy = 0.8292\n",
      "--------- epoch: 863 ---------\n",
      "training loss = 0.3947\n",
      "training accuracy = 0.8383\n",
      "num_train_corrects / train_total_examples = 5030 / 6000\n",
      "num_test_corrects / test_total_examples = 4975 / 6000\n",
      "testing accuracy = 0.8292\n",
      "--------- epoch: 864 ---------\n",
      "training loss = 0.3947\n",
      "training accuracy = 0.8383\n",
      "num_train_corrects / train_total_examples = 5030 / 6000\n",
      "num_test_corrects / test_total_examples = 4979 / 6000\n",
      "testing accuracy = 0.8298\n",
      "--------- epoch: 865 ---------\n",
      "training loss = 0.3946\n",
      "training accuracy = 0.8383\n",
      "num_train_corrects / train_total_examples = 5030 / 6000\n",
      "num_test_corrects / test_total_examples = 4980 / 6000\n",
      "testing accuracy = 0.8300\n",
      "--------- epoch: 866 ---------\n",
      "training loss = 0.3946\n",
      "training accuracy = 0.8383\n",
      "num_train_corrects / train_total_examples = 5030 / 6000\n",
      "num_test_corrects / test_total_examples = 4980 / 6000\n",
      "testing accuracy = 0.8300\n",
      "--------- epoch: 867 ---------\n",
      "training loss = 0.3946\n",
      "training accuracy = 0.8383\n",
      "num_train_corrects / train_total_examples = 5030 / 6000\n",
      "num_test_corrects / test_total_examples = 4980 / 6000\n",
      "testing accuracy = 0.8300\n",
      "--------- epoch: 868 ---------\n",
      "training loss = 0.3945\n",
      "training accuracy = 0.8383\n",
      "num_train_corrects / train_total_examples = 5030 / 6000\n",
      "num_test_corrects / test_total_examples = 4980 / 6000\n",
      "testing accuracy = 0.8300\n",
      "--------- epoch: 869 ---------\n",
      "training loss = 0.3945\n",
      "training accuracy = 0.8385\n",
      "num_train_corrects / train_total_examples = 5031 / 6000\n",
      "num_test_corrects / test_total_examples = 4980 / 6000\n",
      "testing accuracy = 0.8300\n",
      "--------- epoch: 870 ---------\n",
      "training loss = 0.3945\n",
      "training accuracy = 0.8385\n",
      "num_train_corrects / train_total_examples = 5031 / 6000\n",
      "num_test_corrects / test_total_examples = 4981 / 6000\n",
      "testing accuracy = 0.8302\n",
      "--------- epoch: 871 ---------\n",
      "training loss = 0.3945\n",
      "training accuracy = 0.8385\n",
      "num_train_corrects / train_total_examples = 5031 / 6000\n",
      "num_test_corrects / test_total_examples = 4981 / 6000\n",
      "testing accuracy = 0.8302\n",
      "--------- epoch: 872 ---------\n",
      "training loss = 0.3944\n",
      "training accuracy = 0.8385\n",
      "num_train_corrects / train_total_examples = 5031 / 6000\n",
      "num_test_corrects / test_total_examples = 4983 / 6000\n",
      "testing accuracy = 0.8305\n",
      "--------- epoch: 873 ---------\n",
      "training loss = 0.3944\n",
      "training accuracy = 0.8387\n",
      "num_train_corrects / train_total_examples = 5032 / 6000\n",
      "num_test_corrects / test_total_examples = 4983 / 6000\n",
      "testing accuracy = 0.8305\n",
      "--------- epoch: 874 ---------\n",
      "training loss = 0.3944\n",
      "training accuracy = 0.8387\n",
      "num_train_corrects / train_total_examples = 5032 / 6000\n",
      "num_test_corrects / test_total_examples = 4983 / 6000\n",
      "testing accuracy = 0.8305\n",
      "--------- epoch: 875 ---------\n",
      "training loss = 0.3943\n",
      "training accuracy = 0.8387\n",
      "num_train_corrects / train_total_examples = 5032 / 6000\n",
      "num_test_corrects / test_total_examples = 4983 / 6000\n",
      "testing accuracy = 0.8305\n",
      "--------- epoch: 876 ---------\n",
      "training loss = 0.3943\n",
      "training accuracy = 0.8387\n",
      "num_train_corrects / train_total_examples = 5032 / 6000\n",
      "num_test_corrects / test_total_examples = 4983 / 6000\n",
      "testing accuracy = 0.8305\n",
      "--------- epoch: 877 ---------\n",
      "training loss = 0.3943\n",
      "training accuracy = 0.8387\n",
      "num_train_corrects / train_total_examples = 5032 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 878 ---------\n",
      "training loss = 0.3943\n",
      "training accuracy = 0.8387\n",
      "num_train_corrects / train_total_examples = 5032 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 879 ---------\n",
      "training loss = 0.3942\n",
      "training accuracy = 0.8390\n",
      "num_train_corrects / train_total_examples = 5034 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 880 ---------\n",
      "training loss = 0.3942\n",
      "training accuracy = 0.8390\n",
      "num_train_corrects / train_total_examples = 5034 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 881 ---------\n",
      "training loss = 0.3942\n",
      "training accuracy = 0.8390\n",
      "num_train_corrects / train_total_examples = 5034 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 882 ---------\n",
      "training loss = 0.3941\n",
      "training accuracy = 0.8390\n",
      "num_train_corrects / train_total_examples = 5034 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 883 ---------\n",
      "training loss = 0.3941\n",
      "training accuracy = 0.8388\n",
      "num_train_corrects / train_total_examples = 5033 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 884 ---------\n",
      "training loss = 0.3941\n",
      "training accuracy = 0.8388\n",
      "num_train_corrects / train_total_examples = 5033 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 885 ---------\n",
      "training loss = 0.3941\n",
      "training accuracy = 0.8388\n",
      "num_train_corrects / train_total_examples = 5033 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 886 ---------\n",
      "training loss = 0.3940\n",
      "training accuracy = 0.8388\n",
      "num_train_corrects / train_total_examples = 5033 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 887 ---------\n",
      "training loss = 0.3940\n",
      "training accuracy = 0.8388\n",
      "num_train_corrects / train_total_examples = 5033 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 888 ---------\n",
      "training loss = 0.3940\n",
      "training accuracy = 0.8388\n",
      "num_train_corrects / train_total_examples = 5033 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 889 ---------\n",
      "training loss = 0.3940\n",
      "training accuracy = 0.8390\n",
      "num_train_corrects / train_total_examples = 5034 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 890 ---------\n",
      "training loss = 0.3939\n",
      "training accuracy = 0.8390\n",
      "num_train_corrects / train_total_examples = 5034 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 891 ---------\n",
      "training loss = 0.3939\n",
      "training accuracy = 0.8390\n",
      "num_train_corrects / train_total_examples = 5034 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 892 ---------\n",
      "training loss = 0.3939\n",
      "training accuracy = 0.8390\n",
      "num_train_corrects / train_total_examples = 5034 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 893 ---------\n",
      "training loss = 0.3938\n",
      "training accuracy = 0.8390\n",
      "num_train_corrects / train_total_examples = 5034 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 894 ---------\n",
      "training loss = 0.3938\n",
      "training accuracy = 0.8390\n",
      "num_train_corrects / train_total_examples = 5034 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 895 ---------\n",
      "training loss = 0.3938\n",
      "training accuracy = 0.8392\n",
      "num_train_corrects / train_total_examples = 5035 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 896 ---------\n",
      "training loss = 0.3938\n",
      "training accuracy = 0.8393\n",
      "num_train_corrects / train_total_examples = 5036 / 6000\n",
      "num_test_corrects / test_total_examples = 4984 / 6000\n",
      "testing accuracy = 0.8307\n",
      "--------- epoch: 897 ---------\n",
      "training loss = 0.3937\n",
      "training accuracy = 0.8393\n",
      "num_train_corrects / train_total_examples = 5036 / 6000\n",
      "num_test_corrects / test_total_examples = 4985 / 6000\n",
      "testing accuracy = 0.8308\n",
      "--------- epoch: 898 ---------\n",
      "training loss = 0.3937\n",
      "training accuracy = 0.8393\n",
      "num_train_corrects / train_total_examples = 5036 / 6000\n",
      "num_test_corrects / test_total_examples = 4985 / 6000\n",
      "testing accuracy = 0.8308\n",
      "--------- epoch: 899 ---------\n",
      "training loss = 0.3937\n",
      "training accuracy = 0.8393\n",
      "num_train_corrects / train_total_examples = 5036 / 6000\n",
      "num_test_corrects / test_total_examples = 4985 / 6000\n",
      "testing accuracy = 0.8308\n",
      "--------- epoch: 900 ---------\n",
      "training loss = 0.3936\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4985 / 6000\n",
      "testing accuracy = 0.8308\n",
      "--------- epoch: 901 ---------\n",
      "training loss = 0.3936\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4987 / 6000\n",
      "testing accuracy = 0.8312\n",
      "--------- epoch: 902 ---------\n",
      "training loss = 0.3936\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4987 / 6000\n",
      "testing accuracy = 0.8312\n",
      "--------- epoch: 903 ---------\n",
      "training loss = 0.3936\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4987 / 6000\n",
      "testing accuracy = 0.8312\n",
      "--------- epoch: 904 ---------\n",
      "training loss = 0.3935\n",
      "training accuracy = 0.8397\n",
      "num_train_corrects / train_total_examples = 5038 / 6000\n",
      "num_test_corrects / test_total_examples = 4987 / 6000\n",
      "testing accuracy = 0.8312\n",
      "--------- epoch: 905 ---------\n",
      "training loss = 0.3935\n",
      "training accuracy = 0.8397\n",
      "num_train_corrects / train_total_examples = 5038 / 6000\n",
      "num_test_corrects / test_total_examples = 4987 / 6000\n",
      "testing accuracy = 0.8312\n",
      "--------- epoch: 906 ---------\n",
      "training loss = 0.3935\n",
      "training accuracy = 0.8397\n",
      "num_train_corrects / train_total_examples = 5038 / 6000\n",
      "num_test_corrects / test_total_examples = 4988 / 6000\n",
      "testing accuracy = 0.8313\n",
      "--------- epoch: 907 ---------\n",
      "training loss = 0.3935\n",
      "training accuracy = 0.8397\n",
      "num_train_corrects / train_total_examples = 5038 / 6000\n",
      "num_test_corrects / test_total_examples = 4988 / 6000\n",
      "testing accuracy = 0.8313\n",
      "--------- epoch: 908 ---------\n",
      "training loss = 0.3934\n",
      "training accuracy = 0.8398\n",
      "num_train_corrects / train_total_examples = 5039 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 909 ---------\n",
      "training loss = 0.3934\n",
      "training accuracy = 0.8398\n",
      "num_train_corrects / train_total_examples = 5039 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 910 ---------\n",
      "training loss = 0.3934\n",
      "training accuracy = 0.8398\n",
      "num_train_corrects / train_total_examples = 5039 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 911 ---------\n",
      "training loss = 0.3933\n",
      "training accuracy = 0.8398\n",
      "num_train_corrects / train_total_examples = 5039 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 912 ---------\n",
      "training loss = 0.3933\n",
      "training accuracy = 0.8398\n",
      "num_train_corrects / train_total_examples = 5039 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 913 ---------\n",
      "training loss = 0.3933\n",
      "training accuracy = 0.8398\n",
      "num_train_corrects / train_total_examples = 5039 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 914 ---------\n",
      "training loss = 0.3933\n",
      "training accuracy = 0.8398\n",
      "num_train_corrects / train_total_examples = 5039 / 6000\n",
      "num_test_corrects / test_total_examples = 4991 / 6000\n",
      "testing accuracy = 0.8318\n",
      "--------- epoch: 915 ---------\n",
      "training loss = 0.3932\n",
      "training accuracy = 0.8398\n",
      "num_train_corrects / train_total_examples = 5039 / 6000\n",
      "num_test_corrects / test_total_examples = 4991 / 6000\n",
      "testing accuracy = 0.8318\n",
      "--------- epoch: 916 ---------\n",
      "training loss = 0.3932\n",
      "training accuracy = 0.8398\n",
      "num_train_corrects / train_total_examples = 5039 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 917 ---------\n",
      "training loss = 0.3932\n",
      "training accuracy = 0.8398\n",
      "num_train_corrects / train_total_examples = 5039 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 918 ---------\n",
      "training loss = 0.3932\n",
      "training accuracy = 0.8397\n",
      "num_train_corrects / train_total_examples = 5038 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 919 ---------\n",
      "training loss = 0.3931\n",
      "training accuracy = 0.8397\n",
      "num_train_corrects / train_total_examples = 5038 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 920 ---------\n",
      "training loss = 0.3931\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 921 ---------\n",
      "training loss = 0.3931\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 922 ---------\n",
      "training loss = 0.3930\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 923 ---------\n",
      "training loss = 0.3930\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 924 ---------\n",
      "training loss = 0.3930\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 925 ---------\n",
      "training loss = 0.3930\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 926 ---------\n",
      "training loss = 0.3929\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4991 / 6000\n",
      "testing accuracy = 0.8318\n",
      "--------- epoch: 927 ---------\n",
      "training loss = 0.3929\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4991 / 6000\n",
      "testing accuracy = 0.8318\n",
      "--------- epoch: 928 ---------\n",
      "training loss = 0.3929\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 929 ---------\n",
      "training loss = 0.3929\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 930 ---------\n",
      "training loss = 0.3928\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 931 ---------\n",
      "training loss = 0.3928\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 932 ---------\n",
      "training loss = 0.3928\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 933 ---------\n",
      "training loss = 0.3928\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 934 ---------\n",
      "training loss = 0.3927\n",
      "training accuracy = 0.8393\n",
      "num_train_corrects / train_total_examples = 5036 / 6000\n",
      "num_test_corrects / test_total_examples = 4993 / 6000\n",
      "testing accuracy = 0.8322\n",
      "--------- epoch: 935 ---------\n",
      "training loss = 0.3927\n",
      "training accuracy = 0.8393\n",
      "num_train_corrects / train_total_examples = 5036 / 6000\n",
      "num_test_corrects / test_total_examples = 4993 / 6000\n",
      "testing accuracy = 0.8322\n",
      "--------- epoch: 936 ---------\n",
      "training loss = 0.3927\n",
      "training accuracy = 0.8393\n",
      "num_train_corrects / train_total_examples = 5036 / 6000\n",
      "num_test_corrects / test_total_examples = 4993 / 6000\n",
      "testing accuracy = 0.8322\n",
      "--------- epoch: 937 ---------\n",
      "training loss = 0.3926\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4993 / 6000\n",
      "testing accuracy = 0.8322\n",
      "--------- epoch: 938 ---------\n",
      "training loss = 0.3926\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4993 / 6000\n",
      "testing accuracy = 0.8322\n",
      "--------- epoch: 939 ---------\n",
      "training loss = 0.3926\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4993 / 6000\n",
      "testing accuracy = 0.8322\n",
      "--------- epoch: 940 ---------\n",
      "training loss = 0.3926\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4993 / 6000\n",
      "testing accuracy = 0.8322\n",
      "--------- epoch: 941 ---------\n",
      "training loss = 0.3925\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4993 / 6000\n",
      "testing accuracy = 0.8322\n",
      "--------- epoch: 942 ---------\n",
      "training loss = 0.3925\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 943 ---------\n",
      "training loss = 0.3925\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 944 ---------\n",
      "training loss = 0.3925\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 945 ---------\n",
      "training loss = 0.3924\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 946 ---------\n",
      "training loss = 0.3924\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 947 ---------\n",
      "training loss = 0.3924\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 948 ---------\n",
      "training loss = 0.3924\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 949 ---------\n",
      "training loss = 0.3923\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 950 ---------\n",
      "training loss = 0.3923\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 951 ---------\n",
      "training loss = 0.3923\n",
      "training accuracy = 0.8393\n",
      "num_train_corrects / train_total_examples = 5036 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 952 ---------\n",
      "training loss = 0.3922\n",
      "training accuracy = 0.8393\n",
      "num_train_corrects / train_total_examples = 5036 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 953 ---------\n",
      "training loss = 0.3922\n",
      "training accuracy = 0.8393\n",
      "num_train_corrects / train_total_examples = 5036 / 6000\n",
      "num_test_corrects / test_total_examples = 4991 / 6000\n",
      "testing accuracy = 0.8318\n",
      "--------- epoch: 954 ---------\n",
      "training loss = 0.3922\n",
      "training accuracy = 0.8393\n",
      "num_train_corrects / train_total_examples = 5036 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 955 ---------\n",
      "training loss = 0.3922\n",
      "training accuracy = 0.8393\n",
      "num_train_corrects / train_total_examples = 5036 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 956 ---------\n",
      "training loss = 0.3921\n",
      "training accuracy = 0.8393\n",
      "num_train_corrects / train_total_examples = 5036 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 957 ---------\n",
      "training loss = 0.3921\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 958 ---------\n",
      "training loss = 0.3921\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 959 ---------\n",
      "training loss = 0.3921\n",
      "training accuracy = 0.8395\n",
      "num_train_corrects / train_total_examples = 5037 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 960 ---------\n",
      "training loss = 0.3920\n",
      "training accuracy = 0.8397\n",
      "num_train_corrects / train_total_examples = 5038 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 961 ---------\n",
      "training loss = 0.3920\n",
      "training accuracy = 0.8397\n",
      "num_train_corrects / train_total_examples = 5038 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 962 ---------\n",
      "training loss = 0.3920\n",
      "training accuracy = 0.8397\n",
      "num_train_corrects / train_total_examples = 5038 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 963 ---------\n",
      "training loss = 0.3920\n",
      "training accuracy = 0.8397\n",
      "num_train_corrects / train_total_examples = 5038 / 6000\n",
      "num_test_corrects / test_total_examples = 4990 / 6000\n",
      "testing accuracy = 0.8317\n",
      "--------- epoch: 964 ---------\n",
      "training loss = 0.3919\n",
      "training accuracy = 0.8397\n",
      "num_train_corrects / train_total_examples = 5038 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 965 ---------\n",
      "training loss = 0.3919\n",
      "training accuracy = 0.8397\n",
      "num_train_corrects / train_total_examples = 5038 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 966 ---------\n",
      "training loss = 0.3919\n",
      "training accuracy = 0.8398\n",
      "num_train_corrects / train_total_examples = 5039 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 967 ---------\n",
      "training loss = 0.3919\n",
      "training accuracy = 0.8398\n",
      "num_train_corrects / train_total_examples = 5039 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 968 ---------\n",
      "training loss = 0.3918\n",
      "training accuracy = 0.8400\n",
      "num_train_corrects / train_total_examples = 5040 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 969 ---------\n",
      "training loss = 0.3918\n",
      "training accuracy = 0.8400\n",
      "num_train_corrects / train_total_examples = 5040 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 970 ---------\n",
      "training loss = 0.3918\n",
      "training accuracy = 0.8400\n",
      "num_train_corrects / train_total_examples = 5040 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 971 ---------\n",
      "training loss = 0.3918\n",
      "training accuracy = 0.8400\n",
      "num_train_corrects / train_total_examples = 5040 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 972 ---------\n",
      "training loss = 0.3917\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 973 ---------\n",
      "training loss = 0.3917\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 974 ---------\n",
      "training loss = 0.3917\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 975 ---------\n",
      "training loss = 0.3917\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 976 ---------\n",
      "training loss = 0.3916\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 977 ---------\n",
      "training loss = 0.3916\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 978 ---------\n",
      "training loss = 0.3916\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 979 ---------\n",
      "training loss = 0.3916\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4989 / 6000\n",
      "testing accuracy = 0.8315\n",
      "--------- epoch: 980 ---------\n",
      "training loss = 0.3915\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 981 ---------\n",
      "training loss = 0.3915\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 982 ---------\n",
      "training loss = 0.3915\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 983 ---------\n",
      "training loss = 0.3915\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 984 ---------\n",
      "training loss = 0.3914\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 985 ---------\n",
      "training loss = 0.3914\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 986 ---------\n",
      "training loss = 0.3914\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 987 ---------\n",
      "training loss = 0.3914\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 988 ---------\n",
      "training loss = 0.3913\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 989 ---------\n",
      "training loss = 0.3913\n",
      "training accuracy = 0.8400\n",
      "num_train_corrects / train_total_examples = 5040 / 6000\n",
      "num_test_corrects / test_total_examples = 4992 / 6000\n",
      "testing accuracy = 0.8320\n",
      "--------- epoch: 990 ---------\n",
      "training loss = 0.3913\n",
      "training accuracy = 0.8400\n",
      "num_train_corrects / train_total_examples = 5040 / 6000\n",
      "num_test_corrects / test_total_examples = 4993 / 6000\n",
      "testing accuracy = 0.8322\n",
      "--------- epoch: 991 ---------\n",
      "training loss = 0.3913\n",
      "training accuracy = 0.8400\n",
      "num_train_corrects / train_total_examples = 5040 / 6000\n",
      "num_test_corrects / test_total_examples = 4993 / 6000\n",
      "testing accuracy = 0.8322\n",
      "--------- epoch: 992 ---------\n",
      "training loss = 0.3912\n",
      "training accuracy = 0.8400\n",
      "num_train_corrects / train_total_examples = 5040 / 6000\n",
      "num_test_corrects / test_total_examples = 4994 / 6000\n",
      "testing accuracy = 0.8323\n",
      "--------- epoch: 993 ---------\n",
      "training loss = 0.3912\n",
      "training accuracy = 0.8400\n",
      "num_train_corrects / train_total_examples = 5040 / 6000\n",
      "num_test_corrects / test_total_examples = 4994 / 6000\n",
      "testing accuracy = 0.8323\n",
      "--------- epoch: 994 ---------\n",
      "training loss = 0.3912\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4994 / 6000\n",
      "testing accuracy = 0.8323\n",
      "--------- epoch: 995 ---------\n",
      "training loss = 0.3912\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4994 / 6000\n",
      "testing accuracy = 0.8323\n",
      "--------- epoch: 996 ---------\n",
      "training loss = 0.3911\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4994 / 6000\n",
      "testing accuracy = 0.8323\n",
      "--------- epoch: 997 ---------\n",
      "training loss = 0.3911\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4994 / 6000\n",
      "testing accuracy = 0.8323\n",
      "--------- epoch: 998 ---------\n",
      "training loss = 0.3911\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4994 / 6000\n",
      "testing accuracy = 0.8323\n",
      "--------- epoch: 999 ---------\n",
      "training loss = 0.3911\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4995 / 6000\n",
      "testing accuracy = 0.8325\n",
      "--------- epoch: 1000 ---------\n",
      "training loss = 0.3910\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4995 / 6000\n",
      "testing accuracy = 0.8325\n",
      "--------- epoch: 1001 ---------\n",
      "training loss = 0.3910\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4995 / 6000\n",
      "testing accuracy = 0.8325\n",
      "--------- epoch: 1002 ---------\n",
      "training loss = 0.3910\n",
      "training accuracy = 0.8400\n",
      "num_train_corrects / train_total_examples = 5040 / 6000\n",
      "num_test_corrects / test_total_examples = 4995 / 6000\n",
      "testing accuracy = 0.8325\n",
      "--------- epoch: 1003 ---------\n",
      "training loss = 0.3910\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4995 / 6000\n",
      "testing accuracy = 0.8325\n",
      "--------- epoch: 1004 ---------\n",
      "training loss = 0.3909\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1005 ---------\n",
      "training loss = 0.3909\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1006 ---------\n",
      "training loss = 0.3909\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1007 ---------\n",
      "training loss = 0.3909\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1008 ---------\n",
      "training loss = 0.3908\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1009 ---------\n",
      "training loss = 0.3908\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1010 ---------\n",
      "training loss = 0.3908\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1011 ---------\n",
      "training loss = 0.3908\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 4995 / 6000\n",
      "testing accuracy = 0.8325\n",
      "--------- epoch: 1012 ---------\n",
      "training loss = 0.3907\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 4995 / 6000\n",
      "testing accuracy = 0.8325\n",
      "--------- epoch: 1013 ---------\n",
      "training loss = 0.3907\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1014 ---------\n",
      "training loss = 0.3907\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1015 ---------\n",
      "training loss = 0.3907\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1016 ---------\n",
      "training loss = 0.3906\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1017 ---------\n",
      "training loss = 0.3906\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1018 ---------\n",
      "training loss = 0.3906\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1019 ---------\n",
      "training loss = 0.3906\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1020 ---------\n",
      "training loss = 0.3905\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1021 ---------\n",
      "training loss = 0.3905\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1022 ---------\n",
      "training loss = 0.3905\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1023 ---------\n",
      "training loss = 0.3905\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1024 ---------\n",
      "training loss = 0.3904\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1025 ---------\n",
      "training loss = 0.3904\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1026 ---------\n",
      "training loss = 0.3904\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1027 ---------\n",
      "training loss = 0.3904\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4996 / 6000\n",
      "testing accuracy = 0.8327\n",
      "--------- epoch: 1028 ---------\n",
      "training loss = 0.3903\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4997 / 6000\n",
      "testing accuracy = 0.8328\n",
      "--------- epoch: 1029 ---------\n",
      "training loss = 0.3903\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4997 / 6000\n",
      "testing accuracy = 0.8328\n",
      "--------- epoch: 1030 ---------\n",
      "training loss = 0.3903\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4998 / 6000\n",
      "testing accuracy = 0.8330\n",
      "--------- epoch: 1031 ---------\n",
      "training loss = 0.3903\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1032 ---------\n",
      "training loss = 0.3903\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1033 ---------\n",
      "training loss = 0.3902\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1034 ---------\n",
      "training loss = 0.3902\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1035 ---------\n",
      "training loss = 0.3902\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1036 ---------\n",
      "training loss = 0.3902\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1037 ---------\n",
      "training loss = 0.3901\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1038 ---------\n",
      "training loss = 0.3901\n",
      "training accuracy = 0.8407\n",
      "num_train_corrects / train_total_examples = 5044 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1039 ---------\n",
      "training loss = 0.3901\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1040 ---------\n",
      "training loss = 0.3901\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1041 ---------\n",
      "training loss = 0.3900\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1042 ---------\n",
      "training loss = 0.3900\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1043 ---------\n",
      "training loss = 0.3900\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1044 ---------\n",
      "training loss = 0.3900\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1045 ---------\n",
      "training loss = 0.3899\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1046 ---------\n",
      "training loss = 0.3899\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1047 ---------\n",
      "training loss = 0.3899\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1048 ---------\n",
      "training loss = 0.3899\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1049 ---------\n",
      "training loss = 0.3898\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1050 ---------\n",
      "training loss = 0.3898\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1051 ---------\n",
      "training loss = 0.3898\n",
      "training accuracy = 0.8402\n",
      "num_train_corrects / train_total_examples = 5041 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1052 ---------\n",
      "training loss = 0.3898\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 5001 / 6000\n",
      "testing accuracy = 0.8335\n",
      "--------- epoch: 1053 ---------\n",
      "training loss = 0.3898\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 5001 / 6000\n",
      "testing accuracy = 0.8335\n",
      "--------- epoch: 1054 ---------\n",
      "training loss = 0.3897\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1055 ---------\n",
      "training loss = 0.3897\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1056 ---------\n",
      "training loss = 0.3897\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1057 ---------\n",
      "training loss = 0.3897\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1058 ---------\n",
      "training loss = 0.3896\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1059 ---------\n",
      "training loss = 0.3896\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1060 ---------\n",
      "training loss = 0.3896\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1061 ---------\n",
      "training loss = 0.3896\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1062 ---------\n",
      "training loss = 0.3895\n",
      "training accuracy = 0.8407\n",
      "num_train_corrects / train_total_examples = 5044 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1063 ---------\n",
      "training loss = 0.3895\n",
      "training accuracy = 0.8407\n",
      "num_train_corrects / train_total_examples = 5044 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1064 ---------\n",
      "training loss = 0.3895\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1065 ---------\n",
      "training loss = 0.3895\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1066 ---------\n",
      "training loss = 0.3895\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1067 ---------\n",
      "training loss = 0.3894\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1068 ---------\n",
      "training loss = 0.3894\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1069 ---------\n",
      "training loss = 0.3894\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1070 ---------\n",
      "training loss = 0.3894\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1071 ---------\n",
      "training loss = 0.3893\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1072 ---------\n",
      "training loss = 0.3893\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 4999 / 6000\n",
      "testing accuracy = 0.8332\n",
      "--------- epoch: 1073 ---------\n",
      "training loss = 0.3893\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1074 ---------\n",
      "training loss = 0.3893\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 5000 / 6000\n",
      "testing accuracy = 0.8333\n",
      "--------- epoch: 1075 ---------\n",
      "training loss = 0.3892\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 5001 / 6000\n",
      "testing accuracy = 0.8335\n",
      "--------- epoch: 1076 ---------\n",
      "training loss = 0.3892\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 5001 / 6000\n",
      "testing accuracy = 0.8335\n",
      "--------- epoch: 1077 ---------\n",
      "training loss = 0.3892\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5001 / 6000\n",
      "testing accuracy = 0.8335\n",
      "--------- epoch: 1078 ---------\n",
      "training loss = 0.3892\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5001 / 6000\n",
      "testing accuracy = 0.8335\n",
      "--------- epoch: 1079 ---------\n",
      "training loss = 0.3892\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5002 / 6000\n",
      "testing accuracy = 0.8337\n",
      "--------- epoch: 1080 ---------\n",
      "training loss = 0.3891\n",
      "training accuracy = 0.8407\n",
      "num_train_corrects / train_total_examples = 5044 / 6000\n",
      "num_test_corrects / test_total_examples = 5002 / 6000\n",
      "testing accuracy = 0.8337\n",
      "--------- epoch: 1081 ---------\n",
      "training loss = 0.3891\n",
      "training accuracy = 0.8407\n",
      "num_train_corrects / train_total_examples = 5044 / 6000\n",
      "num_test_corrects / test_total_examples = 5002 / 6000\n",
      "testing accuracy = 0.8337\n",
      "--------- epoch: 1082 ---------\n",
      "training loss = 0.3891\n",
      "training accuracy = 0.8403\n",
      "num_train_corrects / train_total_examples = 5042 / 6000\n",
      "num_test_corrects / test_total_examples = 5002 / 6000\n",
      "testing accuracy = 0.8337\n",
      "--------- epoch: 1083 ---------\n",
      "training loss = 0.3891\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5002 / 6000\n",
      "testing accuracy = 0.8337\n",
      "--------- epoch: 1084 ---------\n",
      "training loss = 0.3890\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5002 / 6000\n",
      "testing accuracy = 0.8337\n",
      "--------- epoch: 1085 ---------\n",
      "training loss = 0.3890\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5002 / 6000\n",
      "testing accuracy = 0.8337\n",
      "--------- epoch: 1086 ---------\n",
      "training loss = 0.3890\n",
      "training accuracy = 0.8405\n",
      "num_train_corrects / train_total_examples = 5043 / 6000\n",
      "num_test_corrects / test_total_examples = 5002 / 6000\n",
      "testing accuracy = 0.8337\n",
      "--------- epoch: 1087 ---------\n",
      "training loss = 0.3890\n",
      "training accuracy = 0.8407\n",
      "num_train_corrects / train_total_examples = 5044 / 6000\n",
      "num_test_corrects / test_total_examples = 5002 / 6000\n",
      "testing accuracy = 0.8337\n",
      "--------- epoch: 1088 ---------\n",
      "training loss = 0.3889\n",
      "training accuracy = 0.8407\n",
      "num_train_corrects / train_total_examples = 5044 / 6000\n",
      "num_test_corrects / test_total_examples = 5002 / 6000\n",
      "testing accuracy = 0.8337\n",
      "--------- epoch: 1089 ---------\n",
      "training loss = 0.3889\n",
      "training accuracy = 0.8407\n",
      "num_train_corrects / train_total_examples = 5044 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1090 ---------\n",
      "training loss = 0.3889\n",
      "training accuracy = 0.8407\n",
      "num_train_corrects / train_total_examples = 5044 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1091 ---------\n",
      "training loss = 0.3889\n",
      "training accuracy = 0.8407\n",
      "num_train_corrects / train_total_examples = 5044 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1092 ---------\n",
      "training loss = 0.3889\n",
      "training accuracy = 0.8407\n",
      "num_train_corrects / train_total_examples = 5044 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1093 ---------\n",
      "training loss = 0.3888\n",
      "training accuracy = 0.8407\n",
      "num_train_corrects / train_total_examples = 5044 / 6000\n",
      "num_test_corrects / test_total_examples = 5002 / 6000\n",
      "testing accuracy = 0.8337\n",
      "--------- epoch: 1094 ---------\n",
      "training loss = 0.3888\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1095 ---------\n",
      "training loss = 0.3888\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1096 ---------\n",
      "training loss = 0.3888\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1097 ---------\n",
      "training loss = 0.3887\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1098 ---------\n",
      "training loss = 0.3887\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5002 / 6000\n",
      "testing accuracy = 0.8337\n",
      "--------- epoch: 1099 ---------\n",
      "training loss = 0.3887\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5002 / 6000\n",
      "testing accuracy = 0.8337\n",
      "--------- epoch: 1100 ---------\n",
      "training loss = 0.3887\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1101 ---------\n",
      "training loss = 0.3887\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1102 ---------\n",
      "training loss = 0.3886\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1103 ---------\n",
      "training loss = 0.3886\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1104 ---------\n",
      "training loss = 0.3886\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1105 ---------\n",
      "training loss = 0.3886\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1106 ---------\n",
      "training loss = 0.3885\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1107 ---------\n",
      "training loss = 0.3885\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1108 ---------\n",
      "training loss = 0.3885\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1109 ---------\n",
      "training loss = 0.3885\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5003 / 6000\n",
      "testing accuracy = 0.8338\n",
      "--------- epoch: 1110 ---------\n",
      "training loss = 0.3885\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5004 / 6000\n",
      "testing accuracy = 0.8340\n",
      "--------- epoch: 1111 ---------\n",
      "training loss = 0.3884\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5004 / 6000\n",
      "testing accuracy = 0.8340\n",
      "--------- epoch: 1112 ---------\n",
      "training loss = 0.3884\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5004 / 6000\n",
      "testing accuracy = 0.8340\n",
      "--------- epoch: 1113 ---------\n",
      "training loss = 0.3884\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5004 / 6000\n",
      "testing accuracy = 0.8340\n",
      "--------- epoch: 1114 ---------\n",
      "training loss = 0.3884\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5004 / 6000\n",
      "testing accuracy = 0.8340\n",
      "--------- epoch: 1115 ---------\n",
      "training loss = 0.3883\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5004 / 6000\n",
      "testing accuracy = 0.8340\n",
      "--------- epoch: 1116 ---------\n",
      "training loss = 0.3883\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5004 / 6000\n",
      "testing accuracy = 0.8340\n",
      "--------- epoch: 1117 ---------\n",
      "training loss = 0.3883\n",
      "training accuracy = 0.8410\n",
      "num_train_corrects / train_total_examples = 5046 / 6000\n",
      "num_test_corrects / test_total_examples = 5004 / 6000\n",
      "testing accuracy = 0.8340\n",
      "--------- epoch: 1118 ---------\n",
      "training loss = 0.3883\n",
      "training accuracy = 0.8410\n",
      "num_train_corrects / train_total_examples = 5046 / 6000\n",
      "num_test_corrects / test_total_examples = 5004 / 6000\n",
      "testing accuracy = 0.8340\n",
      "--------- epoch: 1119 ---------\n",
      "training loss = 0.3883\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5005 / 6000\n",
      "testing accuracy = 0.8342\n",
      "--------- epoch: 1120 ---------\n",
      "training loss = 0.3882\n",
      "training accuracy = 0.8408\n",
      "num_train_corrects / train_total_examples = 5045 / 6000\n",
      "num_test_corrects / test_total_examples = 5005 / 6000\n",
      "testing accuracy = 0.8342\n",
      "--------- epoch: 1121 ---------\n",
      "training loss = 0.3882\n",
      "training accuracy = 0.8410\n",
      "num_train_corrects / train_total_examples = 5046 / 6000\n",
      "num_test_corrects / test_total_examples = 5005 / 6000\n",
      "testing accuracy = 0.8342\n",
      "--------- epoch: 1122 ---------\n",
      "training loss = 0.3882\n",
      "training accuracy = 0.8410\n",
      "num_train_corrects / train_total_examples = 5046 / 6000\n",
      "num_test_corrects / test_total_examples = 5005 / 6000\n",
      "testing accuracy = 0.8342\n",
      "--------- epoch: 1123 ---------\n",
      "training loss = 0.3882\n",
      "training accuracy = 0.8410\n",
      "num_train_corrects / train_total_examples = 5046 / 6000\n",
      "num_test_corrects / test_total_examples = 5005 / 6000\n",
      "testing accuracy = 0.8342\n",
      "--------- epoch: 1124 ---------\n",
      "training loss = 0.3882\n",
      "training accuracy = 0.8410\n",
      "num_train_corrects / train_total_examples = 5046 / 6000\n",
      "num_test_corrects / test_total_examples = 5005 / 6000\n",
      "testing accuracy = 0.8342\n",
      "--------- epoch: 1125 ---------\n",
      "training loss = 0.3881\n",
      "training accuracy = 0.8410\n",
      "num_train_corrects / train_total_examples = 5046 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1126 ---------\n",
      "training loss = 0.3881\n",
      "training accuracy = 0.8410\n",
      "num_train_corrects / train_total_examples = 5046 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1127 ---------\n",
      "training loss = 0.3881\n",
      "training accuracy = 0.8410\n",
      "num_train_corrects / train_total_examples = 5046 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1128 ---------\n",
      "training loss = 0.3881\n",
      "training accuracy = 0.8412\n",
      "num_train_corrects / train_total_examples = 5047 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1129 ---------\n",
      "training loss = 0.3880\n",
      "training accuracy = 0.8412\n",
      "num_train_corrects / train_total_examples = 5047 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1130 ---------\n",
      "training loss = 0.3880\n",
      "training accuracy = 0.8412\n",
      "num_train_corrects / train_total_examples = 5047 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1131 ---------\n",
      "training loss = 0.3880\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1132 ---------\n",
      "training loss = 0.3880\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1133 ---------\n",
      "training loss = 0.3880\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1134 ---------\n",
      "training loss = 0.3879\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1135 ---------\n",
      "training loss = 0.3879\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1136 ---------\n",
      "training loss = 0.3879\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1137 ---------\n",
      "training loss = 0.3879\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1138 ---------\n",
      "training loss = 0.3878\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1139 ---------\n",
      "training loss = 0.3878\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1140 ---------\n",
      "training loss = 0.3878\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1141 ---------\n",
      "training loss = 0.3878\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1142 ---------\n",
      "training loss = 0.3878\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1143 ---------\n",
      "training loss = 0.3877\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1144 ---------\n",
      "training loss = 0.3877\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1145 ---------\n",
      "training loss = 0.3877\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1146 ---------\n",
      "training loss = 0.3877\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1147 ---------\n",
      "training loss = 0.3877\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5006 / 6000\n",
      "testing accuracy = 0.8343\n",
      "--------- epoch: 1148 ---------\n",
      "training loss = 0.3876\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5007 / 6000\n",
      "testing accuracy = 0.8345\n",
      "--------- epoch: 1149 ---------\n",
      "training loss = 0.3876\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5008 / 6000\n",
      "testing accuracy = 0.8347\n",
      "--------- epoch: 1150 ---------\n",
      "training loss = 0.3876\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5008 / 6000\n",
      "testing accuracy = 0.8347\n",
      "--------- epoch: 1151 ---------\n",
      "training loss = 0.3876\n",
      "training accuracy = 0.8413\n",
      "num_train_corrects / train_total_examples = 5048 / 6000\n",
      "num_test_corrects / test_total_examples = 5008 / 6000\n",
      "testing accuracy = 0.8347\n",
      "--------- epoch: 1152 ---------\n",
      "training loss = 0.3875\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5008 / 6000\n",
      "testing accuracy = 0.8347\n",
      "--------- epoch: 1153 ---------\n",
      "training loss = 0.3875\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5009 / 6000\n",
      "testing accuracy = 0.8348\n",
      "--------- epoch: 1154 ---------\n",
      "training loss = 0.3875\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1155 ---------\n",
      "training loss = 0.3875\n",
      "training accuracy = 0.8417\n",
      "num_train_corrects / train_total_examples = 5050 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1156 ---------\n",
      "training loss = 0.3875\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1157 ---------\n",
      "training loss = 0.3874\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1158 ---------\n",
      "training loss = 0.3874\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1159 ---------\n",
      "training loss = 0.3874\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1160 ---------\n",
      "training loss = 0.3874\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1161 ---------\n",
      "training loss = 0.3874\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1162 ---------\n",
      "training loss = 0.3873\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1163 ---------\n",
      "training loss = 0.3873\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1164 ---------\n",
      "training loss = 0.3873\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1165 ---------\n",
      "training loss = 0.3873\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1166 ---------\n",
      "training loss = 0.3873\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1167 ---------\n",
      "training loss = 0.3872\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1168 ---------\n",
      "training loss = 0.3872\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1169 ---------\n",
      "training loss = 0.3872\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1170 ---------\n",
      "training loss = 0.3872\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1171 ---------\n",
      "training loss = 0.3871\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1172 ---------\n",
      "training loss = 0.3871\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1173 ---------\n",
      "training loss = 0.3871\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1174 ---------\n",
      "training loss = 0.3871\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1175 ---------\n",
      "training loss = 0.3871\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1176 ---------\n",
      "training loss = 0.3870\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1177 ---------\n",
      "training loss = 0.3870\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1178 ---------\n",
      "training loss = 0.3870\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1179 ---------\n",
      "training loss = 0.3870\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1180 ---------\n",
      "training loss = 0.3870\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1181 ---------\n",
      "training loss = 0.3869\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1182 ---------\n",
      "training loss = 0.3869\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1183 ---------\n",
      "training loss = 0.3869\n",
      "training accuracy = 0.8415\n",
      "num_train_corrects / train_total_examples = 5049 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1184 ---------\n",
      "training loss = 0.3869\n",
      "training accuracy = 0.8417\n",
      "num_train_corrects / train_total_examples = 5050 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1185 ---------\n",
      "training loss = 0.3869\n",
      "training accuracy = 0.8417\n",
      "num_train_corrects / train_total_examples = 5050 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1186 ---------\n",
      "training loss = 0.3868\n",
      "training accuracy = 0.8417\n",
      "num_train_corrects / train_total_examples = 5050 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1187 ---------\n",
      "training loss = 0.3868\n",
      "training accuracy = 0.8417\n",
      "num_train_corrects / train_total_examples = 5050 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1188 ---------\n",
      "training loss = 0.3868\n",
      "training accuracy = 0.8418\n",
      "num_train_corrects / train_total_examples = 5051 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1189 ---------\n",
      "training loss = 0.3868\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1190 ---------\n",
      "training loss = 0.3868\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5010 / 6000\n",
      "testing accuracy = 0.8350\n",
      "--------- epoch: 1191 ---------\n",
      "training loss = 0.3867\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5011 / 6000\n",
      "testing accuracy = 0.8352\n",
      "--------- epoch: 1192 ---------\n",
      "training loss = 0.3867\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5011 / 6000\n",
      "testing accuracy = 0.8352\n",
      "--------- epoch: 1193 ---------\n",
      "training loss = 0.3867\n",
      "training accuracy = 0.8422\n",
      "num_train_corrects / train_total_examples = 5053 / 6000\n",
      "num_test_corrects / test_total_examples = 5011 / 6000\n",
      "testing accuracy = 0.8352\n",
      "--------- epoch: 1194 ---------\n",
      "training loss = 0.3867\n",
      "training accuracy = 0.8422\n",
      "num_train_corrects / train_total_examples = 5053 / 6000\n",
      "num_test_corrects / test_total_examples = 5011 / 6000\n",
      "testing accuracy = 0.8352\n",
      "--------- epoch: 1195 ---------\n",
      "training loss = 0.3867\n",
      "training accuracy = 0.8422\n",
      "num_train_corrects / train_total_examples = 5053 / 6000\n",
      "num_test_corrects / test_total_examples = 5011 / 6000\n",
      "testing accuracy = 0.8352\n",
      "--------- epoch: 1196 ---------\n",
      "training loss = 0.3866\n",
      "training accuracy = 0.8422\n",
      "num_train_corrects / train_total_examples = 5053 / 6000\n",
      "num_test_corrects / test_total_examples = 5011 / 6000\n",
      "testing accuracy = 0.8352\n",
      "--------- epoch: 1197 ---------\n",
      "training loss = 0.3866\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5013 / 6000\n",
      "testing accuracy = 0.8355\n",
      "--------- epoch: 1198 ---------\n",
      "training loss = 0.3866\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5014 / 6000\n",
      "testing accuracy = 0.8357\n",
      "--------- epoch: 1199 ---------\n",
      "training loss = 0.3866\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5014 / 6000\n",
      "testing accuracy = 0.8357\n",
      "--------- epoch: 1200 ---------\n",
      "training loss = 0.3866\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1201 ---------\n",
      "training loss = 0.3865\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1202 ---------\n",
      "training loss = 0.3865\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1203 ---------\n",
      "training loss = 0.3865\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1204 ---------\n",
      "training loss = 0.3865\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1205 ---------\n",
      "training loss = 0.3865\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1206 ---------\n",
      "training loss = 0.3864\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1207 ---------\n",
      "training loss = 0.3864\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1208 ---------\n",
      "training loss = 0.3864\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1209 ---------\n",
      "training loss = 0.3864\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1210 ---------\n",
      "training loss = 0.3863\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1211 ---------\n",
      "training loss = 0.3863\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1212 ---------\n",
      "training loss = 0.3863\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5014 / 6000\n",
      "testing accuracy = 0.8357\n",
      "--------- epoch: 1213 ---------\n",
      "training loss = 0.3863\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5014 / 6000\n",
      "testing accuracy = 0.8357\n",
      "--------- epoch: 1214 ---------\n",
      "training loss = 0.3863\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5014 / 6000\n",
      "testing accuracy = 0.8357\n",
      "--------- epoch: 1215 ---------\n",
      "training loss = 0.3862\n",
      "training accuracy = 0.8420\n",
      "num_train_corrects / train_total_examples = 5052 / 6000\n",
      "num_test_corrects / test_total_examples = 5014 / 6000\n",
      "testing accuracy = 0.8357\n",
      "--------- epoch: 1216 ---------\n",
      "training loss = 0.3862\n",
      "training accuracy = 0.8422\n",
      "num_train_corrects / train_total_examples = 5053 / 6000\n",
      "num_test_corrects / test_total_examples = 5014 / 6000\n",
      "testing accuracy = 0.8357\n",
      "--------- epoch: 1217 ---------\n",
      "training loss = 0.3862\n",
      "training accuracy = 0.8423\n",
      "num_train_corrects / train_total_examples = 5054 / 6000\n",
      "num_test_corrects / test_total_examples = 5014 / 6000\n",
      "testing accuracy = 0.8357\n",
      "--------- epoch: 1218 ---------\n",
      "training loss = 0.3862\n",
      "training accuracy = 0.8423\n",
      "num_train_corrects / train_total_examples = 5054 / 6000\n",
      "num_test_corrects / test_total_examples = 5014 / 6000\n",
      "testing accuracy = 0.8357\n",
      "--------- epoch: 1219 ---------\n",
      "training loss = 0.3862\n",
      "training accuracy = 0.8425\n",
      "num_train_corrects / train_total_examples = 5055 / 6000\n",
      "num_test_corrects / test_total_examples = 5014 / 6000\n",
      "testing accuracy = 0.8357\n",
      "--------- epoch: 1220 ---------\n",
      "training loss = 0.3861\n",
      "training accuracy = 0.8425\n",
      "num_train_corrects / train_total_examples = 5055 / 6000\n",
      "num_test_corrects / test_total_examples = 5014 / 6000\n",
      "testing accuracy = 0.8357\n",
      "--------- epoch: 1221 ---------\n",
      "training loss = 0.3861\n",
      "training accuracy = 0.8425\n",
      "num_train_corrects / train_total_examples = 5055 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1222 ---------\n",
      "training loss = 0.3861\n",
      "training accuracy = 0.8425\n",
      "num_train_corrects / train_total_examples = 5055 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1223 ---------\n",
      "training loss = 0.3861\n",
      "training accuracy = 0.8425\n",
      "num_train_corrects / train_total_examples = 5055 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1224 ---------\n",
      "training loss = 0.3861\n",
      "training accuracy = 0.8425\n",
      "num_train_corrects / train_total_examples = 5055 / 6000\n",
      "num_test_corrects / test_total_examples = 5015 / 6000\n",
      "testing accuracy = 0.8358\n",
      "--------- epoch: 1225 ---------\n",
      "training loss = 0.3860\n",
      "training accuracy = 0.8425\n",
      "num_train_corrects / train_total_examples = 5055 / 6000\n",
      "num_test_corrects / test_total_examples = 5016 / 6000\n",
      "testing accuracy = 0.8360\n",
      "--------- epoch: 1226 ---------\n",
      "training loss = 0.3860\n",
      "training accuracy = 0.8427\n",
      "num_train_corrects / train_total_examples = 5056 / 6000\n",
      "num_test_corrects / test_total_examples = 5016 / 6000\n",
      "testing accuracy = 0.8360\n",
      "--------- epoch: 1227 ---------\n",
      "training loss = 0.3860\n",
      "training accuracy = 0.8427\n",
      "num_train_corrects / train_total_examples = 5056 / 6000\n",
      "num_test_corrects / test_total_examples = 5016 / 6000\n",
      "testing accuracy = 0.8360\n",
      "--------- epoch: 1228 ---------\n",
      "training loss = 0.3860\n",
      "training accuracy = 0.8428\n",
      "num_train_corrects / train_total_examples = 5057 / 6000\n",
      "num_test_corrects / test_total_examples = 5016 / 6000\n",
      "testing accuracy = 0.8360\n",
      "--------- epoch: 1229 ---------\n",
      "training loss = 0.3860\n",
      "training accuracy = 0.8428\n",
      "num_train_corrects / train_total_examples = 5057 / 6000\n",
      "num_test_corrects / test_total_examples = 5016 / 6000\n",
      "testing accuracy = 0.8360\n",
      "--------- epoch: 1230 ---------\n",
      "training loss = 0.3860\n",
      "training accuracy = 0.8428\n",
      "num_train_corrects / train_total_examples = 5057 / 6000\n",
      "num_test_corrects / test_total_examples = 5016 / 6000\n",
      "testing accuracy = 0.8360\n",
      "--------- epoch: 1231 ---------\n",
      "training loss = 0.3859\n",
      "training accuracy = 0.8428\n",
      "num_train_corrects / train_total_examples = 5057 / 6000\n",
      "num_test_corrects / test_total_examples = 5016 / 6000\n",
      "testing accuracy = 0.8360\n",
      "--------- epoch: 1232 ---------\n",
      "training loss = 0.3859\n",
      "training accuracy = 0.8428\n",
      "num_train_corrects / train_total_examples = 5057 / 6000\n",
      "num_test_corrects / test_total_examples = 5016 / 6000\n",
      "testing accuracy = 0.8360\n",
      "--------- epoch: 1233 ---------\n",
      "training loss = 0.3859\n",
      "training accuracy = 0.8428\n",
      "num_train_corrects / train_total_examples = 5057 / 6000\n",
      "num_test_corrects / test_total_examples = 5016 / 6000\n",
      "testing accuracy = 0.8360\n",
      "--------- epoch: 1234 ---------\n",
      "training loss = 0.3859\n",
      "training accuracy = 0.8428\n",
      "num_train_corrects / train_total_examples = 5057 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1235 ---------\n",
      "training loss = 0.3859\n",
      "training accuracy = 0.8428\n",
      "num_train_corrects / train_total_examples = 5057 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1236 ---------\n",
      "training loss = 0.3858\n",
      "training accuracy = 0.8428\n",
      "num_train_corrects / train_total_examples = 5057 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1237 ---------\n",
      "training loss = 0.3858\n",
      "training accuracy = 0.8428\n",
      "num_train_corrects / train_total_examples = 5057 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1238 ---------\n",
      "training loss = 0.3858\n",
      "training accuracy = 0.8428\n",
      "num_train_corrects / train_total_examples = 5057 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1239 ---------\n",
      "training loss = 0.3858\n",
      "training accuracy = 0.8428\n",
      "num_train_corrects / train_total_examples = 5057 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1240 ---------\n",
      "training loss = 0.3858\n",
      "training accuracy = 0.8428\n",
      "num_train_corrects / train_total_examples = 5057 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1241 ---------\n",
      "training loss = 0.3857\n",
      "training accuracy = 0.8428\n",
      "num_train_corrects / train_total_examples = 5057 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1242 ---------\n",
      "training loss = 0.3857\n",
      "training accuracy = 0.8430\n",
      "num_train_corrects / train_total_examples = 5058 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1243 ---------\n",
      "training loss = 0.3857\n",
      "training accuracy = 0.8430\n",
      "num_train_corrects / train_total_examples = 5058 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1244 ---------\n",
      "training loss = 0.3857\n",
      "training accuracy = 0.8430\n",
      "num_train_corrects / train_total_examples = 5058 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1245 ---------\n",
      "training loss = 0.3857\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1246 ---------\n",
      "training loss = 0.3856\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1247 ---------\n",
      "training loss = 0.3856\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1248 ---------\n",
      "training loss = 0.3856\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1249 ---------\n",
      "training loss = 0.3856\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1250 ---------\n",
      "training loss = 0.3856\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5017 / 6000\n",
      "testing accuracy = 0.8362\n",
      "--------- epoch: 1251 ---------\n",
      "training loss = 0.3855\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5018 / 6000\n",
      "testing accuracy = 0.8363\n",
      "--------- epoch: 1252 ---------\n",
      "training loss = 0.3855\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5018 / 6000\n",
      "testing accuracy = 0.8363\n",
      "--------- epoch: 1253 ---------\n",
      "training loss = 0.3855\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5018 / 6000\n",
      "testing accuracy = 0.8363\n",
      "--------- epoch: 1254 ---------\n",
      "training loss = 0.3855\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5018 / 6000\n",
      "testing accuracy = 0.8363\n",
      "--------- epoch: 1255 ---------\n",
      "training loss = 0.3855\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5018 / 6000\n",
      "testing accuracy = 0.8363\n",
      "--------- epoch: 1256 ---------\n",
      "training loss = 0.3854\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5018 / 6000\n",
      "testing accuracy = 0.8363\n",
      "--------- epoch: 1257 ---------\n",
      "training loss = 0.3854\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5019 / 6000\n",
      "testing accuracy = 0.8365\n",
      "--------- epoch: 1258 ---------\n",
      "training loss = 0.3854\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5019 / 6000\n",
      "testing accuracy = 0.8365\n",
      "--------- epoch: 1259 ---------\n",
      "training loss = 0.3854\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5019 / 6000\n",
      "testing accuracy = 0.8365\n",
      "--------- epoch: 1260 ---------\n",
      "training loss = 0.3854\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5019 / 6000\n",
      "testing accuracy = 0.8365\n",
      "--------- epoch: 1261 ---------\n",
      "training loss = 0.3853\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5020 / 6000\n",
      "testing accuracy = 0.8367\n",
      "--------- epoch: 1262 ---------\n",
      "training loss = 0.3853\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5020 / 6000\n",
      "testing accuracy = 0.8367\n",
      "--------- epoch: 1263 ---------\n",
      "training loss = 0.3853\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5020 / 6000\n",
      "testing accuracy = 0.8367\n",
      "--------- epoch: 1264 ---------\n",
      "training loss = 0.3853\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5020 / 6000\n",
      "testing accuracy = 0.8367\n",
      "--------- epoch: 1265 ---------\n",
      "training loss = 0.3853\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5020 / 6000\n",
      "testing accuracy = 0.8367\n",
      "--------- epoch: 1266 ---------\n",
      "training loss = 0.3853\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5020 / 6000\n",
      "testing accuracy = 0.8367\n",
      "--------- epoch: 1267 ---------\n",
      "training loss = 0.3852\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5020 / 6000\n",
      "testing accuracy = 0.8367\n",
      "--------- epoch: 1268 ---------\n",
      "training loss = 0.3852\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5020 / 6000\n",
      "testing accuracy = 0.8367\n",
      "--------- epoch: 1269 ---------\n",
      "training loss = 0.3852\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5020 / 6000\n",
      "testing accuracy = 0.8367\n",
      "--------- epoch: 1270 ---------\n",
      "training loss = 0.3852\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5020 / 6000\n",
      "testing accuracy = 0.8367\n",
      "--------- epoch: 1271 ---------\n",
      "training loss = 0.3852\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5020 / 6000\n",
      "testing accuracy = 0.8367\n",
      "--------- epoch: 1272 ---------\n",
      "training loss = 0.3851\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5020 / 6000\n",
      "testing accuracy = 0.8367\n",
      "--------- epoch: 1273 ---------\n",
      "training loss = 0.3851\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5021 / 6000\n",
      "testing accuracy = 0.8368\n",
      "--------- epoch: 1274 ---------\n",
      "training loss = 0.3851\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5021 / 6000\n",
      "testing accuracy = 0.8368\n",
      "--------- epoch: 1275 ---------\n",
      "training loss = 0.3851\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5021 / 6000\n",
      "testing accuracy = 0.8368\n",
      "--------- epoch: 1276 ---------\n",
      "training loss = 0.3851\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5021 / 6000\n",
      "testing accuracy = 0.8368\n",
      "--------- epoch: 1277 ---------\n",
      "training loss = 0.3850\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5021 / 6000\n",
      "testing accuracy = 0.8368\n",
      "--------- epoch: 1278 ---------\n",
      "training loss = 0.3850\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5021 / 6000\n",
      "testing accuracy = 0.8368\n",
      "--------- epoch: 1279 ---------\n",
      "training loss = 0.3850\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5021 / 6000\n",
      "testing accuracy = 0.8368\n",
      "--------- epoch: 1280 ---------\n",
      "training loss = 0.3850\n",
      "training accuracy = 0.8432\n",
      "num_train_corrects / train_total_examples = 5059 / 6000\n",
      "num_test_corrects / test_total_examples = 5021 / 6000\n",
      "testing accuracy = 0.8368\n",
      "--------- epoch: 1281 ---------\n",
      "training loss = 0.3850\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5022 / 6000\n",
      "testing accuracy = 0.8370\n",
      "--------- epoch: 1282 ---------\n",
      "training loss = 0.3849\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5022 / 6000\n",
      "testing accuracy = 0.8370\n",
      "--------- epoch: 1283 ---------\n",
      "training loss = 0.3849\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5022 / 6000\n",
      "testing accuracy = 0.8370\n",
      "--------- epoch: 1284 ---------\n",
      "training loss = 0.3849\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5022 / 6000\n",
      "testing accuracy = 0.8370\n",
      "--------- epoch: 1285 ---------\n",
      "training loss = 0.3849\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5022 / 6000\n",
      "testing accuracy = 0.8370\n",
      "--------- epoch: 1286 ---------\n",
      "training loss = 0.3849\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5023 / 6000\n",
      "testing accuracy = 0.8372\n",
      "--------- epoch: 1287 ---------\n",
      "training loss = 0.3849\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5023 / 6000\n",
      "testing accuracy = 0.8372\n",
      "--------- epoch: 1288 ---------\n",
      "training loss = 0.3848\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5023 / 6000\n",
      "testing accuracy = 0.8372\n",
      "--------- epoch: 1289 ---------\n",
      "training loss = 0.3848\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5024 / 6000\n",
      "testing accuracy = 0.8373\n",
      "--------- epoch: 1290 ---------\n",
      "training loss = 0.3848\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1291 ---------\n",
      "training loss = 0.3848\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1292 ---------\n",
      "training loss = 0.3848\n",
      "training accuracy = 0.8435\n",
      "num_train_corrects / train_total_examples = 5061 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1293 ---------\n",
      "training loss = 0.3847\n",
      "training accuracy = 0.8435\n",
      "num_train_corrects / train_total_examples = 5061 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1294 ---------\n",
      "training loss = 0.3847\n",
      "training accuracy = 0.8435\n",
      "num_train_corrects / train_total_examples = 5061 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1295 ---------\n",
      "training loss = 0.3847\n",
      "training accuracy = 0.8435\n",
      "num_train_corrects / train_total_examples = 5061 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1296 ---------\n",
      "training loss = 0.3847\n",
      "training accuracy = 0.8435\n",
      "num_train_corrects / train_total_examples = 5061 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1297 ---------\n",
      "training loss = 0.3847\n",
      "training accuracy = 0.8435\n",
      "num_train_corrects / train_total_examples = 5061 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1298 ---------\n",
      "training loss = 0.3846\n",
      "training accuracy = 0.8435\n",
      "num_train_corrects / train_total_examples = 5061 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1299 ---------\n",
      "training loss = 0.3846\n",
      "training accuracy = 0.8435\n",
      "num_train_corrects / train_total_examples = 5061 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1300 ---------\n",
      "training loss = 0.3846\n",
      "training accuracy = 0.8435\n",
      "num_train_corrects / train_total_examples = 5061 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1301 ---------\n",
      "training loss = 0.3846\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1302 ---------\n",
      "training loss = 0.3846\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1303 ---------\n",
      "training loss = 0.3846\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1304 ---------\n",
      "training loss = 0.3845\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1305 ---------\n",
      "training loss = 0.3845\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1306 ---------\n",
      "training loss = 0.3845\n",
      "training accuracy = 0.8433\n",
      "num_train_corrects / train_total_examples = 5060 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1307 ---------\n",
      "training loss = 0.3845\n",
      "training accuracy = 0.8435\n",
      "num_train_corrects / train_total_examples = 5061 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1308 ---------\n",
      "training loss = 0.3845\n",
      "training accuracy = 0.8435\n",
      "num_train_corrects / train_total_examples = 5061 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1309 ---------\n",
      "training loss = 0.3844\n",
      "training accuracy = 0.8437\n",
      "num_train_corrects / train_total_examples = 5062 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1310 ---------\n",
      "training loss = 0.3844\n",
      "training accuracy = 0.8437\n",
      "num_train_corrects / train_total_examples = 5062 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1311 ---------\n",
      "training loss = 0.3844\n",
      "training accuracy = 0.8437\n",
      "num_train_corrects / train_total_examples = 5062 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1312 ---------\n",
      "training loss = 0.3844\n",
      "training accuracy = 0.8437\n",
      "num_train_corrects / train_total_examples = 5062 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1313 ---------\n",
      "training loss = 0.3844\n",
      "training accuracy = 0.8437\n",
      "num_train_corrects / train_total_examples = 5062 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1314 ---------\n",
      "training loss = 0.3844\n",
      "training accuracy = 0.8437\n",
      "num_train_corrects / train_total_examples = 5062 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1315 ---------\n",
      "training loss = 0.3843\n",
      "training accuracy = 0.8437\n",
      "num_train_corrects / train_total_examples = 5062 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1316 ---------\n",
      "training loss = 0.3843\n",
      "training accuracy = 0.8438\n",
      "num_train_corrects / train_total_examples = 5063 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1317 ---------\n",
      "training loss = 0.3843\n",
      "training accuracy = 0.8438\n",
      "num_train_corrects / train_total_examples = 5063 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1318 ---------\n",
      "training loss = 0.3843\n",
      "training accuracy = 0.8438\n",
      "num_train_corrects / train_total_examples = 5063 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1319 ---------\n",
      "training loss = 0.3843\n",
      "training accuracy = 0.8440\n",
      "num_train_corrects / train_total_examples = 5064 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1320 ---------\n",
      "training loss = 0.3842\n",
      "training accuracy = 0.8440\n",
      "num_train_corrects / train_total_examples = 5064 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1321 ---------\n",
      "training loss = 0.3842\n",
      "training accuracy = 0.8442\n",
      "num_train_corrects / train_total_examples = 5065 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1322 ---------\n",
      "training loss = 0.3842\n",
      "training accuracy = 0.8442\n",
      "num_train_corrects / train_total_examples = 5065 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1323 ---------\n",
      "training loss = 0.3842\n",
      "training accuracy = 0.8443\n",
      "num_train_corrects / train_total_examples = 5066 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1324 ---------\n",
      "training loss = 0.3842\n",
      "training accuracy = 0.8443\n",
      "num_train_corrects / train_total_examples = 5066 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1325 ---------\n",
      "training loss = 0.3841\n",
      "training accuracy = 0.8445\n",
      "num_train_corrects / train_total_examples = 5067 / 6000\n",
      "num_test_corrects / test_total_examples = 5025 / 6000\n",
      "testing accuracy = 0.8375\n",
      "--------- epoch: 1326 ---------\n",
      "training loss = 0.3841\n",
      "training accuracy = 0.8445\n",
      "num_train_corrects / train_total_examples = 5067 / 6000\n",
      "num_test_corrects / test_total_examples = 5026 / 6000\n",
      "testing accuracy = 0.8377\n",
      "--------- epoch: 1327 ---------\n",
      "training loss = 0.3841\n",
      "training accuracy = 0.8447\n",
      "num_train_corrects / train_total_examples = 5068 / 6000\n",
      "num_test_corrects / test_total_examples = 5026 / 6000\n",
      "testing accuracy = 0.8377\n",
      "--------- epoch: 1328 ---------\n",
      "training loss = 0.3841\n",
      "training accuracy = 0.8447\n",
      "num_train_corrects / train_total_examples = 5068 / 6000\n",
      "num_test_corrects / test_total_examples = 5026 / 6000\n",
      "testing accuracy = 0.8377\n",
      "--------- epoch: 1329 ---------\n",
      "training loss = 0.3841\n",
      "training accuracy = 0.8447\n",
      "num_train_corrects / train_total_examples = 5068 / 6000\n",
      "num_test_corrects / test_total_examples = 5026 / 6000\n",
      "testing accuracy = 0.8377\n",
      "--------- epoch: 1330 ---------\n",
      "training loss = 0.3841\n",
      "training accuracy = 0.8447\n",
      "num_train_corrects / train_total_examples = 5068 / 6000\n",
      "num_test_corrects / test_total_examples = 5026 / 6000\n",
      "testing accuracy = 0.8377\n",
      "--------- epoch: 1331 ---------\n",
      "training loss = 0.3840\n",
      "training accuracy = 0.8448\n",
      "num_train_corrects / train_total_examples = 5069 / 6000\n",
      "num_test_corrects / test_total_examples = 5026 / 6000\n",
      "testing accuracy = 0.8377\n",
      "--------- epoch: 1332 ---------\n",
      "training loss = 0.3840\n",
      "training accuracy = 0.8448\n",
      "num_train_corrects / train_total_examples = 5069 / 6000\n",
      "num_test_corrects / test_total_examples = 5026 / 6000\n",
      "testing accuracy = 0.8377\n",
      "--------- epoch: 1333 ---------\n",
      "training loss = 0.3840\n",
      "training accuracy = 0.8448\n",
      "num_train_corrects / train_total_examples = 5069 / 6000\n",
      "num_test_corrects / test_total_examples = 5026 / 6000\n",
      "testing accuracy = 0.8377\n",
      "--------- epoch: 1334 ---------\n",
      "training loss = 0.3840\n",
      "training accuracy = 0.8448\n",
      "num_train_corrects / train_total_examples = 5069 / 6000\n",
      "num_test_corrects / test_total_examples = 5026 / 6000\n",
      "testing accuracy = 0.8377\n",
      "--------- epoch: 1335 ---------\n",
      "training loss = 0.3840\n",
      "training accuracy = 0.8448\n",
      "num_train_corrects / train_total_examples = 5069 / 6000\n",
      "num_test_corrects / test_total_examples = 5026 / 6000\n",
      "testing accuracy = 0.8377\n",
      "--------- epoch: 1336 ---------\n",
      "training loss = 0.3840\n",
      "training accuracy = 0.8448\n",
      "num_train_corrects / train_total_examples = 5069 / 6000\n",
      "num_test_corrects / test_total_examples = 5026 / 6000\n",
      "testing accuracy = 0.8377\n",
      "--------- epoch: 1337 ---------\n",
      "training loss = 0.3839\n",
      "training accuracy = 0.8448\n",
      "num_train_corrects / train_total_examples = 5069 / 6000\n",
      "num_test_corrects / test_total_examples = 5026 / 6000\n",
      "testing accuracy = 0.8377\n",
      "--------- epoch: 1338 ---------\n",
      "training loss = 0.3839\n",
      "training accuracy = 0.8448\n",
      "num_train_corrects / train_total_examples = 5069 / 6000\n",
      "num_test_corrects / test_total_examples = 5026 / 6000\n",
      "testing accuracy = 0.8377\n",
      "--------- epoch: 1339 ---------\n",
      "training loss = 0.3839\n",
      "training accuracy = 0.8448\n",
      "num_train_corrects / train_total_examples = 5069 / 6000\n",
      "num_test_corrects / test_total_examples = 5027 / 6000\n",
      "testing accuracy = 0.8378\n",
      "--------- epoch: 1340 ---------\n",
      "training loss = 0.3839\n",
      "training accuracy = 0.8448\n",
      "num_train_corrects / train_total_examples = 5069 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1341 ---------\n",
      "training loss = 0.3839\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1342 ---------\n",
      "training loss = 0.3838\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1343 ---------\n",
      "training loss = 0.3838\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1344 ---------\n",
      "training loss = 0.3838\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1345 ---------\n",
      "training loss = 0.3838\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1346 ---------\n",
      "training loss = 0.3838\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1347 ---------\n",
      "training loss = 0.3838\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1348 ---------\n",
      "training loss = 0.3837\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1349 ---------\n",
      "training loss = 0.3837\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1350 ---------\n",
      "training loss = 0.3837\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1351 ---------\n",
      "training loss = 0.3837\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5029 / 6000\n",
      "testing accuracy = 0.8382\n",
      "--------- epoch: 1352 ---------\n",
      "training loss = 0.3837\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5029 / 6000\n",
      "testing accuracy = 0.8382\n",
      "--------- epoch: 1353 ---------\n",
      "training loss = 0.3836\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5029 / 6000\n",
      "testing accuracy = 0.8382\n",
      "--------- epoch: 1354 ---------\n",
      "training loss = 0.3836\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5029 / 6000\n",
      "testing accuracy = 0.8382\n",
      "--------- epoch: 1355 ---------\n",
      "training loss = 0.3836\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5029 / 6000\n",
      "testing accuracy = 0.8382\n",
      "--------- epoch: 1356 ---------\n",
      "training loss = 0.3836\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5029 / 6000\n",
      "testing accuracy = 0.8382\n",
      "--------- epoch: 1357 ---------\n",
      "training loss = 0.3836\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1358 ---------\n",
      "training loss = 0.3836\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1359 ---------\n",
      "training loss = 0.3835\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1360 ---------\n",
      "training loss = 0.3835\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1361 ---------\n",
      "training loss = 0.3835\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1362 ---------\n",
      "training loss = 0.3835\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1363 ---------\n",
      "training loss = 0.3835\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1364 ---------\n",
      "training loss = 0.3835\n",
      "training accuracy = 0.8450\n",
      "num_train_corrects / train_total_examples = 5070 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1365 ---------\n",
      "training loss = 0.3834\n",
      "training accuracy = 0.8452\n",
      "num_train_corrects / train_total_examples = 5071 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1366 ---------\n",
      "training loss = 0.3834\n",
      "training accuracy = 0.8452\n",
      "num_train_corrects / train_total_examples = 5071 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1367 ---------\n",
      "training loss = 0.3834\n",
      "training accuracy = 0.8452\n",
      "num_train_corrects / train_total_examples = 5071 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1368 ---------\n",
      "training loss = 0.3834\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1369 ---------\n",
      "training loss = 0.3834\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1370 ---------\n",
      "training loss = 0.3833\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1371 ---------\n",
      "training loss = 0.3833\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1372 ---------\n",
      "training loss = 0.3833\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1373 ---------\n",
      "training loss = 0.3833\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1374 ---------\n",
      "training loss = 0.3833\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1375 ---------\n",
      "training loss = 0.3833\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1376 ---------\n",
      "training loss = 0.3832\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1377 ---------\n",
      "training loss = 0.3832\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1378 ---------\n",
      "training loss = 0.3832\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1379 ---------\n",
      "training loss = 0.3832\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1380 ---------\n",
      "training loss = 0.3832\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1381 ---------\n",
      "training loss = 0.3832\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1382 ---------\n",
      "training loss = 0.3831\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1383 ---------\n",
      "training loss = 0.3831\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1384 ---------\n",
      "training loss = 0.3831\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1385 ---------\n",
      "training loss = 0.3831\n",
      "training accuracy = 0.8453\n",
      "num_train_corrects / train_total_examples = 5072 / 6000\n",
      "num_test_corrects / test_total_examples = 5029 / 6000\n",
      "testing accuracy = 0.8382\n",
      "--------- epoch: 1386 ---------\n",
      "training loss = 0.3831\n",
      "training accuracy = 0.8455\n",
      "num_train_corrects / train_total_examples = 5073 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1387 ---------\n",
      "training loss = 0.3831\n",
      "training accuracy = 0.8455\n",
      "num_train_corrects / train_total_examples = 5073 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1388 ---------\n",
      "training loss = 0.3830\n",
      "training accuracy = 0.8455\n",
      "num_train_corrects / train_total_examples = 5073 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1389 ---------\n",
      "training loss = 0.3830\n",
      "training accuracy = 0.8457\n",
      "num_train_corrects / train_total_examples = 5074 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1390 ---------\n",
      "training loss = 0.3830\n",
      "training accuracy = 0.8457\n",
      "num_train_corrects / train_total_examples = 5074 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1391 ---------\n",
      "training loss = 0.3830\n",
      "training accuracy = 0.8457\n",
      "num_train_corrects / train_total_examples = 5074 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1392 ---------\n",
      "training loss = 0.3830\n",
      "training accuracy = 0.8457\n",
      "num_train_corrects / train_total_examples = 5074 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1393 ---------\n",
      "training loss = 0.3829\n",
      "training accuracy = 0.8457\n",
      "num_train_corrects / train_total_examples = 5074 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1394 ---------\n",
      "training loss = 0.3829\n",
      "training accuracy = 0.8457\n",
      "num_train_corrects / train_total_examples = 5074 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1395 ---------\n",
      "training loss = 0.3829\n",
      "training accuracy = 0.8457\n",
      "num_train_corrects / train_total_examples = 5074 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1396 ---------\n",
      "training loss = 0.3829\n",
      "training accuracy = 0.8457\n",
      "num_train_corrects / train_total_examples = 5074 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1397 ---------\n",
      "training loss = 0.3829\n",
      "training accuracy = 0.8457\n",
      "num_train_corrects / train_total_examples = 5074 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1398 ---------\n",
      "training loss = 0.3829\n",
      "training accuracy = 0.8457\n",
      "num_train_corrects / train_total_examples = 5074 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1399 ---------\n",
      "training loss = 0.3828\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5028 / 6000\n",
      "testing accuracy = 0.8380\n",
      "--------- epoch: 1400 ---------\n",
      "training loss = 0.3828\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5029 / 6000\n",
      "testing accuracy = 0.8382\n",
      "--------- epoch: 1401 ---------\n",
      "training loss = 0.3828\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5029 / 6000\n",
      "testing accuracy = 0.8382\n",
      "--------- epoch: 1402 ---------\n",
      "training loss = 0.3828\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5029 / 6000\n",
      "testing accuracy = 0.8382\n",
      "--------- epoch: 1403 ---------\n",
      "training loss = 0.3828\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1404 ---------\n",
      "training loss = 0.3828\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1405 ---------\n",
      "training loss = 0.3827\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1406 ---------\n",
      "training loss = 0.3827\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1407 ---------\n",
      "training loss = 0.3827\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5029 / 6000\n",
      "testing accuracy = 0.8382\n",
      "--------- epoch: 1408 ---------\n",
      "training loss = 0.3827\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5029 / 6000\n",
      "testing accuracy = 0.8382\n",
      "--------- epoch: 1409 ---------\n",
      "training loss = 0.3827\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5029 / 6000\n",
      "testing accuracy = 0.8382\n",
      "--------- epoch: 1410 ---------\n",
      "training loss = 0.3827\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1411 ---------\n",
      "training loss = 0.3826\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1412 ---------\n",
      "training loss = 0.3826\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1413 ---------\n",
      "training loss = 0.3826\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1414 ---------\n",
      "training loss = 0.3826\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1415 ---------\n",
      "training loss = 0.3826\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1416 ---------\n",
      "training loss = 0.3826\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1417 ---------\n",
      "training loss = 0.3825\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1418 ---------\n",
      "training loss = 0.3825\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1419 ---------\n",
      "training loss = 0.3825\n",
      "training accuracy = 0.8458\n",
      "num_train_corrects / train_total_examples = 5075 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1420 ---------\n",
      "training loss = 0.3825\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1421 ---------\n",
      "training loss = 0.3825\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1422 ---------\n",
      "training loss = 0.3825\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1423 ---------\n",
      "training loss = 0.3824\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1424 ---------\n",
      "training loss = 0.3824\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1425 ---------\n",
      "training loss = 0.3824\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1426 ---------\n",
      "training loss = 0.3824\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1427 ---------\n",
      "training loss = 0.3824\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1428 ---------\n",
      "training loss = 0.3824\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1429 ---------\n",
      "training loss = 0.3823\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1430 ---------\n",
      "training loss = 0.3823\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1431 ---------\n",
      "training loss = 0.3823\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1432 ---------\n",
      "training loss = 0.3823\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1433 ---------\n",
      "training loss = 0.3823\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1434 ---------\n",
      "training loss = 0.3823\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1435 ---------\n",
      "training loss = 0.3822\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1436 ---------\n",
      "training loss = 0.3822\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1437 ---------\n",
      "training loss = 0.3822\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1438 ---------\n",
      "training loss = 0.3822\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1439 ---------\n",
      "training loss = 0.3822\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1440 ---------\n",
      "training loss = 0.3822\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1441 ---------\n",
      "training loss = 0.3821\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1442 ---------\n",
      "training loss = 0.3821\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1443 ---------\n",
      "training loss = 0.3821\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5030 / 6000\n",
      "testing accuracy = 0.8383\n",
      "--------- epoch: 1444 ---------\n",
      "training loss = 0.3821\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1445 ---------\n",
      "training loss = 0.3821\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1446 ---------\n",
      "training loss = 0.3821\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1447 ---------\n",
      "training loss = 0.3820\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1448 ---------\n",
      "training loss = 0.3820\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1449 ---------\n",
      "training loss = 0.3820\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1450 ---------\n",
      "training loss = 0.3820\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1451 ---------\n",
      "training loss = 0.3820\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1452 ---------\n",
      "training loss = 0.3820\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1453 ---------\n",
      "training loss = 0.3819\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1454 ---------\n",
      "training loss = 0.3819\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1455 ---------\n",
      "training loss = 0.3819\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1456 ---------\n",
      "training loss = 0.3819\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1457 ---------\n",
      "training loss = 0.3819\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1458 ---------\n",
      "training loss = 0.3819\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1459 ---------\n",
      "training loss = 0.3818\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1460 ---------\n",
      "training loss = 0.3818\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1461 ---------\n",
      "training loss = 0.3818\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1462 ---------\n",
      "training loss = 0.3818\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1463 ---------\n",
      "training loss = 0.3818\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1464 ---------\n",
      "training loss = 0.3818\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5032 / 6000\n",
      "testing accuracy = 0.8387\n",
      "--------- epoch: 1465 ---------\n",
      "training loss = 0.3817\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5032 / 6000\n",
      "testing accuracy = 0.8387\n",
      "--------- epoch: 1466 ---------\n",
      "training loss = 0.3817\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5032 / 6000\n",
      "testing accuracy = 0.8387\n",
      "--------- epoch: 1467 ---------\n",
      "training loss = 0.3817\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1468 ---------\n",
      "training loss = 0.3817\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1469 ---------\n",
      "training loss = 0.3817\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1470 ---------\n",
      "training loss = 0.3817\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1471 ---------\n",
      "training loss = 0.3816\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1472 ---------\n",
      "training loss = 0.3816\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1473 ---------\n",
      "training loss = 0.3816\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1474 ---------\n",
      "training loss = 0.3816\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1475 ---------\n",
      "training loss = 0.3816\n",
      "training accuracy = 0.8460\n",
      "num_train_corrects / train_total_examples = 5076 / 6000\n",
      "num_test_corrects / test_total_examples = 5031 / 6000\n",
      "testing accuracy = 0.8385\n",
      "--------- epoch: 1476 ---------\n",
      "training loss = 0.3816\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5033 / 6000\n",
      "testing accuracy = 0.8388\n",
      "--------- epoch: 1477 ---------\n",
      "training loss = 0.3816\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5034 / 6000\n",
      "testing accuracy = 0.8390\n",
      "--------- epoch: 1478 ---------\n",
      "training loss = 0.3815\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5034 / 6000\n",
      "testing accuracy = 0.8390\n",
      "--------- epoch: 1479 ---------\n",
      "training loss = 0.3815\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5034 / 6000\n",
      "testing accuracy = 0.8390\n",
      "--------- epoch: 1480 ---------\n",
      "training loss = 0.3815\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5034 / 6000\n",
      "testing accuracy = 0.8390\n",
      "--------- epoch: 1481 ---------\n",
      "training loss = 0.3815\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5034 / 6000\n",
      "testing accuracy = 0.8390\n",
      "--------- epoch: 1482 ---------\n",
      "training loss = 0.3815\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5034 / 6000\n",
      "testing accuracy = 0.8390\n",
      "--------- epoch: 1483 ---------\n",
      "training loss = 0.3815\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5034 / 6000\n",
      "testing accuracy = 0.8390\n",
      "--------- epoch: 1484 ---------\n",
      "training loss = 0.3814\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1485 ---------\n",
      "training loss = 0.3814\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1486 ---------\n",
      "training loss = 0.3814\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1487 ---------\n",
      "training loss = 0.3814\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1488 ---------\n",
      "training loss = 0.3814\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1489 ---------\n",
      "training loss = 0.3814\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1490 ---------\n",
      "training loss = 0.3813\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1491 ---------\n",
      "training loss = 0.3813\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1492 ---------\n",
      "training loss = 0.3813\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1493 ---------\n",
      "training loss = 0.3813\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1494 ---------\n",
      "training loss = 0.3813\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1495 ---------\n",
      "training loss = 0.3813\n",
      "training accuracy = 0.8462\n",
      "num_train_corrects / train_total_examples = 5077 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1496 ---------\n",
      "training loss = 0.3812\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1497 ---------\n",
      "training loss = 0.3812\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1498 ---------\n",
      "training loss = 0.3812\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1499 ---------\n",
      "training loss = 0.3812\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1500 ---------\n",
      "training loss = 0.3812\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1501 ---------\n",
      "training loss = 0.3812\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1502 ---------\n",
      "training loss = 0.3812\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1503 ---------\n",
      "training loss = 0.3811\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1504 ---------\n",
      "training loss = 0.3811\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1505 ---------\n",
      "training loss = 0.3811\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1506 ---------\n",
      "training loss = 0.3811\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1507 ---------\n",
      "training loss = 0.3811\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1508 ---------\n",
      "training loss = 0.3811\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1509 ---------\n",
      "training loss = 0.3810\n",
      "training accuracy = 0.8463\n",
      "num_train_corrects / train_total_examples = 5078 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1510 ---------\n",
      "training loss = 0.3810\n",
      "training accuracy = 0.8465\n",
      "num_train_corrects / train_total_examples = 5079 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1511 ---------\n",
      "training loss = 0.3810\n",
      "training accuracy = 0.8465\n",
      "num_train_corrects / train_total_examples = 5079 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1512 ---------\n",
      "training loss = 0.3810\n",
      "training accuracy = 0.8467\n",
      "num_train_corrects / train_total_examples = 5080 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1513 ---------\n",
      "training loss = 0.3810\n",
      "training accuracy = 0.8467\n",
      "num_train_corrects / train_total_examples = 5080 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1514 ---------\n",
      "training loss = 0.3810\n",
      "training accuracy = 0.8467\n",
      "num_train_corrects / train_total_examples = 5080 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1515 ---------\n",
      "training loss = 0.3810\n",
      "training accuracy = 0.8467\n",
      "num_train_corrects / train_total_examples = 5080 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1516 ---------\n",
      "training loss = 0.3809\n",
      "training accuracy = 0.8468\n",
      "num_train_corrects / train_total_examples = 5081 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1517 ---------\n",
      "training loss = 0.3809\n",
      "training accuracy = 0.8468\n",
      "num_train_corrects / train_total_examples = 5081 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1518 ---------\n",
      "training loss = 0.3809\n",
      "training accuracy = 0.8468\n",
      "num_train_corrects / train_total_examples = 5081 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1519 ---------\n",
      "training loss = 0.3809\n",
      "training accuracy = 0.8468\n",
      "num_train_corrects / train_total_examples = 5081 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1520 ---------\n",
      "training loss = 0.3809\n",
      "training accuracy = 0.8468\n",
      "num_train_corrects / train_total_examples = 5081 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1521 ---------\n",
      "training loss = 0.3809\n",
      "training accuracy = 0.8468\n",
      "num_train_corrects / train_total_examples = 5081 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1522 ---------\n",
      "training loss = 0.3808\n",
      "training accuracy = 0.8468\n",
      "num_train_corrects / train_total_examples = 5081 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1523 ---------\n",
      "training loss = 0.3808\n",
      "training accuracy = 0.8468\n",
      "num_train_corrects / train_total_examples = 5081 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1524 ---------\n",
      "training loss = 0.3808\n",
      "training accuracy = 0.8470\n",
      "num_train_corrects / train_total_examples = 5082 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1525 ---------\n",
      "training loss = 0.3808\n",
      "training accuracy = 0.8470\n",
      "num_train_corrects / train_total_examples = 5082 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1526 ---------\n",
      "training loss = 0.3808\n",
      "training accuracy = 0.8470\n",
      "num_train_corrects / train_total_examples = 5082 / 6000\n",
      "num_test_corrects / test_total_examples = 5035 / 6000\n",
      "testing accuracy = 0.8392\n",
      "--------- epoch: 1527 ---------\n",
      "training loss = 0.3808\n",
      "training accuracy = 0.8470\n",
      "num_train_corrects / train_total_examples = 5082 / 6000\n",
      "num_test_corrects / test_total_examples = 5034 / 6000\n",
      "testing accuracy = 0.8390\n",
      "--------- epoch: 1528 ---------\n",
      "training loss = 0.3807\n",
      "training accuracy = 0.8472\n",
      "num_train_corrects / train_total_examples = 5083 / 6000\n",
      "num_test_corrects / test_total_examples = 5034 / 6000\n",
      "testing accuracy = 0.8390\n",
      "--------- epoch: 1529 ---------\n",
      "training loss = 0.3807\n",
      "training accuracy = 0.8472\n",
      "num_train_corrects / train_total_examples = 5083 / 6000\n",
      "num_test_corrects / test_total_examples = 5034 / 6000\n",
      "testing accuracy = 0.8390\n",
      "--------- epoch: 1530 ---------\n",
      "training loss = 0.3807\n",
      "training accuracy = 0.8473\n",
      "num_train_corrects / train_total_examples = 5084 / 6000\n",
      "num_test_corrects / test_total_examples = 5034 / 6000\n",
      "testing accuracy = 0.8390\n",
      "--------- epoch: 1531 ---------\n",
      "training loss = 0.3807\n",
      "training accuracy = 0.8475\n",
      "num_train_corrects / train_total_examples = 5085 / 6000\n",
      "num_test_corrects / test_total_examples = 5034 / 6000\n",
      "testing accuracy = 0.8390\n",
      "--------- epoch: 1532 ---------\n",
      "training loss = 0.3807\n",
      "training accuracy = 0.8475\n",
      "num_train_corrects / train_total_examples = 5085 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1533 ---------\n",
      "training loss = 0.3807\n",
      "training accuracy = 0.8477\n",
      "num_train_corrects / train_total_examples = 5086 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1534 ---------\n",
      "training loss = 0.3807\n",
      "training accuracy = 0.8477\n",
      "num_train_corrects / train_total_examples = 5086 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1535 ---------\n",
      "training loss = 0.3806\n",
      "training accuracy = 0.8478\n",
      "num_train_corrects / train_total_examples = 5087 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1536 ---------\n",
      "training loss = 0.3806\n",
      "training accuracy = 0.8478\n",
      "num_train_corrects / train_total_examples = 5087 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1537 ---------\n",
      "training loss = 0.3806\n",
      "training accuracy = 0.8478\n",
      "num_train_corrects / train_total_examples = 5087 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1538 ---------\n",
      "training loss = 0.3806\n",
      "training accuracy = 0.8478\n",
      "num_train_corrects / train_total_examples = 5087 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1539 ---------\n",
      "training loss = 0.3806\n",
      "training accuracy = 0.8478\n",
      "num_train_corrects / train_total_examples = 5087 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1540 ---------\n",
      "training loss = 0.3806\n",
      "training accuracy = 0.8478\n",
      "num_train_corrects / train_total_examples = 5087 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1541 ---------\n",
      "training loss = 0.3805\n",
      "training accuracy = 0.8480\n",
      "num_train_corrects / train_total_examples = 5088 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1542 ---------\n",
      "training loss = 0.3805\n",
      "training accuracy = 0.8483\n",
      "num_train_corrects / train_total_examples = 5090 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1543 ---------\n",
      "training loss = 0.3805\n",
      "training accuracy = 0.8483\n",
      "num_train_corrects / train_total_examples = 5090 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1544 ---------\n",
      "training loss = 0.3805\n",
      "training accuracy = 0.8483\n",
      "num_train_corrects / train_total_examples = 5090 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1545 ---------\n",
      "training loss = 0.3805\n",
      "training accuracy = 0.8483\n",
      "num_train_corrects / train_total_examples = 5090 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1546 ---------\n",
      "training loss = 0.3805\n",
      "training accuracy = 0.8483\n",
      "num_train_corrects / train_total_examples = 5090 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1547 ---------\n",
      "training loss = 0.3805\n",
      "training accuracy = 0.8485\n",
      "num_train_corrects / train_total_examples = 5091 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1548 ---------\n",
      "training loss = 0.3804\n",
      "training accuracy = 0.8485\n",
      "num_train_corrects / train_total_examples = 5091 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1549 ---------\n",
      "training loss = 0.3804\n",
      "training accuracy = 0.8485\n",
      "num_train_corrects / train_total_examples = 5091 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1550 ---------\n",
      "training loss = 0.3804\n",
      "training accuracy = 0.8485\n",
      "num_train_corrects / train_total_examples = 5091 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1551 ---------\n",
      "training loss = 0.3804\n",
      "training accuracy = 0.8485\n",
      "num_train_corrects / train_total_examples = 5091 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1552 ---------\n",
      "training loss = 0.3804\n",
      "training accuracy = 0.8485\n",
      "num_train_corrects / train_total_examples = 5091 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1553 ---------\n",
      "training loss = 0.3804\n",
      "training accuracy = 0.8487\n",
      "num_train_corrects / train_total_examples = 5092 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1554 ---------\n",
      "training loss = 0.3804\n",
      "training accuracy = 0.8487\n",
      "num_train_corrects / train_total_examples = 5092 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1555 ---------\n",
      "training loss = 0.3803\n",
      "training accuracy = 0.8488\n",
      "num_train_corrects / train_total_examples = 5093 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1556 ---------\n",
      "training loss = 0.3803\n",
      "training accuracy = 0.8488\n",
      "num_train_corrects / train_total_examples = 5093 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1557 ---------\n",
      "training loss = 0.3803\n",
      "training accuracy = 0.8488\n",
      "num_train_corrects / train_total_examples = 5093 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1558 ---------\n",
      "training loss = 0.3803\n",
      "training accuracy = 0.8488\n",
      "num_train_corrects / train_total_examples = 5093 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1559 ---------\n",
      "training loss = 0.3803\n",
      "training accuracy = 0.8488\n",
      "num_train_corrects / train_total_examples = 5093 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1560 ---------\n",
      "training loss = 0.3803\n",
      "training accuracy = 0.8488\n",
      "num_train_corrects / train_total_examples = 5093 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1561 ---------\n",
      "training loss = 0.3802\n",
      "training accuracy = 0.8488\n",
      "num_train_corrects / train_total_examples = 5093 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1562 ---------\n",
      "training loss = 0.3802\n",
      "training accuracy = 0.8488\n",
      "num_train_corrects / train_total_examples = 5093 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1563 ---------\n",
      "training loss = 0.3802\n",
      "training accuracy = 0.8488\n",
      "num_train_corrects / train_total_examples = 5093 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1564 ---------\n",
      "training loss = 0.3802\n",
      "training accuracy = 0.8488\n",
      "num_train_corrects / train_total_examples = 5093 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1565 ---------\n",
      "training loss = 0.3802\n",
      "training accuracy = 0.8488\n",
      "num_train_corrects / train_total_examples = 5093 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1566 ---------\n",
      "training loss = 0.3802\n",
      "training accuracy = 0.8490\n",
      "num_train_corrects / train_total_examples = 5094 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1567 ---------\n",
      "training loss = 0.3802\n",
      "training accuracy = 0.8490\n",
      "num_train_corrects / train_total_examples = 5094 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1568 ---------\n",
      "training loss = 0.3801\n",
      "training accuracy = 0.8490\n",
      "num_train_corrects / train_total_examples = 5094 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1569 ---------\n",
      "training loss = 0.3801\n",
      "training accuracy = 0.8492\n",
      "num_train_corrects / train_total_examples = 5095 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1570 ---------\n",
      "training loss = 0.3801\n",
      "training accuracy = 0.8492\n",
      "num_train_corrects / train_total_examples = 5095 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1571 ---------\n",
      "training loss = 0.3801\n",
      "training accuracy = 0.8492\n",
      "num_train_corrects / train_total_examples = 5095 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1572 ---------\n",
      "training loss = 0.3801\n",
      "training accuracy = 0.8492\n",
      "num_train_corrects / train_total_examples = 5095 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1573 ---------\n",
      "training loss = 0.3801\n",
      "training accuracy = 0.8492\n",
      "num_train_corrects / train_total_examples = 5095 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1574 ---------\n",
      "training loss = 0.3801\n",
      "training accuracy = 0.8492\n",
      "num_train_corrects / train_total_examples = 5095 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1575 ---------\n",
      "training loss = 0.3800\n",
      "training accuracy = 0.8492\n",
      "num_train_corrects / train_total_examples = 5095 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1576 ---------\n",
      "training loss = 0.3800\n",
      "training accuracy = 0.8492\n",
      "num_train_corrects / train_total_examples = 5095 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1577 ---------\n",
      "training loss = 0.3800\n",
      "training accuracy = 0.8492\n",
      "num_train_corrects / train_total_examples = 5095 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1578 ---------\n",
      "training loss = 0.3800\n",
      "training accuracy = 0.8492\n",
      "num_train_corrects / train_total_examples = 5095 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1579 ---------\n",
      "training loss = 0.3800\n",
      "training accuracy = 0.8492\n",
      "num_train_corrects / train_total_examples = 5095 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1580 ---------\n",
      "training loss = 0.3800\n",
      "training accuracy = 0.8492\n",
      "num_train_corrects / train_total_examples = 5095 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1581 ---------\n",
      "training loss = 0.3799\n",
      "training accuracy = 0.8493\n",
      "num_train_corrects / train_total_examples = 5096 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1582 ---------\n",
      "training loss = 0.3799\n",
      "training accuracy = 0.8493\n",
      "num_train_corrects / train_total_examples = 5096 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1583 ---------\n",
      "training loss = 0.3799\n",
      "training accuracy = 0.8493\n",
      "num_train_corrects / train_total_examples = 5096 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1584 ---------\n",
      "training loss = 0.3799\n",
      "training accuracy = 0.8493\n",
      "num_train_corrects / train_total_examples = 5096 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1585 ---------\n",
      "training loss = 0.3799\n",
      "training accuracy = 0.8493\n",
      "num_train_corrects / train_total_examples = 5096 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1586 ---------\n",
      "training loss = 0.3799\n",
      "training accuracy = 0.8493\n",
      "num_train_corrects / train_total_examples = 5096 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1587 ---------\n",
      "training loss = 0.3799\n",
      "training accuracy = 0.8493\n",
      "num_train_corrects / train_total_examples = 5096 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1588 ---------\n",
      "training loss = 0.3798\n",
      "training accuracy = 0.8493\n",
      "num_train_corrects / train_total_examples = 5096 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1589 ---------\n",
      "training loss = 0.3798\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1590 ---------\n",
      "training loss = 0.3798\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1591 ---------\n",
      "training loss = 0.3798\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1592 ---------\n",
      "training loss = 0.3798\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1593 ---------\n",
      "training loss = 0.3798\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1594 ---------\n",
      "training loss = 0.3798\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1595 ---------\n",
      "training loss = 0.3797\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1596 ---------\n",
      "training loss = 0.3797\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1597 ---------\n",
      "training loss = 0.3797\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1598 ---------\n",
      "training loss = 0.3797\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1599 ---------\n",
      "training loss = 0.3797\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1600 ---------\n",
      "training loss = 0.3797\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1601 ---------\n",
      "training loss = 0.3797\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1602 ---------\n",
      "training loss = 0.3796\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1603 ---------\n",
      "training loss = 0.3796\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1604 ---------\n",
      "training loss = 0.3796\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1605 ---------\n",
      "training loss = 0.3796\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1606 ---------\n",
      "training loss = 0.3796\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1607 ---------\n",
      "training loss = 0.3796\n",
      "training accuracy = 0.8497\n",
      "num_train_corrects / train_total_examples = 5098 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1608 ---------\n",
      "training loss = 0.3796\n",
      "training accuracy = 0.8497\n",
      "num_train_corrects / train_total_examples = 5098 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1609 ---------\n",
      "training loss = 0.3795\n",
      "training accuracy = 0.8497\n",
      "num_train_corrects / train_total_examples = 5098 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1610 ---------\n",
      "training loss = 0.3795\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1611 ---------\n",
      "training loss = 0.3795\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1612 ---------\n",
      "training loss = 0.3795\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1613 ---------\n",
      "training loss = 0.3795\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1614 ---------\n",
      "training loss = 0.3795\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5036 / 6000\n",
      "testing accuracy = 0.8393\n",
      "--------- epoch: 1615 ---------\n",
      "training loss = 0.3794\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1616 ---------\n",
      "training loss = 0.3794\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1617 ---------\n",
      "training loss = 0.3794\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1618 ---------\n",
      "training loss = 0.3794\n",
      "training accuracy = 0.8495\n",
      "num_train_corrects / train_total_examples = 5097 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1619 ---------\n",
      "training loss = 0.3794\n",
      "training accuracy = 0.8497\n",
      "num_train_corrects / train_total_examples = 5098 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1620 ---------\n",
      "training loss = 0.3794\n",
      "training accuracy = 0.8497\n",
      "num_train_corrects / train_total_examples = 5098 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1621 ---------\n",
      "training loss = 0.3794\n",
      "training accuracy = 0.8497\n",
      "num_train_corrects / train_total_examples = 5098 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1622 ---------\n",
      "training loss = 0.3793\n",
      "training accuracy = 0.8497\n",
      "num_train_corrects / train_total_examples = 5098 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1623 ---------\n",
      "training loss = 0.3793\n",
      "training accuracy = 0.8497\n",
      "num_train_corrects / train_total_examples = 5098 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1624 ---------\n",
      "training loss = 0.3793\n",
      "training accuracy = 0.8497\n",
      "num_train_corrects / train_total_examples = 5098 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1625 ---------\n",
      "training loss = 0.3793\n",
      "training accuracy = 0.8497\n",
      "num_train_corrects / train_total_examples = 5098 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1626 ---------\n",
      "training loss = 0.3793\n",
      "training accuracy = 0.8497\n",
      "num_train_corrects / train_total_examples = 5098 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1627 ---------\n",
      "training loss = 0.3793\n",
      "training accuracy = 0.8497\n",
      "num_train_corrects / train_total_examples = 5098 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1628 ---------\n",
      "training loss = 0.3793\n",
      "training accuracy = 0.8498\n",
      "num_train_corrects / train_total_examples = 5099 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1629 ---------\n",
      "training loss = 0.3792\n",
      "training accuracy = 0.8498\n",
      "num_train_corrects / train_total_examples = 5099 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1630 ---------\n",
      "training loss = 0.3792\n",
      "training accuracy = 0.8498\n",
      "num_train_corrects / train_total_examples = 5099 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1631 ---------\n",
      "training loss = 0.3792\n",
      "training accuracy = 0.8498\n",
      "num_train_corrects / train_total_examples = 5099 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1632 ---------\n",
      "training loss = 0.3792\n",
      "training accuracy = 0.8498\n",
      "num_train_corrects / train_total_examples = 5099 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1633 ---------\n",
      "training loss = 0.3792\n",
      "training accuracy = 0.8498\n",
      "num_train_corrects / train_total_examples = 5099 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1634 ---------\n",
      "training loss = 0.3792\n",
      "training accuracy = 0.8498\n",
      "num_train_corrects / train_total_examples = 5099 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1635 ---------\n",
      "training loss = 0.3792\n",
      "training accuracy = 0.8498\n",
      "num_train_corrects / train_total_examples = 5099 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1636 ---------\n",
      "training loss = 0.3791\n",
      "training accuracy = 0.8498\n",
      "num_train_corrects / train_total_examples = 5099 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1637 ---------\n",
      "training loss = 0.3791\n",
      "training accuracy = 0.8498\n",
      "num_train_corrects / train_total_examples = 5099 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1638 ---------\n",
      "training loss = 0.3791\n",
      "training accuracy = 0.8500\n",
      "num_train_corrects / train_total_examples = 5100 / 6000\n",
      "num_test_corrects / test_total_examples = 5037 / 6000\n",
      "testing accuracy = 0.8395\n",
      "--------- epoch: 1639 ---------\n",
      "training loss = 0.3791\n",
      "training accuracy = 0.8500\n",
      "num_train_corrects / train_total_examples = 5100 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1640 ---------\n",
      "training loss = 0.3791\n",
      "training accuracy = 0.8500\n",
      "num_train_corrects / train_total_examples = 5100 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1641 ---------\n",
      "training loss = 0.3791\n",
      "training accuracy = 0.8500\n",
      "num_train_corrects / train_total_examples = 5100 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1642 ---------\n",
      "training loss = 0.3791\n",
      "training accuracy = 0.8500\n",
      "num_train_corrects / train_total_examples = 5100 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1643 ---------\n",
      "training loss = 0.3790\n",
      "training accuracy = 0.8502\n",
      "num_train_corrects / train_total_examples = 5101 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1644 ---------\n",
      "training loss = 0.3790\n",
      "training accuracy = 0.8502\n",
      "num_train_corrects / train_total_examples = 5101 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1645 ---------\n",
      "training loss = 0.3790\n",
      "training accuracy = 0.8502\n",
      "num_train_corrects / train_total_examples = 5101 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1646 ---------\n",
      "training loss = 0.3790\n",
      "training accuracy = 0.8502\n",
      "num_train_corrects / train_total_examples = 5101 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1647 ---------\n",
      "training loss = 0.3790\n",
      "training accuracy = 0.8502\n",
      "num_train_corrects / train_total_examples = 5101 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1648 ---------\n",
      "training loss = 0.3790\n",
      "training accuracy = 0.8502\n",
      "num_train_corrects / train_total_examples = 5101 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1649 ---------\n",
      "training loss = 0.3790\n",
      "training accuracy = 0.8502\n",
      "num_train_corrects / train_total_examples = 5101 / 6000\n",
      "num_test_corrects / test_total_examples = 5038 / 6000\n",
      "testing accuracy = 0.8397\n",
      "--------- epoch: 1650 ---------\n",
      "training loss = 0.3789\n",
      "training accuracy = 0.8502\n",
      "num_train_corrects / train_total_examples = 5101 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1651 ---------\n",
      "training loss = 0.3789\n",
      "training accuracy = 0.8502\n",
      "num_train_corrects / train_total_examples = 5101 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1652 ---------\n",
      "training loss = 0.3789\n",
      "training accuracy = 0.8502\n",
      "num_train_corrects / train_total_examples = 5101 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1653 ---------\n",
      "training loss = 0.3789\n",
      "training accuracy = 0.8503\n",
      "num_train_corrects / train_total_examples = 5102 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1654 ---------\n",
      "training loss = 0.3789\n",
      "training accuracy = 0.8503\n",
      "num_train_corrects / train_total_examples = 5102 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1655 ---------\n",
      "training loss = 0.3789\n",
      "training accuracy = 0.8503\n",
      "num_train_corrects / train_total_examples = 5102 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1656 ---------\n",
      "training loss = 0.3789\n",
      "training accuracy = 0.8503\n",
      "num_train_corrects / train_total_examples = 5102 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1657 ---------\n",
      "training loss = 0.3789\n",
      "training accuracy = 0.8503\n",
      "num_train_corrects / train_total_examples = 5102 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1658 ---------\n",
      "training loss = 0.3788\n",
      "training accuracy = 0.8503\n",
      "num_train_corrects / train_total_examples = 5102 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1659 ---------\n",
      "training loss = 0.3788\n",
      "training accuracy = 0.8503\n",
      "num_train_corrects / train_total_examples = 5102 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1660 ---------\n",
      "training loss = 0.3788\n",
      "training accuracy = 0.8503\n",
      "num_train_corrects / train_total_examples = 5102 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1661 ---------\n",
      "training loss = 0.3788\n",
      "training accuracy = 0.8503\n",
      "num_train_corrects / train_total_examples = 5102 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1662 ---------\n",
      "training loss = 0.3788\n",
      "training accuracy = 0.8503\n",
      "num_train_corrects / train_total_examples = 5102 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1663 ---------\n",
      "training loss = 0.3788\n",
      "training accuracy = 0.8503\n",
      "num_train_corrects / train_total_examples = 5102 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1664 ---------\n",
      "training loss = 0.3788\n",
      "training accuracy = 0.8503\n",
      "num_train_corrects / train_total_examples = 5102 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1665 ---------\n",
      "training loss = 0.3787\n",
      "training accuracy = 0.8503\n",
      "num_train_corrects / train_total_examples = 5102 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1666 ---------\n",
      "training loss = 0.3787\n",
      "training accuracy = 0.8505\n",
      "num_train_corrects / train_total_examples = 5103 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1667 ---------\n",
      "training loss = 0.3787\n",
      "training accuracy = 0.8505\n",
      "num_train_corrects / train_total_examples = 5103 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1668 ---------\n",
      "training loss = 0.3787\n",
      "training accuracy = 0.8507\n",
      "num_train_corrects / train_total_examples = 5104 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1669 ---------\n",
      "training loss = 0.3787\n",
      "training accuracy = 0.8508\n",
      "num_train_corrects / train_total_examples = 5105 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1670 ---------\n",
      "training loss = 0.3787\n",
      "training accuracy = 0.8508\n",
      "num_train_corrects / train_total_examples = 5105 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1671 ---------\n",
      "training loss = 0.3787\n",
      "training accuracy = 0.8508\n",
      "num_train_corrects / train_total_examples = 5105 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1672 ---------\n",
      "training loss = 0.3786\n",
      "training accuracy = 0.8510\n",
      "num_train_corrects / train_total_examples = 5106 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1673 ---------\n",
      "training loss = 0.3786\n",
      "training accuracy = 0.8510\n",
      "num_train_corrects / train_total_examples = 5106 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1674 ---------\n",
      "training loss = 0.3786\n",
      "training accuracy = 0.8510\n",
      "num_train_corrects / train_total_examples = 5106 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1675 ---------\n",
      "training loss = 0.3786\n",
      "training accuracy = 0.8508\n",
      "num_train_corrects / train_total_examples = 5105 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1676 ---------\n",
      "training loss = 0.3786\n",
      "training accuracy = 0.8508\n",
      "num_train_corrects / train_total_examples = 5105 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1677 ---------\n",
      "training loss = 0.3786\n",
      "training accuracy = 0.8508\n",
      "num_train_corrects / train_total_examples = 5105 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1678 ---------\n",
      "training loss = 0.3786\n",
      "training accuracy = 0.8508\n",
      "num_train_corrects / train_total_examples = 5105 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1679 ---------\n",
      "training loss = 0.3785\n",
      "training accuracy = 0.8508\n",
      "num_train_corrects / train_total_examples = 5105 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1680 ---------\n",
      "training loss = 0.3785\n",
      "training accuracy = 0.8508\n",
      "num_train_corrects / train_total_examples = 5105 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1681 ---------\n",
      "training loss = 0.3785\n",
      "training accuracy = 0.8508\n",
      "num_train_corrects / train_total_examples = 5105 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1682 ---------\n",
      "training loss = 0.3785\n",
      "training accuracy = 0.8508\n",
      "num_train_corrects / train_total_examples = 5105 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1683 ---------\n",
      "training loss = 0.3785\n",
      "training accuracy = 0.8508\n",
      "num_train_corrects / train_total_examples = 5105 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1684 ---------\n",
      "training loss = 0.3785\n",
      "training accuracy = 0.8508\n",
      "num_train_corrects / train_total_examples = 5105 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1685 ---------\n",
      "training loss = 0.3785\n",
      "training accuracy = 0.8510\n",
      "num_train_corrects / train_total_examples = 5106 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1686 ---------\n",
      "training loss = 0.3784\n",
      "training accuracy = 0.8508\n",
      "num_train_corrects / train_total_examples = 5105 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1687 ---------\n",
      "training loss = 0.3784\n",
      "training accuracy = 0.8512\n",
      "num_train_corrects / train_total_examples = 5107 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1688 ---------\n",
      "training loss = 0.3784\n",
      "training accuracy = 0.8512\n",
      "num_train_corrects / train_total_examples = 5107 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1689 ---------\n",
      "training loss = 0.3784\n",
      "training accuracy = 0.8512\n",
      "num_train_corrects / train_total_examples = 5107 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1690 ---------\n",
      "training loss = 0.3784\n",
      "training accuracy = 0.8512\n",
      "num_train_corrects / train_total_examples = 5107 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1691 ---------\n",
      "training loss = 0.3784\n",
      "training accuracy = 0.8513\n",
      "num_train_corrects / train_total_examples = 5108 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1692 ---------\n",
      "training loss = 0.3784\n",
      "training accuracy = 0.8513\n",
      "num_train_corrects / train_total_examples = 5108 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1693 ---------\n",
      "training loss = 0.3784\n",
      "training accuracy = 0.8513\n",
      "num_train_corrects / train_total_examples = 5108 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1694 ---------\n",
      "training loss = 0.3783\n",
      "training accuracy = 0.8513\n",
      "num_train_corrects / train_total_examples = 5108 / 6000\n",
      "num_test_corrects / test_total_examples = 5042 / 6000\n",
      "testing accuracy = 0.8403\n",
      "--------- epoch: 1695 ---------\n",
      "training loss = 0.3783\n",
      "training accuracy = 0.8513\n",
      "num_train_corrects / train_total_examples = 5108 / 6000\n",
      "num_test_corrects / test_total_examples = 5042 / 6000\n",
      "testing accuracy = 0.8403\n",
      "--------- epoch: 1696 ---------\n",
      "training loss = 0.3783\n",
      "training accuracy = 0.8515\n",
      "num_train_corrects / train_total_examples = 5109 / 6000\n",
      "num_test_corrects / test_total_examples = 5042 / 6000\n",
      "testing accuracy = 0.8403\n",
      "--------- epoch: 1697 ---------\n",
      "training loss = 0.3783\n",
      "training accuracy = 0.8515\n",
      "num_train_corrects / train_total_examples = 5109 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1698 ---------\n",
      "training loss = 0.3783\n",
      "training accuracy = 0.8515\n",
      "num_train_corrects / train_total_examples = 5109 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1699 ---------\n",
      "training loss = 0.3783\n",
      "training accuracy = 0.8515\n",
      "num_train_corrects / train_total_examples = 5109 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1700 ---------\n",
      "training loss = 0.3783\n",
      "training accuracy = 0.8515\n",
      "num_train_corrects / train_total_examples = 5109 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1701 ---------\n",
      "training loss = 0.3782\n",
      "training accuracy = 0.8515\n",
      "num_train_corrects / train_total_examples = 5109 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1702 ---------\n",
      "training loss = 0.3782\n",
      "training accuracy = 0.8515\n",
      "num_train_corrects / train_total_examples = 5109 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1703 ---------\n",
      "training loss = 0.3782\n",
      "training accuracy = 0.8515\n",
      "num_train_corrects / train_total_examples = 5109 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1704 ---------\n",
      "training loss = 0.3782\n",
      "training accuracy = 0.8513\n",
      "num_train_corrects / train_total_examples = 5108 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1705 ---------\n",
      "training loss = 0.3782\n",
      "training accuracy = 0.8513\n",
      "num_train_corrects / train_total_examples = 5108 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1706 ---------\n",
      "training loss = 0.3782\n",
      "training accuracy = 0.8513\n",
      "num_train_corrects / train_total_examples = 5108 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1707 ---------\n",
      "training loss = 0.3782\n",
      "training accuracy = 0.8513\n",
      "num_train_corrects / train_total_examples = 5108 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1708 ---------\n",
      "training loss = 0.3781\n",
      "training accuracy = 0.8513\n",
      "num_train_corrects / train_total_examples = 5108 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1709 ---------\n",
      "training loss = 0.3781\n",
      "training accuracy = 0.8515\n",
      "num_train_corrects / train_total_examples = 5109 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1710 ---------\n",
      "training loss = 0.3781\n",
      "training accuracy = 0.8515\n",
      "num_train_corrects / train_total_examples = 5109 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1711 ---------\n",
      "training loss = 0.3781\n",
      "training accuracy = 0.8515\n",
      "num_train_corrects / train_total_examples = 5109 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1712 ---------\n",
      "training loss = 0.3781\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1713 ---------\n",
      "training loss = 0.3781\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1714 ---------\n",
      "training loss = 0.3781\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1715 ---------\n",
      "training loss = 0.3781\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1716 ---------\n",
      "training loss = 0.3780\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1717 ---------\n",
      "training loss = 0.3780\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1718 ---------\n",
      "training loss = 0.3780\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1719 ---------\n",
      "training loss = 0.3780\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1720 ---------\n",
      "training loss = 0.3780\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1721 ---------\n",
      "training loss = 0.3780\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1722 ---------\n",
      "training loss = 0.3780\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1723 ---------\n",
      "training loss = 0.3779\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1724 ---------\n",
      "training loss = 0.3779\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1725 ---------\n",
      "training loss = 0.3779\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1726 ---------\n",
      "training loss = 0.3779\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1727 ---------\n",
      "training loss = 0.3779\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1728 ---------\n",
      "training loss = 0.3779\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1729 ---------\n",
      "training loss = 0.3779\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1730 ---------\n",
      "training loss = 0.3779\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1731 ---------\n",
      "training loss = 0.3778\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1732 ---------\n",
      "training loss = 0.3778\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1733 ---------\n",
      "training loss = 0.3778\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1734 ---------\n",
      "training loss = 0.3778\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1735 ---------\n",
      "training loss = 0.3778\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1736 ---------\n",
      "training loss = 0.3778\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1737 ---------\n",
      "training loss = 0.3778\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1738 ---------\n",
      "training loss = 0.3777\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1739 ---------\n",
      "training loss = 0.3777\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1740 ---------\n",
      "training loss = 0.3777\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1741 ---------\n",
      "training loss = 0.3777\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5040 / 6000\n",
      "testing accuracy = 0.8400\n",
      "--------- epoch: 1742 ---------\n",
      "training loss = 0.3777\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1743 ---------\n",
      "training loss = 0.3777\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1744 ---------\n",
      "training loss = 0.3777\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1745 ---------\n",
      "training loss = 0.3777\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1746 ---------\n",
      "training loss = 0.3776\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1747 ---------\n",
      "training loss = 0.3776\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1748 ---------\n",
      "training loss = 0.3776\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1749 ---------\n",
      "training loss = 0.3776\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1750 ---------\n",
      "training loss = 0.3776\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5039 / 6000\n",
      "testing accuracy = 0.8398\n",
      "--------- epoch: 1751 ---------\n",
      "training loss = 0.3776\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1752 ---------\n",
      "training loss = 0.3776\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1753 ---------\n",
      "training loss = 0.3775\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1754 ---------\n",
      "training loss = 0.3775\n",
      "training accuracy = 0.8517\n",
      "num_train_corrects / train_total_examples = 5110 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1755 ---------\n",
      "training loss = 0.3775\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1756 ---------\n",
      "training loss = 0.3775\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1757 ---------\n",
      "training loss = 0.3775\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1758 ---------\n",
      "training loss = 0.3775\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1759 ---------\n",
      "training loss = 0.3775\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1760 ---------\n",
      "training loss = 0.3775\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1761 ---------\n",
      "training loss = 0.3774\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1762 ---------\n",
      "training loss = 0.3774\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5041 / 6000\n",
      "testing accuracy = 0.8402\n",
      "--------- epoch: 1763 ---------\n",
      "training loss = 0.3774\n",
      "training accuracy = 0.8518\n",
      "num_train_corrects / train_total_examples = 5111 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1764 ---------\n",
      "training loss = 0.3774\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1765 ---------\n",
      "training loss = 0.3774\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1766 ---------\n",
      "training loss = 0.3774\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1767 ---------\n",
      "training loss = 0.3774\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1768 ---------\n",
      "training loss = 0.3774\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1769 ---------\n",
      "training loss = 0.3773\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1770 ---------\n",
      "training loss = 0.3773\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1771 ---------\n",
      "training loss = 0.3773\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1772 ---------\n",
      "training loss = 0.3773\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1773 ---------\n",
      "training loss = 0.3773\n",
      "training accuracy = 0.8522\n",
      "num_train_corrects / train_total_examples = 5113 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1774 ---------\n",
      "training loss = 0.3773\n",
      "training accuracy = 0.8522\n",
      "num_train_corrects / train_total_examples = 5113 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1775 ---------\n",
      "training loss = 0.3773\n",
      "training accuracy = 0.8522\n",
      "num_train_corrects / train_total_examples = 5113 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1776 ---------\n",
      "training loss = 0.3772\n",
      "training accuracy = 0.8522\n",
      "num_train_corrects / train_total_examples = 5113 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1777 ---------\n",
      "training loss = 0.3772\n",
      "training accuracy = 0.8522\n",
      "num_train_corrects / train_total_examples = 5113 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1778 ---------\n",
      "training loss = 0.3772\n",
      "training accuracy = 0.8522\n",
      "num_train_corrects / train_total_examples = 5113 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1779 ---------\n",
      "training loss = 0.3772\n",
      "training accuracy = 0.8522\n",
      "num_train_corrects / train_total_examples = 5113 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1780 ---------\n",
      "training loss = 0.3772\n",
      "training accuracy = 0.8522\n",
      "num_train_corrects / train_total_examples = 5113 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1781 ---------\n",
      "training loss = 0.3772\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1782 ---------\n",
      "training loss = 0.3772\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1783 ---------\n",
      "training loss = 0.3772\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1784 ---------\n",
      "training loss = 0.3771\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1785 ---------\n",
      "training loss = 0.3771\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1786 ---------\n",
      "training loss = 0.3771\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1787 ---------\n",
      "training loss = 0.3771\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1788 ---------\n",
      "training loss = 0.3771\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1789 ---------\n",
      "training loss = 0.3771\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1790 ---------\n",
      "training loss = 0.3771\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1791 ---------\n",
      "training loss = 0.3771\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1792 ---------\n",
      "training loss = 0.3770\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1793 ---------\n",
      "training loss = 0.3770\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1794 ---------\n",
      "training loss = 0.3770\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1795 ---------\n",
      "training loss = 0.3770\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1796 ---------\n",
      "training loss = 0.3770\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1797 ---------\n",
      "training loss = 0.3770\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1798 ---------\n",
      "training loss = 0.3770\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1799 ---------\n",
      "training loss = 0.3770\n",
      "training accuracy = 0.8520\n",
      "num_train_corrects / train_total_examples = 5112 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1800 ---------\n",
      "training loss = 0.3769\n",
      "training accuracy = 0.8522\n",
      "num_train_corrects / train_total_examples = 5113 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1801 ---------\n",
      "training loss = 0.3769\n",
      "training accuracy = 0.8522\n",
      "num_train_corrects / train_total_examples = 5113 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1802 ---------\n",
      "training loss = 0.3769\n",
      "training accuracy = 0.8522\n",
      "num_train_corrects / train_total_examples = 5113 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1803 ---------\n",
      "training loss = 0.3769\n",
      "training accuracy = 0.8522\n",
      "num_train_corrects / train_total_examples = 5113 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1804 ---------\n",
      "training loss = 0.3769\n",
      "training accuracy = 0.8522\n",
      "num_train_corrects / train_total_examples = 5113 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1805 ---------\n",
      "training loss = 0.3769\n",
      "training accuracy = 0.8522\n",
      "num_train_corrects / train_total_examples = 5113 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1806 ---------\n",
      "training loss = 0.3769\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1807 ---------\n",
      "training loss = 0.3769\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1808 ---------\n",
      "training loss = 0.3768\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1809 ---------\n",
      "training loss = 0.3768\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1810 ---------\n",
      "training loss = 0.3768\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1811 ---------\n",
      "training loss = 0.3768\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1812 ---------\n",
      "training loss = 0.3768\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1813 ---------\n",
      "training loss = 0.3768\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1814 ---------\n",
      "training loss = 0.3768\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1815 ---------\n",
      "training loss = 0.3768\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1816 ---------\n",
      "training loss = 0.3767\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1817 ---------\n",
      "training loss = 0.3767\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1818 ---------\n",
      "training loss = 0.3767\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1819 ---------\n",
      "training loss = 0.3767\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1820 ---------\n",
      "training loss = 0.3767\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1821 ---------\n",
      "training loss = 0.3767\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1822 ---------\n",
      "training loss = 0.3767\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1823 ---------\n",
      "training loss = 0.3767\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1824 ---------\n",
      "training loss = 0.3766\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1825 ---------\n",
      "training loss = 0.3766\n",
      "training accuracy = 0.8523\n",
      "num_train_corrects / train_total_examples = 5114 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1826 ---------\n",
      "training loss = 0.3766\n",
      "training accuracy = 0.8525\n",
      "num_train_corrects / train_total_examples = 5115 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1827 ---------\n",
      "training loss = 0.3766\n",
      "training accuracy = 0.8525\n",
      "num_train_corrects / train_total_examples = 5115 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1828 ---------\n",
      "training loss = 0.3766\n",
      "training accuracy = 0.8525\n",
      "num_train_corrects / train_total_examples = 5115 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1829 ---------\n",
      "training loss = 0.3766\n",
      "training accuracy = 0.8525\n",
      "num_train_corrects / train_total_examples = 5115 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1830 ---------\n",
      "training loss = 0.3766\n",
      "training accuracy = 0.8525\n",
      "num_train_corrects / train_total_examples = 5115 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1831 ---------\n",
      "training loss = 0.3766\n",
      "training accuracy = 0.8525\n",
      "num_train_corrects / train_total_examples = 5115 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1832 ---------\n",
      "training loss = 0.3765\n",
      "training accuracy = 0.8525\n",
      "num_train_corrects / train_total_examples = 5115 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1833 ---------\n",
      "training loss = 0.3765\n",
      "training accuracy = 0.8525\n",
      "num_train_corrects / train_total_examples = 5115 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1834 ---------\n",
      "training loss = 0.3765\n",
      "training accuracy = 0.8525\n",
      "num_train_corrects / train_total_examples = 5115 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1835 ---------\n",
      "training loss = 0.3765\n",
      "training accuracy = 0.8527\n",
      "num_train_corrects / train_total_examples = 5116 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1836 ---------\n",
      "training loss = 0.3765\n",
      "training accuracy = 0.8527\n",
      "num_train_corrects / train_total_examples = 5116 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1837 ---------\n",
      "training loss = 0.3765\n",
      "training accuracy = 0.8527\n",
      "num_train_corrects / train_total_examples = 5116 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1838 ---------\n",
      "training loss = 0.3765\n",
      "training accuracy = 0.8527\n",
      "num_train_corrects / train_total_examples = 5116 / 6000\n",
      "num_test_corrects / test_total_examples = 5043 / 6000\n",
      "testing accuracy = 0.8405\n",
      "--------- epoch: 1839 ---------\n",
      "training loss = 0.3765\n",
      "training accuracy = 0.8527\n",
      "num_train_corrects / train_total_examples = 5116 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1840 ---------\n",
      "training loss = 0.3764\n",
      "training accuracy = 0.8527\n",
      "num_train_corrects / train_total_examples = 5116 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1841 ---------\n",
      "training loss = 0.3764\n",
      "training accuracy = 0.8527\n",
      "num_train_corrects / train_total_examples = 5116 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1842 ---------\n",
      "training loss = 0.3764\n",
      "training accuracy = 0.8527\n",
      "num_train_corrects / train_total_examples = 5116 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1843 ---------\n",
      "training loss = 0.3764\n",
      "training accuracy = 0.8527\n",
      "num_train_corrects / train_total_examples = 5116 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1844 ---------\n",
      "training loss = 0.3764\n",
      "training accuracy = 0.8527\n",
      "num_train_corrects / train_total_examples = 5116 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1845 ---------\n",
      "training loss = 0.3764\n",
      "training accuracy = 0.8527\n",
      "num_train_corrects / train_total_examples = 5116 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1846 ---------\n",
      "training loss = 0.3764\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1847 ---------\n",
      "training loss = 0.3764\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1848 ---------\n",
      "training loss = 0.3763\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1849 ---------\n",
      "training loss = 0.3763\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1850 ---------\n",
      "training loss = 0.3763\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1851 ---------\n",
      "training loss = 0.3763\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1852 ---------\n",
      "training loss = 0.3763\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1853 ---------\n",
      "training loss = 0.3763\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1854 ---------\n",
      "training loss = 0.3763\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1855 ---------\n",
      "training loss = 0.3763\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1856 ---------\n",
      "training loss = 0.3762\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1857 ---------\n",
      "training loss = 0.3762\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1858 ---------\n",
      "training loss = 0.3762\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1859 ---------\n",
      "training loss = 0.3762\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5044 / 6000\n",
      "testing accuracy = 0.8407\n",
      "--------- epoch: 1860 ---------\n",
      "training loss = 0.3762\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1861 ---------\n",
      "training loss = 0.3762\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1862 ---------\n",
      "training loss = 0.3762\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1863 ---------\n",
      "training loss = 0.3762\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1864 ---------\n",
      "training loss = 0.3761\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1865 ---------\n",
      "training loss = 0.3761\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1866 ---------\n",
      "training loss = 0.3761\n",
      "training accuracy = 0.8528\n",
      "num_train_corrects / train_total_examples = 5117 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1867 ---------\n",
      "training loss = 0.3761\n",
      "training accuracy = 0.8530\n",
      "num_train_corrects / train_total_examples = 5118 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1868 ---------\n",
      "training loss = 0.3761\n",
      "training accuracy = 0.8530\n",
      "num_train_corrects / train_total_examples = 5118 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1869 ---------\n",
      "training loss = 0.3761\n",
      "training accuracy = 0.8530\n",
      "num_train_corrects / train_total_examples = 5118 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1870 ---------\n",
      "training loss = 0.3761\n",
      "training accuracy = 0.8530\n",
      "num_train_corrects / train_total_examples = 5118 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1871 ---------\n",
      "training loss = 0.3761\n",
      "training accuracy = 0.8530\n",
      "num_train_corrects / train_total_examples = 5118 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1872 ---------\n",
      "training loss = 0.3760\n",
      "training accuracy = 0.8530\n",
      "num_train_corrects / train_total_examples = 5118 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1873 ---------\n",
      "training loss = 0.3760\n",
      "training accuracy = 0.8530\n",
      "num_train_corrects / train_total_examples = 5118 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1874 ---------\n",
      "training loss = 0.3760\n",
      "training accuracy = 0.8530\n",
      "num_train_corrects / train_total_examples = 5118 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1875 ---------\n",
      "training loss = 0.3760\n",
      "training accuracy = 0.8530\n",
      "num_train_corrects / train_total_examples = 5118 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1876 ---------\n",
      "training loss = 0.3760\n",
      "training accuracy = 0.8530\n",
      "num_train_corrects / train_total_examples = 5118 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1877 ---------\n",
      "training loss = 0.3760\n",
      "training accuracy = 0.8530\n",
      "num_train_corrects / train_total_examples = 5118 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1878 ---------\n",
      "training loss = 0.3760\n",
      "training accuracy = 0.8530\n",
      "num_train_corrects / train_total_examples = 5118 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1879 ---------\n",
      "training loss = 0.3760\n",
      "training accuracy = 0.8532\n",
      "num_train_corrects / train_total_examples = 5119 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1880 ---------\n",
      "training loss = 0.3760\n",
      "training accuracy = 0.8532\n",
      "num_train_corrects / train_total_examples = 5119 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1881 ---------\n",
      "training loss = 0.3759\n",
      "training accuracy = 0.8532\n",
      "num_train_corrects / train_total_examples = 5119 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1882 ---------\n",
      "training loss = 0.3759\n",
      "training accuracy = 0.8532\n",
      "num_train_corrects / train_total_examples = 5119 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1883 ---------\n",
      "training loss = 0.3759\n",
      "training accuracy = 0.8532\n",
      "num_train_corrects / train_total_examples = 5119 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1884 ---------\n",
      "training loss = 0.3759\n",
      "training accuracy = 0.8532\n",
      "num_train_corrects / train_total_examples = 5119 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1885 ---------\n",
      "training loss = 0.3759\n",
      "training accuracy = 0.8532\n",
      "num_train_corrects / train_total_examples = 5119 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1886 ---------\n",
      "training loss = 0.3759\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1887 ---------\n",
      "training loss = 0.3759\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1888 ---------\n",
      "training loss = 0.3759\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1889 ---------\n",
      "training loss = 0.3758\n",
      "training accuracy = 0.8537\n",
      "num_train_corrects / train_total_examples = 5122 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1890 ---------\n",
      "training loss = 0.3758\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1891 ---------\n",
      "training loss = 0.3758\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1892 ---------\n",
      "training loss = 0.3758\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1893 ---------\n",
      "training loss = 0.3758\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1894 ---------\n",
      "training loss = 0.3758\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1895 ---------\n",
      "training loss = 0.3758\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1896 ---------\n",
      "training loss = 0.3758\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1897 ---------\n",
      "training loss = 0.3757\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1898 ---------\n",
      "training loss = 0.3757\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1899 ---------\n",
      "training loss = 0.3757\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1900 ---------\n",
      "training loss = 0.3757\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1901 ---------\n",
      "training loss = 0.3757\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1902 ---------\n",
      "training loss = 0.3757\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1903 ---------\n",
      "training loss = 0.3757\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1904 ---------\n",
      "training loss = 0.3757\n",
      "training accuracy = 0.8533\n",
      "num_train_corrects / train_total_examples = 5120 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1905 ---------\n",
      "training loss = 0.3757\n",
      "training accuracy = 0.8533\n",
      "num_train_corrects / train_total_examples = 5120 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1906 ---------\n",
      "training loss = 0.3756\n",
      "training accuracy = 0.8533\n",
      "num_train_corrects / train_total_examples = 5120 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1907 ---------\n",
      "training loss = 0.3756\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1908 ---------\n",
      "training loss = 0.3756\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1909 ---------\n",
      "training loss = 0.3756\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1910 ---------\n",
      "training loss = 0.3756\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1911 ---------\n",
      "training loss = 0.3756\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1912 ---------\n",
      "training loss = 0.3756\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1913 ---------\n",
      "training loss = 0.3756\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1914 ---------\n",
      "training loss = 0.3755\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1915 ---------\n",
      "training loss = 0.3755\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1916 ---------\n",
      "training loss = 0.3755\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1917 ---------\n",
      "training loss = 0.3755\n",
      "training accuracy = 0.8535\n",
      "num_train_corrects / train_total_examples = 5121 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1918 ---------\n",
      "training loss = 0.3755\n",
      "training accuracy = 0.8537\n",
      "num_train_corrects / train_total_examples = 5122 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1919 ---------\n",
      "training loss = 0.3755\n",
      "training accuracy = 0.8537\n",
      "num_train_corrects / train_total_examples = 5122 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1920 ---------\n",
      "training loss = 0.3755\n",
      "training accuracy = 0.8537\n",
      "num_train_corrects / train_total_examples = 5122 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1921 ---------\n",
      "training loss = 0.3755\n",
      "training accuracy = 0.8537\n",
      "num_train_corrects / train_total_examples = 5122 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1922 ---------\n",
      "training loss = 0.3755\n",
      "training accuracy = 0.8537\n",
      "num_train_corrects / train_total_examples = 5122 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1923 ---------\n",
      "training loss = 0.3754\n",
      "training accuracy = 0.8537\n",
      "num_train_corrects / train_total_examples = 5122 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1924 ---------\n",
      "training loss = 0.3754\n",
      "training accuracy = 0.8538\n",
      "num_train_corrects / train_total_examples = 5123 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1925 ---------\n",
      "training loss = 0.3754\n",
      "training accuracy = 0.8538\n",
      "num_train_corrects / train_total_examples = 5123 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1926 ---------\n",
      "training loss = 0.3754\n",
      "training accuracy = 0.8538\n",
      "num_train_corrects / train_total_examples = 5123 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1927 ---------\n",
      "training loss = 0.3754\n",
      "training accuracy = 0.8538\n",
      "num_train_corrects / train_total_examples = 5123 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1928 ---------\n",
      "training loss = 0.3754\n",
      "training accuracy = 0.8538\n",
      "num_train_corrects / train_total_examples = 5123 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1929 ---------\n",
      "training loss = 0.3754\n",
      "training accuracy = 0.8538\n",
      "num_train_corrects / train_total_examples = 5123 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1930 ---------\n",
      "training loss = 0.3754\n",
      "training accuracy = 0.8538\n",
      "num_train_corrects / train_total_examples = 5123 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1931 ---------\n",
      "training loss = 0.3753\n",
      "training accuracy = 0.8538\n",
      "num_train_corrects / train_total_examples = 5123 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1932 ---------\n",
      "training loss = 0.3753\n",
      "training accuracy = 0.8538\n",
      "num_train_corrects / train_total_examples = 5123 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1933 ---------\n",
      "training loss = 0.3753\n",
      "training accuracy = 0.8538\n",
      "num_train_corrects / train_total_examples = 5123 / 6000\n",
      "num_test_corrects / test_total_examples = 5045 / 6000\n",
      "testing accuracy = 0.8408\n",
      "--------- epoch: 1934 ---------\n",
      "training loss = 0.3753\n",
      "training accuracy = 0.8538\n",
      "num_train_corrects / train_total_examples = 5123 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1935 ---------\n",
      "training loss = 0.3753\n",
      "training accuracy = 0.8538\n",
      "num_train_corrects / train_total_examples = 5123 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1936 ---------\n",
      "training loss = 0.3753\n",
      "training accuracy = 0.8538\n",
      "num_train_corrects / train_total_examples = 5123 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1937 ---------\n",
      "training loss = 0.3753\n",
      "training accuracy = 0.8540\n",
      "num_train_corrects / train_total_examples = 5124 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1938 ---------\n",
      "training loss = 0.3753\n",
      "training accuracy = 0.8540\n",
      "num_train_corrects / train_total_examples = 5124 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1939 ---------\n",
      "training loss = 0.3753\n",
      "training accuracy = 0.8540\n",
      "num_train_corrects / train_total_examples = 5124 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1940 ---------\n",
      "training loss = 0.3752\n",
      "training accuracy = 0.8540\n",
      "num_train_corrects / train_total_examples = 5124 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1941 ---------\n",
      "training loss = 0.3752\n",
      "training accuracy = 0.8540\n",
      "num_train_corrects / train_total_examples = 5124 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1942 ---------\n",
      "training loss = 0.3752\n",
      "training accuracy = 0.8540\n",
      "num_train_corrects / train_total_examples = 5124 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1943 ---------\n",
      "training loss = 0.3752\n",
      "training accuracy = 0.8540\n",
      "num_train_corrects / train_total_examples = 5124 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1944 ---------\n",
      "training loss = 0.3752\n",
      "training accuracy = 0.8540\n",
      "num_train_corrects / train_total_examples = 5124 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1945 ---------\n",
      "training loss = 0.3752\n",
      "training accuracy = 0.8540\n",
      "num_train_corrects / train_total_examples = 5124 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1946 ---------\n",
      "training loss = 0.3752\n",
      "training accuracy = 0.8540\n",
      "num_train_corrects / train_total_examples = 5124 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1947 ---------\n",
      "training loss = 0.3752\n",
      "training accuracy = 0.8540\n",
      "num_train_corrects / train_total_examples = 5124 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1948 ---------\n",
      "training loss = 0.3752\n",
      "training accuracy = 0.8542\n",
      "num_train_corrects / train_total_examples = 5125 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1949 ---------\n",
      "training loss = 0.3751\n",
      "training accuracy = 0.8542\n",
      "num_train_corrects / train_total_examples = 5125 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1950 ---------\n",
      "training loss = 0.3751\n",
      "training accuracy = 0.8542\n",
      "num_train_corrects / train_total_examples = 5125 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1951 ---------\n",
      "training loss = 0.3751\n",
      "training accuracy = 0.8543\n",
      "num_train_corrects / train_total_examples = 5126 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1952 ---------\n",
      "training loss = 0.3751\n",
      "training accuracy = 0.8543\n",
      "num_train_corrects / train_total_examples = 5126 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1953 ---------\n",
      "training loss = 0.3751\n",
      "training accuracy = 0.8543\n",
      "num_train_corrects / train_total_examples = 5126 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1954 ---------\n",
      "training loss = 0.3751\n",
      "training accuracy = 0.8543\n",
      "num_train_corrects / train_total_examples = 5126 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1955 ---------\n",
      "training loss = 0.3751\n",
      "training accuracy = 0.8543\n",
      "num_train_corrects / train_total_examples = 5126 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1956 ---------\n",
      "training loss = 0.3751\n",
      "training accuracy = 0.8545\n",
      "num_train_corrects / train_total_examples = 5127 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1957 ---------\n",
      "training loss = 0.3750\n",
      "training accuracy = 0.8545\n",
      "num_train_corrects / train_total_examples = 5127 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1958 ---------\n",
      "training loss = 0.3750\n",
      "training accuracy = 0.8545\n",
      "num_train_corrects / train_total_examples = 5127 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1959 ---------\n",
      "training loss = 0.3750\n",
      "training accuracy = 0.8545\n",
      "num_train_corrects / train_total_examples = 5127 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1960 ---------\n",
      "training loss = 0.3750\n",
      "training accuracy = 0.8545\n",
      "num_train_corrects / train_total_examples = 5127 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1961 ---------\n",
      "training loss = 0.3750\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1962 ---------\n",
      "training loss = 0.3750\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1963 ---------\n",
      "training loss = 0.3750\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1964 ---------\n",
      "training loss = 0.3750\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1965 ---------\n",
      "training loss = 0.3750\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1966 ---------\n",
      "training loss = 0.3749\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1967 ---------\n",
      "training loss = 0.3749\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1968 ---------\n",
      "training loss = 0.3749\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1969 ---------\n",
      "training loss = 0.3749\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1970 ---------\n",
      "training loss = 0.3749\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1971 ---------\n",
      "training loss = 0.3749\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1972 ---------\n",
      "training loss = 0.3749\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1973 ---------\n",
      "training loss = 0.3749\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1974 ---------\n",
      "training loss = 0.3749\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1975 ---------\n",
      "training loss = 0.3748\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1976 ---------\n",
      "training loss = 0.3748\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1977 ---------\n",
      "training loss = 0.3748\n",
      "training accuracy = 0.8548\n",
      "num_train_corrects / train_total_examples = 5129 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1978 ---------\n",
      "training loss = 0.3748\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1979 ---------\n",
      "training loss = 0.3748\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1980 ---------\n",
      "training loss = 0.3748\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1981 ---------\n",
      "training loss = 0.3748\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1982 ---------\n",
      "training loss = 0.3748\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1983 ---------\n",
      "training loss = 0.3748\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1984 ---------\n",
      "training loss = 0.3747\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1985 ---------\n",
      "training loss = 0.3747\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5046 / 6000\n",
      "testing accuracy = 0.8410\n",
      "--------- epoch: 1986 ---------\n",
      "training loss = 0.3747\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1987 ---------\n",
      "training loss = 0.3747\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1988 ---------\n",
      "training loss = 0.3747\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1989 ---------\n",
      "training loss = 0.3747\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1990 ---------\n",
      "training loss = 0.3747\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1991 ---------\n",
      "training loss = 0.3747\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1992 ---------\n",
      "training loss = 0.3747\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5047 / 6000\n",
      "testing accuracy = 0.8412\n",
      "--------- epoch: 1993 ---------\n",
      "training loss = 0.3746\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5048 / 6000\n",
      "testing accuracy = 0.8413\n",
      "--------- epoch: 1994 ---------\n",
      "training loss = 0.3746\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5048 / 6000\n",
      "testing accuracy = 0.8413\n",
      "--------- epoch: 1995 ---------\n",
      "training loss = 0.3746\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5048 / 6000\n",
      "testing accuracy = 0.8413\n",
      "--------- epoch: 1996 ---------\n",
      "training loss = 0.3746\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5048 / 6000\n",
      "testing accuracy = 0.8413\n",
      "--------- epoch: 1997 ---------\n",
      "training loss = 0.3746\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5048 / 6000\n",
      "testing accuracy = 0.8413\n",
      "--------- epoch: 1998 ---------\n",
      "training loss = 0.3746\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5048 / 6000\n",
      "testing accuracy = 0.8413\n",
      "--------- epoch: 1999 ---------\n",
      "training loss = 0.3746\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5049 / 6000\n",
      "testing accuracy = 0.8415\n",
      "--------- epoch: 2000 ---------\n",
      "training loss = 0.3746\n",
      "training accuracy = 0.8547\n",
      "num_train_corrects / train_total_examples = 5128 / 6000\n",
      "num_test_corrects / test_total_examples = 5049 / 6000\n",
      "testing accuracy = 0.8415\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearModel(128, 1)\n",
    "lr_model.to(device)\n",
    "print(lr_model)\n",
    "\n",
    "def train(model):\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    for e in range(epoch):\n",
    "        print(f\"--------- epoch: {e+1} ---------\")\n",
    "        # training\n",
    "        train_loss = 0.0\n",
    "        corrects = 0\n",
    "        total_examples = 0\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()  # zero the gradients\n",
    "            # prepare data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).to(torch.float32)\n",
    "            # the forward pass\n",
    "            y_pred = model(x)\n",
    "            y_pred = y_pred.reshape(y.shape)\n",
    "            # the backward pass\n",
    "            loss = criterion(y_pred, y)  # calculate the loss\n",
    "            loss.backward()  # get the gradients\n",
    "            optimizer.step()  # update the params based on the gradients\n",
    "            # collect training results\n",
    "            train_loss += loss.item()\n",
    "            corrects += torch.sum((y_pred.round() == y))\n",
    "            total_examples += len(y)\n",
    "\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        train_accuracies.append(corrects / total_examples)\n",
    "        print(f\"training loss = {train_losses[-1]:.4f}\")\n",
    "        print(f\"training accuracy = {train_accuracies[-1]:.4f}\")\n",
    "        print(f\"num_train_corrects / train_total_examples = {corrects.item()} / {total_examples}\")\n",
    "        # print(total_examples)\n",
    "\n",
    "        # testing\n",
    "        test_corrects = 0\n",
    "        test_total_examples = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(test_loader):\n",
    "                # prepare data\n",
    "                x = x.to(device)\n",
    "                y = y.to(device).to(torch.float32)\n",
    "                # the forward pass\n",
    "                y_pred = model(x)\n",
    "                y_pred = y_pred.reshape(y.shape)\n",
    "                # collect testing results\n",
    "                test_corrects += torch.sum((y_pred.round() == y))\n",
    "                test_total_examples += len(y)\n",
    "\n",
    "        test_accuracies.append(test_corrects.item() / test_total_examples)\n",
    "        print(f\"num_test_corrects / test_total_examples = {test_corrects.item()} / {test_total_examples}\")\n",
    "        print(f\"testing accuracy = {test_accuracies[-1]:.4f}\")\n",
    "\n",
    "    return train_losses, train_accuracies, test_accuracies\n",
    "\n",
    "train_losses, train_accuracies, test_accuracies = train(lr_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f83c3661e20>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f83c339dee0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_accuracies = [acc.cpu() for acc in train_accuracies]\n",
    "plt.plot(train_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f83c3320520>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max train accuracy = 0.8548333048820496\n",
      "max test accuracy = 0.8415\n"
     ]
    }
   ],
   "source": [
    "print(f\"max train accuracy = {max(train_accuracies)}\")\n",
    "print(f\"max test accuracy = {max(test_accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ -0.8059,   2.2355,  -0.2880,  -0.2858,  -0.4535,  -0.2342,  -0.2057,\n",
      "          -0.1182,  -0.1000,   0.3365,   0.7231,   1.0056,   1.1089,   1.1210,\n",
      "           1.0363,   0.9773,   0.8117,   0.5018,   0.0694,   0.0522,   0.1617,\n",
      "           0.1406,   0.0578,   0.4041,   0.7574,   1.1670,   1.6081,   1.9638,\n",
      "           2.3568,   2.1186,   1.5858,   1.1777,   0.4016,  -0.3250,  -1.2893,\n",
      "          -2.7258,  -4.0824,  -4.8620,  -5.4745,  -5.6274,  -5.5927,  -5.6501,\n",
      "          -5.4143,  -5.0953,  -4.2264,  -2.4719,  -0.2995,   1.7619,   3.3523,\n",
      "           3.8264,   3.8829,   3.3570,   3.4993,   7.3627,  10.7933,  10.4131,\n",
      "           7.8224,   0.1326,  -5.9996,  -1.6574,   2.6312,  -3.4065,  -8.8616,\n",
      "          -3.8130,   1.2951,   6.9161,   3.4147,  -4.1008, -11.5156,   5.5204,\n",
      "          25.2935,   9.1979, -11.0725, -12.3531,  -8.5122,  -3.2046,   2.1805,\n",
      "           3.7424,   3.5325,   0.5519,  -3.2311,  -5.8989,  -8.1377,  -9.7657,\n",
      "          -9.5818,  -6.1962,  -1.7040,   2.6284,   6.1908,   6.6713,   6.1947,\n",
      "           5.5732,   4.9731,   4.7303,   4.2726,   3.4351,   2.4664,   1.3135,\n",
      "           0.0331,  -1.3806,  -2.3825,  -2.5128,  -2.3342,  -1.9680,  -1.7259,\n",
      "          -1.6441,  -1.6567,  -1.1181,  -0.4798,  -0.2557,  -0.1383,   0.2398,\n",
      "           0.4039,   0.4061,   0.1999,   0.0788,   0.1547,   0.2051,   0.2593,\n",
      "           0.2932,   0.2090,  -0.0789,  -0.4025,  -0.6136,  -1.0050,  -1.1246,\n",
      "          -1.1178,  -1.1851]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.2629], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in lr_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hesplitnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "399b82d93c603256e32b1f50bab1e44304c1a63f6ab0c291ce7489d4e70c0394"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
