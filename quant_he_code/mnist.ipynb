{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = Path.cwd().parent\n",
    "mnist_path = project_path/'data/mnist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset and dataloader for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST(root=mnist_path, download=False, transform=transforms.Compose([\n",
    "    ToTensor(),\n",
    "    lambda x: (x*4).int(),\n",
    "    lambda x: x.float()/4,\n",
    "]))\n",
    "test_dataset = MNIST(root=mnist_path, train=False, transform=transforms.Compose([\n",
    "    ToTensor(),\n",
    "    lambda x: (x*4).int(),\n",
    "    lambda x: x.float()/4,\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n",
      "Unique values = tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1281b023d0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = train_dataset[0][0][0]\n",
    "print(im.shape)\n",
    "print(f\"Unique values = {im.unique()}\")\n",
    "plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing training and validation data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43)\n",
    "val_size = 5000\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size * 2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size * 2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get if device is GPU or CPU. Bring data onto the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "\n",
    "    def __init__(self, data_loader, device):\n",
    "        self.dl = data_loader\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "    \n",
    "device = get_default_device()\n",
    "\n",
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "val_loader = DeviceDataLoader(val_loader, device)\n",
    "test_loader = DeviceDataLoader(test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n",
      "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    print(x.unique())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the CNN model (2 conv layers + 1 linear layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \"\"\"\n",
    "    PytorchLightining style\n",
    "    \"\"\"\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch) -> Dict:\n",
    "        images, labels = batch\n",
    "        out = self(images)  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
    "        acc = accuracy(out, labels)  # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs) -> Dict:\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()  # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()  # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "\n",
    "    def epoch_end(self, epoch, result) -> None:\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch + 1, result['val_loss'], result['val_acc']))\n",
    "\n",
    "\n",
    "class MNISTConvModel(ImageClassificationBase):\n",
    "    \"\"\"\n",
    "    2 conv layers + 1 linear layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 5, 5, stride=(2, 2),\n",
    "                               padding=0, bias=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(5, 50, 5, stride=(2, 2),\n",
    "                               padding=0, bias=True)\n",
    "        self.fc1 = nn.Linear(800, 10, bias=True)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = out * out  # first square\n",
    "        out = self.conv2(out)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = out * out  # second square\n",
    "        out = self.fc1(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTConvModel(\n",
       "  (conv1): Conv2d(1, 5, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (conv2): Conv2d(5, 50, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (fc1): Linear(in_features=800, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = to_device(MNISTConvModel(), device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader) -> Dict:\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "\n",
    "def fit(epochs, lr, model, \n",
    "        train_loader, val_loader, test_loader, \n",
    "        file_name, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    high_acc = 0.98\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "\n",
    "        if epoch >= 2:\n",
    "            eval_dict = evaluate(model, test_loader)\n",
    "            print(str(epoch) + \"\\t\" + str(eval_dict))\n",
    "            if eval_dict['val_acc'] > high_acc:\n",
    "                high_acc = eval_dict['val_acc']\n",
    "                torch.save(model.state_dict(), file_name)\n",
    "                print(\"Saved\")\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], val_loss: 0.1171, val_acc: 0.9666\n",
      "Epoch [2], val_loss: 0.0896, val_acc: 0.9707\n",
      "Epoch [3], val_loss: 0.0663, val_acc: 0.9788\n",
      "2\t{'val_loss': 0.06194232776761055, 'val_acc': 0.9809912443161011}\n",
      "Saved\n",
      "Epoch [4], val_loss: 0.0680, val_acc: 0.9802\n",
      "3\t{'val_loss': 0.059880662709474564, 'val_acc': 0.9809912443161011}\n",
      "Epoch [5], val_loss: 0.0676, val_acc: 0.9796\n",
      "4\t{'val_loss': 0.05957421287894249, 'val_acc': 0.9831807613372803}\n",
      "Saved\n",
      "Epoch [6], val_loss: 0.0554, val_acc: 0.9822\n",
      "5\t{'val_loss': 0.0483112707734108, 'val_acc': 0.9853702187538147}\n",
      "Saved\n",
      "Epoch [7], val_loss: 0.0721, val_acc: 0.9798\n",
      "6\t{'val_loss': 0.056040626019239426, 'val_acc': 0.9833797812461853}\n",
      "Epoch [8], val_loss: 0.0654, val_acc: 0.9816\n",
      "7\t{'val_loss': 0.051207542419433594, 'val_acc': 0.9847730994224548}\n",
      "Epoch [9], val_loss: 0.0652, val_acc: 0.9848\n",
      "8\t{'val_loss': 0.0532069131731987, 'val_acc': 0.9853702187538147}\n",
      "Epoch [10], val_loss: 0.0751, val_acc: 0.9804\n",
      "9\t{'val_loss': 0.06918980181217194, 'val_acc': 0.9823845624923706}\n",
      "Epoch [11], val_loss: 0.0697, val_acc: 0.9810\n",
      "10\t{'val_loss': 0.05848272889852524, 'val_acc': 0.9859673380851746}\n",
      "Saved\n",
      "Epoch [12], val_loss: 0.1302, val_acc: 0.9751\n",
      "11\t{'val_loss': 0.08298469334840775, 'val_acc': 0.9803941249847412}\n",
      "Epoch [13], val_loss: 0.0810, val_acc: 0.9820\n",
      "12\t{'val_loss': 0.05685562640428543, 'val_acc': 0.9856687784194946}\n",
      "Epoch [14], val_loss: 0.0905, val_acc: 0.9840\n",
      "13\t{'val_loss': 0.06953354179859161, 'val_acc': 0.9860668778419495}\n",
      "Saved\n",
      "Epoch [15], val_loss: 0.0827, val_acc: 0.9808\n",
      "14\t{'val_loss': 0.06969023495912552, 'val_acc': 0.9847730994224548}\n",
      "Epoch [16], val_loss: 0.0836, val_acc: 0.9814\n",
      "15\t{'val_loss': 0.061901893466711044, 'val_acc': 0.9853702187538147}\n",
      "Epoch [17], val_loss: 0.1204, val_acc: 0.9763\n",
      "16\t{'val_loss': 0.08535316586494446, 'val_acc': 0.9823845624923706}\n",
      "Epoch [18], val_loss: 0.1029, val_acc: 0.9800\n",
      "17\t{'val_loss': 0.09233072400093079, 'val_acc': 0.9813893437385559}\n",
      "Epoch [19], val_loss: 0.0996, val_acc: 0.9778\n",
      "18\t{'val_loss': 0.07919482886791229, 'val_acc': 0.9826831221580505}\n",
      "Epoch [20], val_loss: 0.0912, val_acc: 0.9804\n",
      "19\t{'val_loss': 0.06923448294401169, 'val_acc': 0.9844745397567749}\n",
      "Epoch [21], val_loss: 0.1165, val_acc: 0.9798\n",
      "20\t{'val_loss': 0.09048284590244293, 'val_acc': 0.984375}\n",
      "Epoch [22], val_loss: 0.1080, val_acc: 0.9798\n",
      "21\t{'val_loss': 0.09538070857524872, 'val_acc': 0.9840764403343201}\n",
      "Epoch [23], val_loss: 0.1078, val_acc: 0.9808\n",
      "22\t{'val_loss': 0.08506989479064941, 'val_acc': 0.9842754602432251}\n",
      "Epoch [24], val_loss: 0.1058, val_acc: 0.9820\n",
      "23\t{'val_loss': 0.08356185257434845, 'val_acc': 0.984175980091095}\n",
      "Epoch [25], val_loss: 0.1349, val_acc: 0.9792\n",
      "24\t{'val_loss': 0.1112842932343483, 'val_acc': 0.9816879034042358}\n",
      "Epoch [26], val_loss: 0.1255, val_acc: 0.9814\n",
      "25\t{'val_loss': 0.10238262265920639, 'val_acc': 0.9832802414894104}\n",
      "Epoch [27], val_loss: 0.1034, val_acc: 0.9812\n",
      "26\t{'val_loss': 0.08562196046113968, 'val_acc': 0.9849721193313599}\n",
      "Epoch [28], val_loss: 0.0960, val_acc: 0.9820\n",
      "27\t{'val_loss': 0.07959660142660141, 'val_acc': 0.9849721193313599}\n",
      "Epoch [29], val_loss: 0.0902, val_acc: 0.9834\n",
      "28\t{'val_loss': 0.08191563189029694, 'val_acc': 0.9865645170211792}\n",
      "Saved\n",
      "Epoch [30], val_loss: 0.0843, val_acc: 0.9826\n",
      "29\t{'val_loss': 0.0704057514667511, 'val_acc': 0.9859673380851746}\n",
      "Epoch [31], val_loss: 0.1137, val_acc: 0.9826\n",
      "30\t{'val_loss': 0.09564774483442307, 'val_acc': 0.9852706789970398}\n",
      "Epoch [32], val_loss: 0.1270, val_acc: 0.9828\n",
      "31\t{'val_loss': 0.09410221129655838, 'val_acc': 0.9854697585105896}\n",
      "Epoch [33], val_loss: 0.1024, val_acc: 0.9852\n",
      "32\t{'val_loss': 0.07953348755836487, 'val_acc': 0.9871616363525391}\n",
      "Saved\n",
      "Epoch [34], val_loss: 0.1287, val_acc: 0.9812\n",
      "33\t{'val_loss': 0.10758906602859497, 'val_acc': 0.9844745397567749}\n",
      "Epoch [35], val_loss: 0.1026, val_acc: 0.9838\n",
      "34\t{'val_loss': 0.10139099508523941, 'val_acc': 0.9854697585105896}\n",
      "Epoch [36], val_loss: 0.1310, val_acc: 0.9814\n",
      "35\t{'val_loss': 0.10925708711147308, 'val_acc': 0.9832802414894104}\n",
      "Epoch [37], val_loss: 0.1231, val_acc: 0.9808\n",
      "36\t{'val_loss': 0.11010244488716125, 'val_acc': 0.9849721193313599}\n",
      "Epoch [38], val_loss: 0.0942, val_acc: 0.9834\n",
      "37\t{'val_loss': 0.08702345192432404, 'val_acc': 0.9867635369300842}\n",
      "Epoch [39], val_loss: 0.1623, val_acc: 0.9757\n",
      "38\t{'val_loss': 0.1355152726173401, 'val_acc': 0.9800955653190613}\n",
      "Epoch [40], val_loss: 0.1510, val_acc: 0.9832\n",
      "39\t{'val_loss': 0.11898541450500488, 'val_acc': 0.987261176109314}\n",
      "Saved\n",
      "Epoch [41], val_loss: 0.1125, val_acc: 0.9838\n",
      "40\t{'val_loss': 0.08726806193590164, 'val_acc': 0.9866639971733093}\n",
      "Epoch [42], val_loss: 0.1311, val_acc: 0.9828\n",
      "41\t{'val_loss': 0.11369763314723969, 'val_acc': 0.9856687784194946}\n",
      "Epoch [43], val_loss: 0.1293, val_acc: 0.9784\n",
      "42\t{'val_loss': 0.11815592646598816, 'val_acc': 0.9824841022491455}\n",
      "Epoch [44], val_loss: 0.1300, val_acc: 0.9822\n",
      "43\t{'val_loss': 0.10108140110969543, 'val_acc': 0.9852706789970398}\n",
      "Epoch [45], val_loss: 0.1225, val_acc: 0.9806\n",
      "44\t{'val_loss': 0.08789917081594467, 'val_acc': 0.9851711988449097}\n",
      "Epoch [46], val_loss: 0.1047, val_acc: 0.9838\n",
      "45\t{'val_loss': 0.08805594593286514, 'val_acc': 0.9869625568389893}\n",
      "Epoch [47], val_loss: 0.1146, val_acc: 0.9830\n",
      "46\t{'val_loss': 0.10050713270902634, 'val_acc': 0.987460196018219}\n",
      "Saved\n",
      "Epoch [48], val_loss: 0.1333, val_acc: 0.9788\n",
      "47\t{'val_loss': 0.1071062758564949, 'val_acc': 0.9837778806686401}\n",
      "Epoch [49], val_loss: 0.1543, val_acc: 0.9804\n",
      "48\t{'val_loss': 0.10836119204759598, 'val_acc': 0.9864649772644043}\n",
      "Epoch [50], val_loss: 0.1577, val_acc: 0.9834\n",
      "49\t{'val_loss': 0.13418976962566376, 'val_acc': 0.9835788011550903}\n",
      "Epoch [51], val_loss: 0.1047, val_acc: 0.9848\n",
      "50\t{'val_loss': 0.08725114911794662, 'val_acc': 0.9859673380851746}\n",
      "Epoch [52], val_loss: 0.1630, val_acc: 0.9810\n",
      "51\t{'val_loss': 0.10501456260681152, 'val_acc': 0.9855692386627197}\n",
      "Epoch [53], val_loss: 0.1487, val_acc: 0.9808\n",
      "52\t{'val_loss': 0.10579093545675278, 'val_acc': 0.9828821420669556}\n",
      "Epoch [54], val_loss: 0.1550, val_acc: 0.9818\n",
      "53\t{'val_loss': 0.1223926916718483, 'val_acc': 0.9836783409118652}\n",
      "Epoch [55], val_loss: 0.1254, val_acc: 0.9852\n",
      "54\t{'val_loss': 0.10569585114717484, 'val_acc': 0.9864649772644043}\n",
      "Epoch [56], val_loss: 0.1234, val_acc: 0.9852\n",
      "55\t{'val_loss': 0.10470378398895264, 'val_acc': 0.9856687784194946}\n",
      "Epoch [57], val_loss: 0.1397, val_acc: 0.9816\n",
      "56\t{'val_loss': 0.10180886834859848, 'val_acc': 0.9831807613372803}\n",
      "Epoch [58], val_loss: 0.1157, val_acc: 0.9856\n",
      "57\t{'val_loss': 0.08751897513866425, 'val_acc': 0.9865645170211792}\n",
      "Epoch [59], val_loss: 0.1499, val_acc: 0.9800\n",
      "58\t{'val_loss': 0.1123628094792366, 'val_acc': 0.9848726391792297}\n",
      "Epoch [60], val_loss: 0.1272, val_acc: 0.9848\n",
      "59\t{'val_loss': 0.09678955376148224, 'val_acc': 0.9875597357749939}\n",
      "Saved\n",
      "Epoch [61], val_loss: 0.2742, val_acc: 0.9759\n",
      "60\t{'val_loss': 0.20890569686889648, 'val_acc': 0.9784036874771118}\n",
      "Epoch [62], val_loss: 0.1365, val_acc: 0.9828\n",
      "61\t{'val_loss': 0.11175571382045746, 'val_acc': 0.9867635369300842}\n",
      "Epoch [63], val_loss: 0.1814, val_acc: 0.9806\n",
      "62\t{'val_loss': 0.12992268800735474, 'val_acc': 0.9836783409118652}\n",
      "Epoch [64], val_loss: 0.1187, val_acc: 0.9840\n",
      "63\t{'val_loss': 0.09156647324562073, 'val_acc': 0.9862658977508545}\n",
      "Epoch [65], val_loss: 0.1349, val_acc: 0.9824\n",
      "64\t{'val_loss': 0.11651131510734558, 'val_acc': 0.9849721193313599}\n",
      "Epoch [66], val_loss: 0.1423, val_acc: 0.9864\n",
      "65\t{'val_loss': 0.10699129849672318, 'val_acc': 0.9868630766868591}\n",
      "Epoch [67], val_loss: 0.1174, val_acc: 0.9800\n",
      "66\t{'val_loss': 0.11237630248069763, 'val_acc': 0.9834793210029602}\n",
      "Epoch [68], val_loss: 0.1169, val_acc: 0.9842\n",
      "67\t{'val_loss': 0.0890049934387207, 'val_acc': 0.9866639971733093}\n",
      "Epoch [69], val_loss: 0.1657, val_acc: 0.9822\n",
      "68\t{'val_loss': 0.1268579363822937, 'val_acc': 0.9850716590881348}\n",
      "Epoch [70], val_loss: 0.1485, val_acc: 0.9826\n",
      "69\t{'val_loss': 0.09257236868143082, 'val_acc': 0.9864649772644043}\n",
      "Epoch [71], val_loss: 0.1308, val_acc: 0.9838\n",
      "70\t{'val_loss': 0.09695834666490555, 'val_acc': 0.987659215927124}\n",
      "Saved\n",
      "Epoch [72], val_loss: 0.1272, val_acc: 0.9818\n",
      "71\t{'val_loss': 0.12212041765451431, 'val_acc': 0.9852706789970398}\n",
      "Epoch [73], val_loss: 0.1424, val_acc: 0.9836\n",
      "72\t{'val_loss': 0.1028074398636818, 'val_acc': 0.9861664175987244}\n",
      "Epoch [74], val_loss: 0.1588, val_acc: 0.9812\n",
      "73\t{'val_loss': 0.11598052829504013, 'val_acc': 0.9856687784194946}\n",
      "Epoch [75], val_loss: 0.2648, val_acc: 0.9782\n",
      "74\t{'val_loss': 0.21608278155326843, 'val_acc': 0.9796974658966064}\n",
      "Epoch [76], val_loss: 0.1087, val_acc: 0.9842\n",
      "75\t{'val_loss': 0.10219668596982956, 'val_acc': 0.9864649772644043}\n",
      "Epoch [77], val_loss: 0.1316, val_acc: 0.9828\n",
      "76\t{'val_loss': 0.11462966352701187, 'val_acc': 0.9861664175987244}\n",
      "Epoch [78], val_loss: 0.1946, val_acc: 0.9828\n",
      "77\t{'val_loss': 0.14761708676815033, 'val_acc': 0.984175980091095}\n",
      "Epoch [79], val_loss: 0.1589, val_acc: 0.9840\n",
      "78\t{'val_loss': 0.12492695450782776, 'val_acc': 0.9869625568389893}\n",
      "Epoch [80], val_loss: 0.1643, val_acc: 0.9852\n",
      "79\t{'val_loss': 0.13066928088665009, 'val_acc': 0.9869625568389893}\n",
      "Epoch [81], val_loss: 0.1823, val_acc: 0.9796\n",
      "80\t{'val_loss': 0.14677421748638153, 'val_acc': 0.9816879034042358}\n",
      "Epoch [82], val_loss: 0.1536, val_acc: 0.9844\n",
      "81\t{'val_loss': 0.1207536831498146, 'val_acc': 0.9859673380851746}\n",
      "Epoch [83], val_loss: 0.1698, val_acc: 0.9836\n",
      "82\t{'val_loss': 0.1250964105129242, 'val_acc': 0.9853702187538147}\n",
      "Epoch [84], val_loss: 0.1301, val_acc: 0.9858\n",
      "83\t{'val_loss': 0.10477782785892487, 'val_acc': 0.987659215927124}\n",
      "Epoch [85], val_loss: 0.1246, val_acc: 0.9866\n",
      "84\t{'val_loss': 0.11496104300022125, 'val_acc': 0.9870620965957642}\n",
      "Epoch [86], val_loss: 0.1591, val_acc: 0.9818\n",
      "85\t{'val_loss': 0.11290667951107025, 'val_acc': 0.9856687784194946}\n",
      "Epoch [87], val_loss: 0.1713, val_acc: 0.9836\n",
      "86\t{'val_loss': 0.14863689243793488, 'val_acc': 0.9857683181762695}\n",
      "Epoch [88], val_loss: 0.1680, val_acc: 0.9814\n",
      "87\t{'val_loss': 0.11498133093118668, 'val_acc': 0.9858678579330444}\n",
      "Epoch [89], val_loss: 0.1819, val_acc: 0.9836\n",
      "88\t{'val_loss': 0.13858632743358612, 'val_acc': 0.9862658977508545}\n",
      "Epoch [90], val_loss: 0.1462, val_acc: 0.9838\n",
      "89\t{'val_loss': 0.11796244233846664, 'val_acc': 0.9853702187538147}\n",
      "Epoch [91], val_loss: 0.1572, val_acc: 0.9796\n",
      "90\t{'val_loss': 0.1498114913702011, 'val_acc': 0.9849721193313599}\n",
      "Epoch [92], val_loss: 0.1765, val_acc: 0.9834\n",
      "91\t{'val_loss': 0.1300811469554901, 'val_acc': 0.9867635369300842}\n",
      "Epoch [93], val_loss: 0.1778, val_acc: 0.9840\n",
      "92\t{'val_loss': 0.11933664977550507, 'val_acc': 0.9882563948631287}\n",
      "Saved\n",
      "Epoch [94], val_loss: 0.1350, val_acc: 0.9852\n",
      "93\t{'val_loss': 0.10536397993564606, 'val_acc': 0.987659215927124}\n",
      "Epoch [95], val_loss: 0.2166, val_acc: 0.9777\n",
      "94\t{'val_loss': 0.14709237217903137, 'val_acc': 0.9827826619148254}\n",
      "Epoch [96], val_loss: 0.1338, val_acc: 0.9838\n",
      "95\t{'val_loss': 0.11368417739868164, 'val_acc': 0.9844745397567749}\n",
      "Epoch [97], val_loss: 0.1500, val_acc: 0.9848\n",
      "96\t{'val_loss': 0.11834706366062164, 'val_acc': 0.9863654375076294}\n",
      "Epoch [98], val_loss: 0.1418, val_acc: 0.9820\n",
      "97\t{'val_loss': 0.12374584376811981, 'val_acc': 0.9859673380851746}\n",
      "Epoch [99], val_loss: 0.1767, val_acc: 0.9820\n",
      "98\t{'val_loss': 0.13738594949245453, 'val_acc': 0.9858678579330444}\n",
      "Epoch [100], val_loss: 0.1816, val_acc: 0.9826\n",
      "99\t{'val_loss': 0.1763424426317215, 'val_acc': 0.9842754602432251}\n",
      "Epoch [101], val_loss: 0.1803, val_acc: 0.9838\n",
      "100\t{'val_loss': 0.1524287462234497, 'val_acc': 0.9866639971733093}\n",
      "Epoch [102], val_loss: 0.1821, val_acc: 0.9844\n",
      "101\t{'val_loss': 0.13242554664611816, 'val_acc': 0.9854697585105896}\n",
      "Epoch [103], val_loss: 0.1859, val_acc: 0.9848\n",
      "102\t{'val_loss': 0.15796954929828644, 'val_acc': 0.9854697585105896}\n",
      "Epoch [104], val_loss: 0.1858, val_acc: 0.9840\n",
      "103\t{'val_loss': 0.13508595526218414, 'val_acc': 0.9869625568389893}\n",
      "Epoch [105], val_loss: 0.1694, val_acc: 0.9850\n",
      "104\t{'val_loss': 0.13847139477729797, 'val_acc': 0.9869625568389893}\n",
      "Epoch [106], val_loss: 0.1924, val_acc: 0.9850\n",
      "105\t{'val_loss': 0.13654671609401703, 'val_acc': 0.9873606562614441}\n",
      "Epoch [107], val_loss: 0.1689, val_acc: 0.9838\n",
      "106\t{'val_loss': 0.12675020098686218, 'val_acc': 0.9860668778419495}\n",
      "Epoch [108], val_loss: 0.2299, val_acc: 0.9818\n",
      "107\t{'val_loss': 0.16040077805519104, 'val_acc': 0.9857683181762695}\n",
      "Epoch [109], val_loss: 0.1848, val_acc: 0.9840\n",
      "108\t{'val_loss': 0.13896691799163818, 'val_acc': 0.9860668778419495}\n",
      "Epoch [110], val_loss: 0.3259, val_acc: 0.9753\n",
      "109\t{'val_loss': 0.3031008839607239, 'val_acc': 0.9767118096351624}\n",
      "Epoch [111], val_loss: 0.1924, val_acc: 0.9832\n",
      "110\t{'val_loss': 0.13472571969032288, 'val_acc': 0.9878582954406738}\n",
      "Epoch [112], val_loss: 0.3327, val_acc: 0.9759\n",
      "111\t{'val_loss': 0.2602839469909668, 'val_acc': 0.9801950454711914}\n",
      "Epoch [113], val_loss: 0.2213, val_acc: 0.9818\n",
      "112\t{'val_loss': 0.13721811771392822, 'val_acc': 0.9866639971733093}\n",
      "Epoch [114], val_loss: 0.2717, val_acc: 0.9794\n",
      "113\t{'val_loss': 0.1840125471353531, 'val_acc': 0.9840764403343201}\n",
      "Epoch [115], val_loss: 0.1958, val_acc: 0.9804\n",
      "114\t{'val_loss': 0.12887322902679443, 'val_acc': 0.9862658977508545}\n",
      "Epoch [116], val_loss: 0.2081, val_acc: 0.9840\n",
      "115\t{'val_loss': 0.14880289137363434, 'val_acc': 0.987659215927124}\n",
      "Epoch [117], val_loss: 0.1974, val_acc: 0.9824\n",
      "116\t{'val_loss': 0.12950530648231506, 'val_acc': 0.9873606562614441}\n",
      "Epoch [118], val_loss: 0.2097, val_acc: 0.9830\n",
      "117\t{'val_loss': 0.12954600155353546, 'val_acc': 0.9870620965957642}\n",
      "Epoch [119], val_loss: 0.2113, val_acc: 0.9830\n",
      "118\t{'val_loss': 0.12709996104240417, 'val_acc': 0.9869625568389893}\n",
      "Epoch [120], val_loss: 0.2304, val_acc: 0.9810\n",
      "119\t{'val_loss': 0.15670424699783325, 'val_acc': 0.9853702187538147}\n",
      "Epoch [121], val_loss: 0.2173, val_acc: 0.9834\n",
      "120\t{'val_loss': 0.14497563242912292, 'val_acc': 0.9871616363525391}\n",
      "Epoch [122], val_loss: 0.1723, val_acc: 0.9848\n",
      "121\t{'val_loss': 0.11409029364585876, 'val_acc': 0.9875597357749939}\n",
      "Epoch [123], val_loss: 0.2070, val_acc: 0.9778\n",
      "122\t{'val_loss': 0.13008663058280945, 'val_acc': 0.9836783409118652}\n",
      "Epoch [124], val_loss: 0.2287, val_acc: 0.9810\n",
      "123\t{'val_loss': 0.16562716662883759, 'val_acc': 0.9842754602432251}\n",
      "Epoch [125], val_loss: 0.1956, val_acc: 0.9850\n",
      "124\t{'val_loss': 0.17870859801769257, 'val_acc': 0.9854697585105896}\n",
      "Epoch [126], val_loss: 0.1792, val_acc: 0.9834\n",
      "125\t{'val_loss': 0.14771929383277893, 'val_acc': 0.9863654375076294}\n",
      "Epoch [127], val_loss: 0.1775, val_acc: 0.9848\n",
      "126\t{'val_loss': 0.13417094945907593, 'val_acc': 0.987957775592804}\n",
      "Epoch [128], val_loss: 0.1924, val_acc: 0.9850\n",
      "127\t{'val_loss': 0.1558476835489273, 'val_acc': 0.9875597357749939}\n",
      "Epoch [129], val_loss: 0.1706, val_acc: 0.9873\n",
      "128\t{'val_loss': 0.15844544768333435, 'val_acc': 0.9869625568389893}\n",
      "Epoch [130], val_loss: 0.2067, val_acc: 0.9838\n",
      "129\t{'val_loss': 0.1711978167295456, 'val_acc': 0.9838773608207703}\n",
      "Epoch [131], val_loss: 0.1928, val_acc: 0.9850\n",
      "130\t{'val_loss': 0.1426762491464615, 'val_acc': 0.9870620965957642}\n",
      "Epoch [132], val_loss: 0.1842, val_acc: 0.9846\n",
      "131\t{'val_loss': 0.1474265158176422, 'val_acc': 0.9859673380851746}\n",
      "Epoch [133], val_loss: 0.2264, val_acc: 0.9846\n",
      "132\t{'val_loss': 0.16313551366329193, 'val_acc': 0.9862658977508545}\n",
      "Epoch [134], val_loss: 0.2003, val_acc: 0.9848\n",
      "133\t{'val_loss': 0.15798383951187134, 'val_acc': 0.9881568551063538}\n",
      "Epoch [135], val_loss: 0.1951, val_acc: 0.9846\n",
      "134\t{'val_loss': 0.1489631086587906, 'val_acc': 0.987460196018219}\n",
      "Epoch [136], val_loss: 0.1845, val_acc: 0.9860\n",
      "135\t{'val_loss': 0.14517804980278015, 'val_acc': 0.9877587556838989}\n",
      "Epoch [137], val_loss: 0.1860, val_acc: 0.9864\n",
      "136\t{'val_loss': 0.14829134941101074, 'val_acc': 0.9880573153495789}\n",
      "Epoch [138], val_loss: 0.1953, val_acc: 0.9864\n",
      "137\t{'val_loss': 0.1533321738243103, 'val_acc': 0.9877587556838989}\n",
      "Epoch [139], val_loss: 0.2050, val_acc: 0.9864\n",
      "138\t{'val_loss': 0.16657865047454834, 'val_acc': 0.9878582954406738}\n",
      "Epoch [140], val_loss: 0.2200, val_acc: 0.9860\n",
      "139\t{'val_loss': 0.17155210673809052, 'val_acc': 0.987957775592804}\n",
      "Epoch [141], val_loss: 0.2302, val_acc: 0.9864\n",
      "140\t{'val_loss': 0.1842699944972992, 'val_acc': 0.9881568551063538}\n",
      "Epoch [142], val_loss: 0.2445, val_acc: 0.9866\n",
      "141\t{'val_loss': 0.19557814300060272, 'val_acc': 0.9880573153495789}\n",
      "Epoch [143], val_loss: 0.2689, val_acc: 0.9862\n",
      "142\t{'val_loss': 0.21326908469200134, 'val_acc': 0.9878582954406738}\n",
      "Epoch [144], val_loss: 0.2315, val_acc: 0.9848\n",
      "143\t{'val_loss': 0.21723949909210205, 'val_acc': 0.9862658977508545}\n",
      "Epoch [145], val_loss: 0.2162, val_acc: 0.9834\n",
      "144\t{'val_loss': 0.17932768166065216, 'val_acc': 0.9860668778419495}\n",
      "Epoch [146], val_loss: 0.2222, val_acc: 0.9814\n",
      "145\t{'val_loss': 0.17082525789737701, 'val_acc': 0.9838773608207703}\n",
      "Epoch [147], val_loss: 0.2272, val_acc: 0.9818\n",
      "146\t{'val_loss': 0.158861443400383, 'val_acc': 0.9848726391792297}\n",
      "Epoch [148], val_loss: 0.2411, val_acc: 0.9846\n",
      "147\t{'val_loss': 0.18834324181079865, 'val_acc': 0.9875597357749939}\n",
      "Epoch [149], val_loss: 0.2429, val_acc: 0.9818\n",
      "148\t{'val_loss': 0.16913150250911713, 'val_acc': 0.9846735596656799}\n",
      "Epoch [150], val_loss: 0.3076, val_acc: 0.9824\n",
      "149\t{'val_loss': 0.251384973526001, 'val_acc': 0.9829816818237305}\n"
     ]
    }
   ],
   "source": [
    "history = [evaluate(model, val_loader)]\n",
    "savefile_name = \"hcnn_mnist_plain\"\n",
    "history += fit(epochs=150, lr=0.001, model=model, \n",
    "               train_loader=train_loader, \n",
    "               val_loader=val_loader, test_loader=test_loader, \n",
    "               file_name=str(savefile_name + \".pth\"), \n",
    "               opt_func=torch.optim.Adam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final evaluation on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 0.251384973526001, 'val_acc': 0.9829816818237305}\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(model, test_loader))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pockethhe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
