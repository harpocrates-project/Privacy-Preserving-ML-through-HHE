{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from numpy import logical_and\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Pyfhel import Pyfhel\n",
    "from Pyfhel.PyPtxt import PyPtxt as PyfhelPlaintext\n",
    "from Pyfhel.PyCtxt import PyCtxt as PyfhelCiphertext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist  ## data are downloaded ~/.keras/datasets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (60000, 28, 28)\n",
      "y_train.shape = (60000,)\n",
      "x_test.shape = (10000, 28, 28)\n",
      "y_test.shape = (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{x_train.shape = }\")\n",
    "print(f\"{y_train.shape = }\")\n",
    "print(f\"{x_test.shape = }\")\n",
    "print(f\"{y_test.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantizing the MNIST dataset into 2 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   9,  11,  14,  16,  18,  23,  24,  25,  26,\n",
       "        27,  30,  35,  36,  39,  43,  45,  46,  49,  55,  56,  64,  66,\n",
       "        70,  78,  80,  81,  82,  90,  93,  94, 107, 108, 114, 119, 126,\n",
       "       127, 130, 132, 133, 135, 136, 139, 148, 150, 154, 156, 160, 166,\n",
       "       170, 171, 172, 175, 182, 183, 186, 187, 190, 195, 198, 201, 205,\n",
       "       207, 212, 213, 219, 221, 225, 226, 229, 238, 240, 241, 242, 244,\n",
       "       247, 249, 250, 251, 252, 253, 255], dtype=uint8)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = x_train[0]\n",
    "plt.imshow(im, cmap='gray')\n",
    "np.unique(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train / 255.0 * 3).astype(int)\n",
    "x_test = (x_test / 255.0 * 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(x_train))\n",
    "print(np.unique(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f821c146e20>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.expand_dims(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 28, 28)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantizing the weights (and biases) of the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor_input = 1 / 3\n",
    "bit_width = 4\n",
    "cnn_py = __import__(\"quant_weights_16bits\")\n",
    "\n",
    "def quantise(element, s, b):\n",
    "    upper = 2 ** (b - 1) - 1\n",
    "    lower = -2 ** (b - 1)\n",
    "\n",
    "    value = int(round(element / s))\n",
    "\n",
    "    if value > upper:\n",
    "        return upper\n",
    "    elif value < lower:\n",
    "        return lower\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "np_quantise = np.vectorize(quantise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_ind_scale = 4681.0\n",
      "conv1_scale = 1560.3333333333333\n",
      "conv1_scale_act = 2434640.111111111\n",
      "conv2_ind_scale = 4681.0\n",
      "conv2_scale = 11396550360.11111\n",
      "conv2_scale_act = 1.2988136011054868e+20\n",
      "dense_ind_scale = 4681.0\n",
      "dense_scale = 6.079746466774783e+23\n"
     ]
    }
   ],
   "source": [
    "conv1_ind_scale = np.max(np.abs(cnn_py.conv2d)) / (2 ** (bit_width - 1) - 1)\n",
    "conv1_scale = scale_factor_input * conv1_ind_scale\n",
    "# conv1 activation (square)\n",
    "conv1_scale_act = conv1_scale ** 2\n",
    "\n",
    "# the 1/4 for the scaled average pooling\n",
    "conv2_ind_scale = np.max(np.abs(cnn_py.conv2d_1)) / (2 ** (bit_width - 1) - 1)\n",
    "conv2_scale = conv1_scale_act * conv2_ind_scale\n",
    "# Activation\n",
    "conv2_scale_act = conv2_scale ** 2\n",
    "\n",
    "dense_ind_scale = np.max(np.abs(cnn_py.dense)) / (2 ** (bit_width - 1) - 1)\n",
    "dense_scale = conv2_scale_act * dense_ind_scale\n",
    "\n",
    "print(f\"{conv1_ind_scale = }\")\n",
    "print(f\"{conv1_scale = }\")\n",
    "print(f\"{conv1_scale_act = }\")\n",
    "print(f\"{conv2_ind_scale = }\")\n",
    "print(f\"{conv2_scale = }\")\n",
    "print(f\"{conv2_scale_act = }\")\n",
    "print(f\"{dense_ind_scale = }\")\n",
    "print(f\"{dense_scale = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias are just 0. Can just skip them, and we can quantize them to much bigger bit-width\n",
    "conv1_bias = np_quantise(cnn_py.conv2d_bias, conv1_scale, 1024)\n",
    "conv2_bias = np_quantise(cnn_py.conv2d_1_bias, conv2_scale, 1024)\n",
    "dense_bias = np_quantise(cnn_py.dense_bias, dense_scale, 1024)\n",
    "\n",
    "conv1_q = np_quantise(cnn_py.conv2d, conv1_ind_scale, bit_width)\n",
    "conv2_q = np_quantise(cnn_py.conv2d_1, conv2_ind_scale, bit_width)\n",
    "dense1_q = np_quantise(cnn_py.dense, dense_ind_scale, bit_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.unique(conv1_q) = array([-6, -5, -4, -3, -2, -1,  0,  1,  2,  3,  4,  5,  6,  7])\n",
      "np.unique(conv2_q) = array([-7, -6, -5, -4, -3, -2, -1,  0,  1,  2,  3,  4,  5,  6,  7])\n",
      "np.unique(dense1_q) = array([-7, -6, -5, -4, -3, -2, -1,  0,  1,  2,  3,  4,  5,  6])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{np.unique(conv1_q) = }\")\n",
    "print(f\"{np.unique(conv2_q) = }\")\n",
    "print(f\"{np.unique(dense1_q) = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encrypted Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HE.get_nSlots() = 16384\n",
      "duplicate_factor = 8\n"
     ]
    }
   ],
   "source": [
    "HE = Pyfhel()  # Creating empty Pyfhel object\n",
    "# 16384; 8192\n",
    "HE.contextGen(scheme='bfv', n=16384,\n",
    "    t_bits=47)  # Plaintext modulus bit size\n",
    "HE.keyGen()  # Key Generation: generates a pair of public/secret keys\n",
    "HE.rotateKeyGen()  # Rotate key generation --> Allows rotation/shifting\n",
    "HE.relinKeyGen()  # Relinearization key generation\n",
    "HE.batchEnabled()\n",
    "duplicate_factor = int((HE.get_nSlots() / 2) / 1024)\n",
    "\n",
    "print(f\"{HE.get_nSlots() = }\")\n",
    "print(f\"{duplicate_factor = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate(vec, n):\n",
    "    # repeating the vector `vec` the number of `n` times\n",
    "    return np.tile(vec, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_conv(input_image, data_shape, input_shape, \n",
    "                  conv2d_kernel, bias, conv_stride, data_stride, fact, HE):\n",
    "\n",
    "    original_shape = data_shape\n",
    "    if len(original_shape) != 3:\n",
    "        original_shape = (original_shape[0], int(np.sqrt(original_shape[1])), int(np.sqrt(original_shape[1])))\n",
    "\n",
    "    kernel_shape = conv2d_kernel.shape\n",
    "    output_shape = (int(np.floor((input_shape[1] - kernel_shape[2]-1) // conv_stride[0] + 1)),\n",
    "                    int(np.floor((input_shape[2] - kernel_shape[3]-1) // conv_stride[1] + 1)))\n",
    "\n",
    "    n = original_shape[1]\n",
    "    n2 = n ** 2\n",
    "\n",
    "    # input_flat = input_image.flatten()\n",
    "\n",
    "    result = []\n",
    "\n",
    "    if data_stride[0] == 1:\n",
    "        for c_o in range(kernel_shape[0]):\n",
    "            tmp = HE.encodeInt(np.zeros(4096, dtype=np.int64))\n",
    "            for c_i in range(kernel_shape[1]):\n",
    "                tmp_ency = input_image[c_i]\n",
    "                for j in range(kernel_shape[2]):\n",
    "                    for i in range(kernel_shape[3]):\n",
    "                        # Extra check, else a transpartent Ctxt is created\n",
    "                        if conv2d_kernel[c_o, c_i, j, i] != 0:\n",
    "                            conv_kernel = HE.encodeInt(np.repeat(conv2d_kernel[c_o, c_i, j, i], 4096))\n",
    "                            tmp_mult = tmp_ency << (i + n * j)\n",
    "                            tmp_mult *= conv_kernel\n",
    "                            tmp += tmp_mult\n",
    "            # if c_o % 10 == 0:\n",
    "            #     print(\"Kernel \" + str(c_o))\n",
    "            result.append(tmp)\n",
    "    # TODO: Add extra statement for CiFAR\n",
    "    elif data_stride[0] == 2:\n",
    "        for c_o in range(kernel_shape[0]):\n",
    "            tmp = HE.encodeInt(np.zeros(original_shape[1] * original_shape[2], dtype=np.int64))\n",
    "            for c_i in range(kernel_shape[1]):\n",
    "                tmp_ency = input_image[c_i]\n",
    "                for j in range(kernel_shape[2]):\n",
    "                    for i in range(kernel_shape[3]):\n",
    "                        if conv2d_kernel[c_o, c_i, j, i] != 0:\n",
    "                            conv_kernel = HE.encodeInt(np.repeat(conv2d_kernel[c_o, c_i, j, i], 4096))\n",
    "                            tmp_mult = tmp_ency << ((i * 2) + n * (j * 2))\n",
    "                            tmp_mult *= conv_kernel\n",
    "                            tmp += tmp_mult\n",
    "\n",
    "            result.append(tmp)\n",
    "\n",
    "    # Need to be placed here, now the mask will turn everything that need to be zero to zero\n",
    "    for i in range(kernel_shape[0]):\n",
    "        result[i] += HE.encode(bias[i])\n",
    "\n",
    "    # Dimension of the output C_O, C_I, W, H\n",
    "    mask = np.ones((kernel_shape[0], 1, output_shape[0], output_shape[1]), dtype=np.int64)\n",
    "\n",
    "    # ToDo: Now only works for max conv_stride = 2\n",
    "    # Diliation type of spread out\n",
    "    if conv_stride[0] > 1:\n",
    "        # When stride of a convolution is >1, the data is split out with a factor of data_stride\n",
    "        zeros = 2 ** data_stride[0]\n",
    "        for i in range(output_shape[1] - 1):\n",
    "            for j in range(zeros - 1):\n",
    "                mask = np.insert(mask, zeros * i + j + 1, 0, axis=3)\n",
    "        for i in range(output_shape[1] - 1):\n",
    "            for j in range(zeros - 1):\n",
    "                mask = np.insert(mask, zeros * i + j + 1, 0, axis=2)\n",
    "\n",
    "    mask = np.pad(mask, ((0, 0),\n",
    "                         (0, 0),\n",
    "                         (0, original_shape[1] - mask.shape[2]),\n",
    "                         (0, original_shape[2] - mask.shape[3])))\n",
    "\n",
    "    mask = np.append(mask[0, :].flatten(), np.zeros(240, dtype=np.int64))\n",
    "    mask = HE.encodeInt(duplicate(mask, fact))\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        result[i] *= mask\n",
    "\n",
    "    # result = result * HE.encodeInt(mask.reshape(kernel_shape[0], original_shape[1] * original_shape[2]).flatten())\n",
    "    return result\n",
    "\n",
    "\n",
    "def expand_mat(mat, mat_shape, data_shape, data_stride):\n",
    "    if data_stride[0] > 1:\n",
    "        zeros = 2 ** (data_stride[0] - 1)\n",
    "\n",
    "        for j in range(data_shape[2]):\n",
    "            for i in range(data_shape[1]):\n",
    "                for k in range(zeros - 1):\n",
    "                    mat = np.insert(mat, zeros * mat_shape[1] * j + zeros * i + k + 1, 0, axis=1)\n",
    "\n",
    "            for i in range(zeros * mat_shape[1] - zeros * data_shape[1]):\n",
    "                mat = np.insert(mat, zeros * mat_shape[1] * j + zeros * data_shape[1] + i, 0, axis=1)\n",
    "\n",
    "        diff = mat_shape[1] * mat_shape[1] - mat.shape[1]\n",
    "\n",
    "        mat = np.append(mat, np.zeros((mat.shape[0], diff), dtype=np.int64), axis=1)\n",
    "\n",
    "    else:\n",
    "        diff = mat_shape[1] - data_shape[1]\n",
    "\n",
    "        for i in range(data_shape[1]):\n",
    "            for j in range(diff):\n",
    "                # Always want to have 20 data point, followed by 8 zeros, and then back again 20 data points\n",
    "                mat = np.insert(mat, data_shape[1] * (i + 1) + i * diff + j, 0, axis=1)\n",
    "\n",
    "        mat = np.append(mat, np.zeros((mat.shape[0], diff * mat_shape[1]), dtype=np.int64), axis=1)\n",
    "    return mat\n",
    "\n",
    "\n",
    "def rot_plain(a, b, n_o, n_i, fact, HE):\n",
    "    div_oi = int(n_i / n_o)\n",
    "    slot_size = fact * n_i\n",
    "\n",
    "    diag = np.zeros((n_o, n_i), dtype=np.int64)\n",
    "\n",
    "    for j in range(n_o):\n",
    "        tmp = get_diagonal(j, a)\n",
    "        if div_oi > 1:\n",
    "            for i in range(div_oi - 1):\n",
    "                tmp = np.append(tmp, get_diagonal(j + (i + 1) * n_o, a))\n",
    "\n",
    "        diag[j] = tmp\n",
    "\n",
    "    output = HE.encodeInt(np.zeros(slot_size, dtype=np.int64))\n",
    "    pad_length = 240 + 7*1024\n",
    "\n",
    "    counter = 0\n",
    "    for i in range(n_o):\n",
    "        if np.sum(np.abs(diag[i])) != 0:\n",
    "            output += HE.encodeInt(duplicate(diag[i], fact)) * (b << i)\n",
    "            counter += 1\n",
    "        # output += diag[i] * np.roll(b, -i)\n",
    "        # output += np.tile(diag[i], fact) * np.roll(b, -i)\n",
    "\n",
    "    result = HE.encodeInt(np.zeros(slot_size, dtype=np.int64))\n",
    "    if counter != 0:\n",
    "        for i in range(div_oi):\n",
    "            result += (output << (8192 - (i * n_o + pad_length)))\n",
    "        return result\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_diagonal(pos, mat):\n",
    "    max_size = max(mat.shape[0], mat.shape[1])\n",
    "    min_size = min(mat.shape[0], mat.shape[1])\n",
    "\n",
    "    diag = np.zeros(min_size, dtype=np.int64)\n",
    "    j = pos\n",
    "    i = 0\n",
    "    k = 0\n",
    "\n",
    "    while (i < max_size - pos) and (i < min_size) and (j < max_size):\n",
    "        diag[k] = mat[i, j]\n",
    "        k += 1\n",
    "        i += 1\n",
    "        j += 1\n",
    "\n",
    "    i = max_size - pos\n",
    "    j = 0\n",
    "\n",
    "    while (i < mat.shape[0]) and (j < pos):\n",
    "        diag[k] = mat[i, j]\n",
    "        k += 1\n",
    "        i += 1\n",
    "        j += 1\n",
    "\n",
    "    return diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single time 622.5205037593842\n",
      "0\t0\t0\t0\n"
     ]
    }
   ],
   "source": [
    "nb_tests = 1  # number of test images\n",
    "acc, acc_he = 0, 0\n",
    "\n",
    "for i in range(nb_tests):\n",
    "    # Pad the flattened input image to have length 1024. Then duplicate it\n",
    "    # `duplicate_factor` times due to batching properties of FHE\n",
    "    input_image: np.ndarray = duplicate(\n",
    "        vec=np.append(x_test[i].flatten(), np.zeros(240, dtype=np.int64)), \n",
    "        n=duplicate_factor\n",
    "    )\n",
    "\n",
    "    input_image: PyfhelPlaintext = HE.encodeInt(input_image)\n",
    "    input_image: List[PyfhelCiphertext] = [HE.encrypt(input_image)]\n",
    "\n",
    "    start_time_one = time.time()\n",
    "\n",
    "    # first encrypted conv layer (enc input, plaintext weights)\n",
    "    conv1_rot: List[PyfhelCiphertext] = rotation_conv(\n",
    "        input_image=input_image, data_shape=(1, 28, 28), input_shape=(1, 28, 28),\n",
    "        conv2d_kernel=conv1_q, bias=conv1_bias, conv_stride=cnn_py.conv2d_stride, \n",
    "        data_stride=(1, 1), fact=duplicate_factor, HE=HE\n",
    "    )\n",
    "\n",
    "    # first square activation\n",
    "    conv1_act_rot: List[PyfhelCiphertext] = []\n",
    "    for j in range(len(conv1_rot)):\n",
    "        # result.append(HE.decryptInt(conv1_rot[j]))\n",
    "        conv1_act_rot.append((HE.power(conv1_rot[j], 2)))\n",
    "    \n",
    "    # second encrypted conv layer \n",
    "    conv2_rot: List[PyfhelCiphertext] = rotation_conv(\n",
    "        input_image=conv1_act_rot, data_shape=(1, 28, 28), input_shape=(5, 12, 12), \n",
    "        conv2d_kernel=conv2_q, bias=conv2_bias, conv_stride=cnn_py.conv2d_1_stride, \n",
    "        data_stride=(2, 2), fact=duplicate_factor, HE=HE\n",
    "    )\n",
    "\n",
    "    # second square activation\n",
    "    conv2_act_rot: List[PyfhelCiphertext] = []\n",
    "    for j in range(len(conv2_rot)):\n",
    "        # result.append(HE.decryptInt(conv2_rot[j]))\n",
    "        conv2_act_rot.append(HE.power(conv2_rot[j], 2))\n",
    "\n",
    "    # the dense layer\n",
    "    dense = []\n",
    "    slide_size = int(cnn_py.dense_input / cnn_py.conv2d_1_out_channels)\n",
    "\n",
    "    for j in range(50):\n",
    "        w_tmp = expand_mat(\n",
    "            mat=dense1_q[:, j * slide_size:(j + 1) * slide_size], \n",
    "            mat_shape=(1, 28, 28), data_shape=(1, 4, 4),\n",
    "            data_stride=(3, 3)\n",
    "        )\n",
    "        w_tmp = np.append(w_tmp, np.zeros((10, 240)), axis=1)\n",
    "        w_tmp = np.append(w_tmp, np.zeros((6, 1024)), axis=0)\n",
    "        rot_out = rot_plain(\n",
    "            a=w_tmp, b=conv2_act_rot[j], \n",
    "            n_o=16, n_i=1024, \n",
    "            fact=duplicate_factor, HE=HE)\n",
    "        if rot_out != None:\n",
    "            dense.append(rot_out)\n",
    "\n",
    "    dense_dec = np.zeros(10, dtype=np.int64)\n",
    "    for k in range(len(dense)):\n",
    "        # print(HE.noise_level(dense[k]))\n",
    "        decrypt = HE.decryptInt(dense[k])\n",
    "        dense_dec += decrypt[:10]\n",
    "\n",
    "    dense_dec += dense_bias\n",
    "    if np.argmax(dense_dec[:10]) == y_test[i]:\n",
    "        acc_he += 1\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        single_time = time.time() - start_time_one\n",
    "        print(\"Single time \" + str(single_time))\n",
    "        print(str(i) + \"\\t\" + str(acc) + \"\\t\" + str(acc_he) + \"\\t\" + str(HE.noise_level(dense[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pockethhe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
